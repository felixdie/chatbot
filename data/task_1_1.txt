Wang, L., Huang, N., Hong, Y., Liu, L., Guo, X., & Chen, G. (2023). Voice‐based AI in call
center customer service: A natural field experiment. Production and Operations
Management, 32(4), 1002-1018.
- Context: The study is focused on a specific industry, namely the telecommunication industry, particularly examining the implementation of voice-based AI systems in call center customer service.
- Research Question and Findings: The main research question is: How does the introduction of voice-based AI systems impact call length, customer demand for human service, and customer complaints in call center customer services? The key findings indicate that the implementation of the AI system temporarily increases the duration of machine service and customers’ demand for human service, but it persistently reduces customer complaints.
- Theme of Research:
    - Human vs. AI: The study highlights that while the AI system increases the demand for human service temporarily, it also leads to a reduction in customer complaints, suggesting a nuanced interaction between human agents and AI.
    - Human + AI Collaboration: The collaboration discussed involves the AI system replacing the traditional IVR system, with customers interacting with the AI before potentially being routed to human agents if needed.
- Method: The study method is classified as a Natural Field Experiment.
- Contribution: The primary contribution of the study is theoretical, as it provides empirical evidence on the effects of voice-based AI systems in customer service settings, contributing to the understanding of AI's role in customer interactions.
- Future Potential and Limitations: The study suggests future research directions to explore the implications of voice-based AI systems among different user populations or in other service settings. It also notes limitations regarding the generalizability of findings due to potential cultural variations and differences in technology adoption across countries.
---
Lu, T., & Zhang, Y. (2024). 1+ 1> 2? information, humans, and machines. Information
Systems Research.
- Context: The study focuses on the microloan industry and examines human-machine collaboration in decision-making tasks.
- Research Question and Findings: The main research question investigates how information complexity and machine explanations affect human-machine collaboration in decision-making. The key findings indicate that both larger information volumes and structured machine explanations are necessary for optimal performance in human-machine collaboration, suggesting that neither can be dispensed with for effective decision-making.
- Theme of Research:
    - Human vs. AI: The study highlights that while machines can outperform humans in decision-making due to their computational power, humans can contribute unique insights and private information that machines cannot access. The performance of human-machine collaboration is contingent on the complexity of the task and the information provided.
    - Human + AI Collaboration: The collaboration discussed involves humans making initial independent decisions followed by final decisions informed by machine explanations. The study emphasizes the importance of both rich information and structured machine explanations to enhance decision-making performance.
- Method: The study employs an empirical method, specifically a two-stage field experiment, to quantify the performance outcomes of human-machine collaboration under different conditions.
- Contribution: The primary contribution of the study is methodological, as it provides a framework for understanding the conditions under which human-machine collaboration can exceed the performance of either humans or machines alone.
- Future Potential and Limitations: The study suggests future research directions could explore the impact of task complexity on human-machine collaboration further. Limitations include potential resistance from humans to adopt machine recommendations, which may hinder the effectiveness of collaboration.
---
Ibrahim, Rouba, et al. “Eliciting human judgment for prediction algorithms.” Management
Science, https://doi.org/10.1287/mnsc.2020.3856.
- Context: The study focuses on the integration of human judgment with forecasting algorithms, which suggests a broader, conceptual scope rather than being confined to a specific industry or task.
- Research Question and Findings: The main research question revolves around how the design of a forecasting system's elicitation impacts performance when considering human random error. The key findings indicate that the method of eliciting human forecasts can significantly affect predictive performance, particularly when human random error is taken into account.
- Theme of Research:
    - Human vs. AI: The study highlights the comparative advantages of human judgment in certain contexts, particularly due to their domain knowledge, which can sometimes lead to better forecasting than purely statistical models.
    - Human + AI Collaboration: The research discusses the integration of human judgment with algorithmic forecasts, examining different approaches such as making judgmental adjustments to algorithm outputs or combining separate forecasts from humans and algorithms.
- Method: The study can be classified as a Conceptual or Case Study, as it discusses theoretical implications and contributions to the understanding of human judgment in forecasting systems.
- Contribution: The primary contribution of the study is theoretical, as it advances the understanding of how human random error affects forecasting performance and the implications for system design in operations management.
- Future Potential and Limitations: The study suggests future research directions in exploring various elicitation methods and their impacts on forecasting accuracy. However, it also acknowledges limitations related to the variability of human judgment and the contexts in which these findings may apply.
---
Yalcin, G., Lim, S., Puntoni, S., & van Osselaer, S. M. J. (2022). Thumbs Up or Down:
Consumer Reactions to Decisions by Algorithms Versus Humans. Journal of Marketing
Research, 59(4), 696-717. https://doi.org/10.1177/00222437211070016
- Context: The study focuses on consumer reactions to decisions made by algorithms versus those made by humans, particularly in consumer-facing tasks.
- Research Question and Findings: The main research question investigates how consumers react differently to favorable and unfavorable decisions made by algorithms compared to humans. The key findings reveal that consumers react less positively to favorable decisions made by algorithms than by humans, while this difference is mitigated for unfavorable decisions. The reaction is influenced by attribution processes, where consumers find it easier to internalize favorable outcomes from humans but externalize unfavorable outcomes regardless of the decision maker.
- Theme of Research:
    - Human vs. AI: The study highlights that consumers perceive algorithms as less favorable decision makers when the outcome is positive, indicating a comparative disadvantage for algorithms in this context.
    - Human + AI Collaboration: The research discusses the potential for anthropomorphizing algorithms to improve consumer reactions, suggesting that making algorithms appear more human-like can enhance positive attitudes towards algorithmic decisions.
- Method: The study employs an empirical approach, utilizing multiple lab experiments to gather data on consumer reactions.
- Contribution: The primary contribution of the study is theoretical, as it provides insights into consumer psychology regarding algorithmic versus human decision-making and the implications for marketing practices.
- Future Potential and Limitations: The study suggests future research directions in exploring the psychological processes behind consumer reactions to algorithmic decisions and the effectiveness of anthropomorphizing algorithms. Limitations include the need for further investigation into the long-term effects of algorithmic decision-making on consumer trust and the potential ethical implications of transparency in algorithm use.






