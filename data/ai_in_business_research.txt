Cao, Z., Li, M., & Pavlou, P. A. (2024). AI in Business Research. Available at SSRN
4897619.

Abstract

Articial 
intelligence 
(AI) 
has 
emerged 
as 
a 
pivotal 
force 
in 
modern 
business 
transformation, 
garnering 
widespread 
attention 
from 
both 
practitioners 
and 
academics. 
With 
a 
notable 
exponential 
increase 
in 
AI-
related 
studies, 
we 
provide 
a 
research 
framework 
aiming 
to 
synthesize 
the 
existing 
literature 
on 
AI 
in 
the 
business 
eld. 
We 
conduct 
a 
comprehensive 
review 
of 
AI 
research 
spanning 
from 
2010 
to 
2023 
in 
25 
leading 
business 
journals 
according 
to 
this 
review 
framework. 
Specically, 
we 
review 
the 
literature 
from 
three 
research 
perspectives: 
(i) 
AI 
applications, 
(ii) 
human 
perceptions 
of 
AI, 
and 
(iii) 
AI 
behavior. 
We 
also 
identify 
ve 
principal 
research 
questions 
and 
oer 
suggestions 
for 
future 
research 
directions. 


Key 
words 
: 
Articial 
intelligence; 
human 
perception; 
human-AI 
interaction; 
algorithmic 
bias 


1. 
Introduction 
Articial 
intelligence 
(AI) 
is 
increasingly 
recognized 
as 
the 
next 
general-purpose 
technology, 
heralding 
the 
advent 
of 
the 
fourth 
industrial 
revolution 
and 
catalyzing 
signicant 
societal 
transformations 
(Brynjolfsson 
and 
Mcafee 
2017). 
The 
enormous 
economic 
prospects 
have 
prompted 
a 
wide 
array 
of 
companies 
to 
channel 
substantial 
resources 
into 
the 
research 
and 
development 
of 
AI-centric 
technologies. 
Leading 
this 
surge, 
technology 
giants 
like 
Alphabet 
and 
Microsoft 
have 
pivoted 
towards 
an 
AI-rst 
strategy. 
Simultaneously, 
global 
investments 
in 
AI 
reached 
$91.9 
billion 
in 
2022 
and 
are 
expected 
to 
rise 
to 
approximately 
$200 
billion 
by 
2025 
(Goldman 
Sachs 
2023). 
This 
in
ux 
is 
nurturing 
a 
slew 
of 
AI 
innovations, 
now 
permeating 
diverse 
sectors 
including 
customer 
service, 
banking, 
and 
healthcare. 
A 
key 
milestone 
in 
AI 
development|that 
is, 
the 
emergence 
of 
ChatGPT 
in 
late 
2022|has 
further 
sparked 
greater 
enthusiasm 
in 
AI 
technologies, 
with 
2023 
being 
heralded 
as 
the 
\year 
of 
AI.” 


AI 
is 
rst 
conceptualized 
by 
John 
McCarthy 
in 
the 
1950s 
as 
\the 
science 
and 
engineering 
of 
making 
intelligent 
machines” 
(Stanford 
HAI 
2020). 
Initially, 
AI's 
impact 
is 
limited 
(Hansen 
et 
al. 
1992; 
Goul 
et 
al. 
1992), 
constrained 
by 
the 
development 
of 
hardware 
and 
algorithms. 
However, 
a 


1 





resurgence 
in 
AI 
has 
emerged 
in 
recent 
years, 
fueled 
by 
advances 
in 
machine 
learning, 
especially 
deep 
learning, 
along 
with 
the 
availability 
of 
big 
data 
and 
enhanced 
computing 
capabilities. 
AI 
has 
achieved 
or 
even 
surpassed 
human 
performance 
in 
several 
areas: 
notably, 
AlphaGo 
defeated 
South 
Korean 
Go 
champion 
Lee 
Se-dol 
in 
2016 
(BBC 
2016); 
machine 
image 
recognition 
error 
rates 
dropped 
below 
5%, 
comparable 
to 
human 
levels 
(Brynjolfsson 
and 
Mcafee 
2017); 
and 
ChatGPT 
has 
outperformed 
human 
crowd-workers 
in 
text 
annotation 
tasks 
(Gilardi 
et 
al. 
2023). 


The 
AI-driven 
transformation 
is 
capturing 
signicant 
attention 
across 
both 
practice 
and 
academia, 
with 
increasing 
societal 
and 
economic 
implications. 
For 
example, 
AI 
has 
been 
demonstrated 
to 
have 
signicant 
macroeconomic 
impacts 
on 
national 
economic 
growth 
(Nordhaus 
2021), 
labor 
markets 
(Frank 
et 
al. 
2019; 
Acemoglu 
and 
Restrepo 
2019, 
2020; 
Mann 
and 
Puttmann 
2023), 
and 
income 
inequality 
(Korinek 
and 
Stiglitz 
2018). 
Concurrently, 
business 
journals 
call 
for 
papers 
to 
unravel 
AI-related 
in
uences: 
Management 
Science 
has 
a 
special 
issue 
titled 
\The 
Human-
Algorithm 
Connection", 
emphasizing 
the 
interplay 
between 
humans 
and 
AI 
algorithms 
(Caro 
et 
al. 
2022); 
Production 
and 
Operations 
Management 
has 
a 
special 
issue 
titled 
\Responsible 
Data 
Science", 
focusing 
on 
the 
social 
responsibilities 
associated 
with 
AI 
and 
algorithmic 
applications 
(Cohen 
et 
al. 
2022); 
Decision 
Sciences 
has 
a 
special 
issue 
titled 
\AI-Driven 
Decision 
Sciences", 
concentrating 
on 
AI's 
contributions 
to 
business 
decision-making 
(Li 
et 
al. 
2023). 
Despite 
these 
thematic 
directives, 
there 
is 
still 
a 
noticeable 
lack 
of 
a 
systematic 
framework 
for 
understanding 
AI-related 
research 
within 
the 
context 
of 
business 
studies. 


In 
this 
study, 
we 
introduce 
a 
structured 
framework 
to 
elucidate 
the 
intricate 
dynamics 
between 
humans 
and 
AI, 
as 
depicted 
in 
Figure 
1. 
This 
framework 
is 
based 
on 
a 
directed 
cyclical 
interaction 
between 
humans 
and 
AI. 
First, 
humans, 
as 
creators, 
develop 
and 
rene 
AI-related 
products, 
which 
are 
then 
gradually 
deployed 
across 
various 
industries. 
The 
extensive 
applications 
of 
these 
AI 
products 
foster 
increasing 
interactions 
between 
humans 
and 
AI, 
as 
well 
as 
between 
existing 
organizational 
structures 
and 
AI. 
Consequently, 
it 
is 
crucial 
to 
thoroughly 
assess 
the 
impact 
of 
AI 
applications 
on 
human 
society 
(i.e., 
AI 
applications). 
Second, 
the 
widespread 
adoption 
of 
AI 
raises 
another 
important 
question: 
how 
do 
humans 
perceive 
AI 
during 
human-AI 
interactions? 
Given 
AI's 
transformative 
potential 
across 
numerous 
sectors, 
understanding 
consumer 
attitudes 
is 
vital 
for 
devising 
eective 
strategies 
to 
advertise 
AI 
and 
foster 
its 
broader 
acceptance 
and 
growth. 
Therefore, 
it 
is 
important 
to 
explore 
public 
perceptions 
and 
attitudes 
toward 
AI 
algorithms 
and 
systems 
(i.e., 
human 
perceptions 
of 
AI 
). 
Third, 
with 
the 
development 
of 
AI 
technologies, 
AI 
products 
are 
becoming 
increasingly 
smarter 
and 
more 
intelligent. 
In 
the 
process 
of 
humans 
interacting 
with 
AI, 
these 
advanced 
systems 
may 
display 
human-like 
behaviors, 
such 
as 
discrimination, 
irrational 
actions, 
or 
emotional 
responses, 
due 
to 
biased 
training 
data 
or 
other 
underlying 
factors. 
Such 
behaviors 
can 
in
uence 
the 
application 
and 
development 
of 
AI, 
as 
well 
as 
human 
perceptions 
of 
it. 





HumansAIApplicationson 
human societyPerceptionsof AIHuman-AI InteractionsAI behaviorDeveloping and RefiningHuman-AI Interactions
Figure 
1 
The 
framework 
of 
AI 
in 
business 


Accordingly, 
exploring 
and 
identifying 
these 
behaviors 
in 
AI 
and 
related 
technologies 
is 
a 
pivotal 


research 
goal 
(i.e., 
AI 
behavior). 


We 
adopt 
this 
framework|AI 
applications, 
human 
perceptions 
of 
AI, 
and 
AI 
behavior|to 


conduct 
a 
systematic 
literature 
review 
within 
the 
domain 
of 
business 
research, 
aiming 
to 
delineate 


the 
current 
landscape 
and 
future 
trajectory 
of 
AI 
research. 
Specically, 
we 
focus 
on 
journals 
in 
the 


Dallas 
(UTD) 
24 
List1 
and 
the 
Decision 
Sciences 
Journal. 
We 
select 
relevant 
articles 
as 
follows. 


• 
First, 
we 
construct 
a 
comprehensive 
list 
of 
AI-related 
keywords 
(such 
as 
\AI,” 
\articial 
intelligence,” 
and 
\machine 
learning") 
to 
search 
articles 
published 
on 
those 
25 
journals 
via 


the 
Web 
of 
Science,2 
where 
the 
eld 
tag 
topic 
(TS) 
is 
used 
to 
judge 
an 
article. 
In 
particular, 


searching 
through 
TS 
means 
searching 
for 
specic 
terms 
in 
the 
following 
elds 
within 
a 
record: 


1 
https://jsom.utdallas.edu/the-utd-top-100-business-school-research-rankings. 


2 
Search 
code 
on 
the 
Web 
of 
Science: 
(TS=(\articial 
intelligence” 
OR 
\AI” 
OR 
\machine” 
OR 
\deep 
learning” 
OR 
\algorithm*” 
OR 
\*bot” 
OR 
\*bots” 
OR 
\robo*” 
OR 
\automat*” 
OR 
\intelligen* 
system*") 
AND 
SO=(M 
SOM 
MANUFACTURING 
SERVICE 
OPERATIONS 
MANAGEMENT) 
OR 
SO=(Academy 
of 
Management 
Journal) 
OR 
SO=(Academy 
of 
Management 
Review) 
OR 
SO=(Administrative 
Science 
Quarterly) 
OR 
SO=(Information 
Systems 
Research) 
OR 
SO=(Journal 
of 
Accounting 
Economics) 
OR 
SO=(Journal 
of 
Accounting 
Research) 
OR 
SO=(Journal 
of 
Consumer 
Research) 
OR 
SO=(Journal 
of 
Finance) 
OR 
SO=(Journal 
of 
Financial 
Economics) 
OR 
SO=(Journal 
of 
International 
Business 
Studies) 
OR 
SO=(Journal 
of 
Marketing) 
OR 
SO=(Journal 
of 
Marketing 
Research) 
OR 
SO=(Journal 
of 
Operations 
Management) 
OR 
SO=(INFORMS 
JOURNAL 
ON 
COMPUTING) 
OR 
SO=(Management 
Science) 
OR 
SO=(Marketing 
Science) 
OR 
SO=(MIS 
Quarterly) 
OR 
SO=(Operations 
Research) 
OR 
SO=(Organization 
Science) 
OR 
SO=(Production 
and 
Operations 
Management) 
OR 
SO=(Strategic 
Management 
Journal) 
OR 
SO=(Accounting 
Review) 
OR 
SO=(Review 
of 
Financial 
Studies) 
OR 
SO=(Decision 
Sciences)). 





title, 
abstract, 
author 
keywords, 
and 
keywords 
plus. 
3 
This 
process 
generates 
a 
total 
of 
3,222 
published 
articles 
during 
the 
period 
between 
2010 
and 
2023. 


• 
Second, 
we 
remove 
special 
types 
of 
publications 
such 
as 
review 
articles, 
editorial 
notes, 
and 
biographical 
items, 
retaining 
only 
research 
articles. 
This 
step 
results 
in 
the 
exclusion 
of 
42 
articles 
from 
the 
initial 
set. 
• 
Third, 
we 
conduct 
a 
rigorous 
assessment 
of 
each 
article 
to 
determine 
whether 
its 
content 
aligns 
with 
our 
review 
framework. 
To 
diminish 
subjectivity 
in 
this 
assessment, 
authors 
independently 
read 
and 
evaluate 
all 
articles. 
Subsequently, 
we 
merge 
our 
individual 
assessments 
and 
engage 
in 
discussions 
regarding 
any 
articles 
marked 
dierently, 
to 
reach 
a 
consensus 
on 
whether 
they 
should 
be 
included 
in 
our 
review. 
• 
Finally, 
we 
identify 
114 
research 
articles 
published 
between 
2010 
and 
2023. 
Figure 
2 
reports 
the 
distribution 
of 
these 
articles 
across 
the 
three 
topics. 
051015202530354020102011201220132014201520162017201820192020202120222023TotalAI ApplicationsHuman PerceptionsAI Behavior
Figure 
2 
Number 
of 
publications 
with 
AI-related 
keywords 
in 
topics 


The 
structure 
of 
the 
paper 
is 
as 
follows. 
Section 
2 
reviews 
the 
literature 
related 
to 
AI 
applications. 
Section 
3 
reviews 
the 
studies 
regarding 
human 
perceptions 
of 
AI. 
Section 
4 
discusses 
the 
research 
on 
AI 
behavior. 
Section 
5 
summarizes 
the 
reviewed 
literature 
and 
outlines 
several 
fundamental 
questions 
driving 
future 
research. 
Finally, 
section 
6 
oers 
a 
conclusion. 


3 
This 
eld 
is 
developed 
by 
the 
Web 
of 
Science 
and 
contains 
the 
words 
or 
phrases 
that 
frequently 
appear 
in 
the 
titles 
of 
an 
article's 
references, 
but 
do 
not 
appear 
in 
the 
title 
of 
the 
article 
itself. 
Ref: 





2. 
AI 
Application 
This 
section 
discusses 
the 
impact 
of 
AI 
in 
the 
strategic 
level, 
system 
level, 
and 
algorithm 
level 
on 
organizational 
performance 
(Section 
2.1). 
Then, 
we 
discuss 
the 
human-AI 
interaction 
where 
AI 
can 
serve 
an 
assistant,a 
collaborator, 
and 
a 
competitor 
(Section 
2.2). 


2.1. 
AI 
and 
Organizational 
Performance 
2.1.1. 
Strategy. 
Panel 
A 
of 
Table 
1 
presents 
the 
studies 
of 
AI 
applications 
at 
the 
strategic 
level. 
For 
example, 
Lou 
and 
Wu 
(2021) 
study 
AI's 
role 
in 
accelerating 
drug 
development 
within 
biotech 
and 
pharmaceutical 
sectors, 
nding 
that 
AI 
signicantly 
enhances 
the 
identication 
of 
new 
drug-target 
combinations. 
Zhang 
et 
al. 
(2023) 
reveal 
that 
the 
emergence 
of 
AI 
technologies 
would 
change 
the 
labor 
force 
in 
organizations, 
generally 
complementing 
high-education 
labor 
but 
substituting 
for 
low-education 
labor. 
Dixon 
et 
al. 
(2021) 
show 
that 
robotics 
investments 
increase 
overall 
rm 
employment 
but 
reduce 
the 
needs 
in 
managerial 
positions. 
Cao 
et 
al. 
(2023) 
explore 
how 
publicly 
traded 
companies 
adjust 
to 
the 
rise 
of 
AI 
readership. 
Their 
ndings 
indicate 
that 
rms 
adapt 
their 
disclosure 
practices 
to 
enhance 
the 
machine 
readability 
of 
lings. 
Li 
et 
al. 
(2021a) 
discover 
the 
positive 
moderating 
role 
of 
AI 
innovation 
capabilities 
in 
the 
interplay 
between 
corporate 
social 
performance 
and 
market 
risk. 
On 
the 
modeling 
front, 
Li 
and 
Li 
(2022) 
develop 
mathematical 
models 
to 
analyze 
the 
repercussions 
of 
employing 
AI 
tools 
in 
automating 
order 
decisions 
within 
a 
decentralized 
supply 
chain, 
demonstrating 
potential 
protability 
declines 
for 
retailers 
and 
possible 
detrimental 
eects 
for 
both 
suppliers 
and 
retailers 
in 
extreme 
scenarios. 
Choi 
et 
al. 
(2024) 
explore 
how 
AI-enhanced 
predictive 
capabilities 
in
uence 
a 
rm's 
pricing 
strategies 
under 
the 
ship-then-shop 
business 
model. 
Wang 
et 
al. 
(2023b) 
identify 
conditions 
under 
which 
rms 
bene
t 
from 
disclosing 
their 
use 
of 
AI 
algorithms 
in 
decision-making 
processes 
to 
users. 
Gurkan 
and 
de 
Vericourt 
(2022) 
reveal 
that 
interactions 
among 
data 
volume, 
algorithmic 
enhancement, 
and 
incentive 
mechanisms 
can 
lead 
to 
pricing 
anomalies 
and 
aect 
social 
welfare, 
thereby 
suggesting 
that 
overaccumulation 
of 
data 
might 
inversely 
impact 
prots. 
2.1.2. 
System. 
AI, 
such 
as 
chatbot, 
can 
automate 
complex 
functions 
involving 
data 
processing, 
analysis, 
decision-making, 
and 
action 
execution. 
Panel 
B 
of 
Table 
1 
lists 
the 
related 
literature. 
Song 
et 
al. 
(2017) 
examine 
the 
ecacy 
of 
a 
decision 
support 
system 
in 
facilitating 
auditors’ 
evaluation 
of 
nancial 
and 
nonnancial 
information, 
nding 
that 
it 
enhances 
risk 
assessment 
performance. 
Mukherjee 
and 
Sinha 
(2020) 
demonstrate 
that 
the 
surgical 
robots 
could 
improve 
clinical 
performance. 
Schanke 
et 
al. 
(2021) 
explore 
the 
eect 
of 
anthropomorphic 
chatbots 
in 
retail 
settings, 
concluding 
that 
human-like 
chatbots 
positively 
in
uence 
transaction 
outcomes. 
Similarly, 
Wang 
et 
al. 
(2023a) 
nd 
that 
implementing 
voice-activated 
AI 
systems 
in 
call 
centers 
can 
signicantly 
reduce 
customer 
complaints, 
despite 
the 
increase 
in 
service 
duration. 
Brynjolfsson 
et 
al. 
(2019) 



Table 
1 
Literature 
about 
AI 
impact 


Literature 
Application 
Context 
Journal 


Panel 
A: 
Strategy 


Lou 
and 
Wu 
(2021) 
Pharmaceutical 
rms 
MISQ 
Li 
et 
al. 
(2021a) 
– 
POM 
Zhang 
et 
al. 
(2023) 
– 
ISR 
Dixon 
et 
al. 
(2021) 
– 
MS 
Cao 
et 
al. 
(2023) 
– 
RFS 
Li 
and 
Li 
(2022) 
Supply 
chain 
management 
POM 
Choi 
et 
al. 
(2024) 
Consumer 
prediction 
MS 
Wang 
et 
al. 
(2023b) 
– 
MS 
Gurkan 
and 
de 
Vericourt 
(2022) 
– 
MS 


Panel 
B: 
System 
Song 
et 
al. 
(2017) 
Auditing 
DS 
Mukherjee 
and 
Sinha 
(2020) 
Hospital 
JOM 
Schanke 
et 
al. 
(2021) 
Retailing 
rms 
ISR 
Wang 
et 
al. 
(2023a) 
Call 
center 
POM 
Brynjolfsson 
et 
al. 
(2019) 
E-commerce 
platforms 
MS 
Cheng 
et 
al. 
(2020) 
Trac 
congestion 
ISR 
Deng 
et 
al. 
(2023) 
Shelf 
monitoring 
MISQ 
Spring 
et 
al. 
(2022) 
Law 
and 
accountancy 
rms 
JOM 
Panel 
C: 
Algorithm 
Ferreira 
et 
al. 
(2016) 
Demand 
forecasting 
MSOM 
Shi 
et 
al. 
(2020) 
Inventory 
management 
DS 
Senoner 
et 
al. 
(2022) 
Quality 
management 
MS 
Feldman 
et 
al. 
(2022) 
Product 
display 
OR 
Chen 
et 
al. 
(2023a) 
Revenue 
management 
JOM 
Bertsimas 
et 
al. 
(2022) 
Hospital 
MSOM 
Wu 
et 
al. 
(2021) 
Social 
media 
ISR 
Erel 
et 
al. 
(2021) 
Director 
selection 
RFS 


Notes: 
MISQ: 
Management 
Information 
Systems 
Quarterly; 
POM: 
Production 
and 
Operations 
Management; 
ISR: 
Information 
Systems 
Research; 
MS: 
Management 
Science
; 
RFS: 
The 
Review 
of 
Financial 
Studies; 
DS: 
Decision 
Sciences; 
JOM: 
Journal 
of 
Operations 
Management; 
MSOM: 
Manufacturing 
& 
Service 
Operations 
Management
; 
OR: 
Operations 
Research; 
RFS: 
The 
Review 
of 
Financial 
Studies. 


investigate 
the 
eect 
of 
eBay 
Machine 
Translation, 
an 
AI-driven 
translation 
tool, 
on 
cross-border 
transactions. 
They 
nd 
that 
it 
boosts 
exports 
to 
specic 
regions, 
including 
Latin 
America, 
Italy, 
and 
Russia 
by 
improving 
translation 
quality. 
Cheng 
et 
al. 
(2020) 
analyze 
the 
benets 
of 
implementing 
intelligent 
transportation 
systems 
in 
99 
U.S. 
urban 
areas, 
highlighting 
substantial 
reductions 
in 
trac 
congestion, 
fossil 
fuel 
usage, 
and 
CO2 
emissions. 
Deng 
et 
al. 
(2023) 
nd 
that 
the 
adoption 
of 
intelligent 
image 
processing-based 
shelf 
monitoring 
in 
a 
fast-moving 
consumer 
goods 
manufacturer 
signicantly 
boosts 
its 
product 
sales. 
Spring 
et 
al. 
(2022) 
examine 
the 
deployment 
of 
AI 
systems 
in 
legal 
and 
accounting 
rms, 
revealing 
that 
such 
technologies 
elevate 
performance 
by 
reallocating 
human 
resources 
from 
mundane 
tasks 
to 
more 
strategic 
advisory 
roles. 





2.1.3. 
Algorithm. 
Machine 
learning 
and 
deep 
learning 
algorithms 
exhibit 
powerful 
predictive 
capabilities 
and 
hold 
signicant 
potential 
for 
various 
business 
decision-making 
scenarios. 
Panel 
C 
of 
Table 
1 
lists 
the 
studies 
that 
have 
implemented 
AI 
algorithms 
in 
real-world 
scenarios. 
For 
example, 
Ferreira 
et 
al. 
(2016) 
develop 
a 
machine 
learning 
algorithm 
based 
on 
modied 
regression 
trees 
to 
predict 
demand 
for 
new 
products 
and 
translate 
the 
demand 
forecasts 
into 
pricing. 
Results 
from 
a 
eld 
experiment 
by 
collaborating 
with 
an 
online 
retailer, 
Rue 
La 
La, 
illustrate 
a 
prot 
increase 
of 
approximately 
9.7%. 
In 
a 
similar 
vein, 
Shi 
et 
al. 
(2020) 
develop 
a 
predictive 
algorithm 
based 
on 
the 
random 
forest 
to 
manage 
inventory 
in 
overseas 
warehouses 
for 
a 
Chinese 
fashion 
retailer, 
demonstrating 
that 
the 
application 
of 
this 
algorithm 
in 
the 
rm 
signicantly 
reduces 
costs 
by 
20%. 
Senoner 
et 
al. 
(2022) 
introduce 
an 
innovative 
data-driven 
decision 
model 
employing 
explainable 
articial 
intelligence 
for 
quality 
management, 
which 
has 
been 
shown 
to 
enhance 
manufacturing 
quality 
and 
reduce 
yield 
loss 
by 
21.7% 
in 
collaboration 
with 
a 
high-power 
semiconductor 
manufacturer. 
Chen 
et 
al. 
(2023a) 
develop 
a 
discount 
recommendation 
approach 
based 
on 
reinforcement 
learning 
to 
help 
a 
budget 
hotel 
chain 
attract 
customers 
and 
demonstrate 
its 
superior 
performance 
by 
improving 
hotels’ 
revenue 
per 
available 
room 
in 
a 
eld 
experiment. 
Feldman 
et 
al. 
(2022) 
contrast 
machine 
learning 
algorithms 
against 
the 
traditional 
statistical 
approach 
of 
the 
multinomial 
logit 
(MNL) 
model 
in 
optimizing 
product 
displays 
on 
Tmall 
and 
Taobao. 
Yet, 
their 
large-scale 
eld 
experiment 
indicates 
that 
the 
MNL 
approach 
yields 
a 
28% 
increase 
in 
revenue 
per 
customer 
visit 
compared 
to 
the 
machine-learning 
method. 
Moreover, 
studies 
consistently 
demonstrate 
the 
superior 
performance 
of 
AI 
algorithms 
in 
real-world 
applications 
such 
as 
optimizing 
the 
selection 
of 
board 
directors 
for 
public 
rms 
(Erel 
et 
al. 
2021), 
detecting 
false 
information 
on 
social 
media 
(Wu 
et 
al. 
2021), 
and 
predicting 
patient 

ows 
in 
hospitals 
(Bertsimas 
et 
al. 
2022). 
2.2. 
AI-Human 
Interaction 
2.2.1. 
Assistant. 
AI 
can 
assist 
human 
by 
simplifying, 
speeding 
up, 
or 
taking 
over 
tasks 
that 
are 
routine 
and 
laborious 
without 
participating 
in 
the 
process 
of 
decision-making. 
Panel 
A 
of 
Table 
2 
presents 
the 
related 
literature 
of 
AI 
assistant. 
For 
example, 
Kim 
et 
al. 
(2022) 
identify 
signi
cant 
enhancements 
in 
students’ 
academic 
outcomes 
when 
tutors 
are 
supported 
by 
AI-generated 
diagnoses 
of 
students’ 
learning 
needs. 
Ko 
et 
al. 
(2023) 
reveal 
a 
signicant 
increase 
in 
students’ 
engagement 
frequency 
during 
the 
COVID-19 
pandemic, 
after 
adopting 
an 
AI-based 
educational 
application. 
Moreover, 
in 
the 
realm 
of 
specialized 
training, 
Gaessler 
and 
Piezunka 
(2023) 
nd 
that 
AI 
can 
serve 
as 
an 
eective 
training 
tool 
for 
chess 
players 
to 
enhance 
their 
strategic 
decision-
making 
by 
substituting 
for 
scarce 
human 
training 
partners. 
Furman 
and 
Teodoridis 
(2020) 
nd 
that 
automation 
technologies 
signicantly 
enhance 
the 
generation 
of 
novel 
ideas 
among 
researchers 
by 
reducing 
the 
cost 
of 
executing 
tasks. 
Chen 
et 
al. 
(2022) 
show 
positive 
eects 
of 
AI 
knowledge 



systems 
on 
improving 
workers’ 
job 
performance 
in 
three 
dierent 
application 
contexts. 
Bell 
et 
al. 
(2024) 
examine 
the 
ecacy 
of 
various 
AI 
algorithms 
in 
aiding 
experts 
to 
lter 
ideas 
in 
crowdsourcing 
contests. 
Wang 
et 
al. 
(2023c) 
reveal 
that 
AI 
aids 
signicantly 
increase 
workers’ 
productivity 
in 
medical 
chart 
coding 
tasks, 
with 
junior 
employees 
or 
those 
with 
specic 
task-based 
expertise 
beneting 
more 
from 
AI 
assistance 
than 
their 
senior 
counterparts. 
In 
the 
nancial 
investment 
area, 
Ge 
et 
al. 
(2021) 
reveal 
that 
investors 
adhering 
to 
AI 
advisors’ 
recommendations 
outperform 
others 
on 
peer-to-peer 
lending 
platforms. 
Liu 
et 
al. 
(2024) 
demonstrate 
that 
lenders 
utilizing 
AI 
assistant 
experience 
lower 
delinquency 
rates. 


While 
extensive 
literature 
highlights 
the 
positive 
eects 
of 
AI 
assistance, 
some 
studies 
present 
opposite 
results. 
Fugener 
et 
al. 
(2021) 
observe 
that 
groups 
using 
AI 
assistance 
in 
image 
annotation 
tasks 
underperform 
compared 
to 
those 
operating 
without 
AI, 
attributing 
to 
the 
reduction 
of 
human 
unique 
knowledge 
after 
using 
AI 
assistance. 
Similarly, 
Krakowski 
et 
al. 
(2023) 
reveal 
the 


Table 
2 
Literature 
about 
AI 
Assistant 
and 
AI 
Collaborator 


Literature 
Application 
Context 
Journal 
Panel 
A: 
Assistant 
Kim 
et 
al. 
(2022) 
Ko 
et 
al. 
(2023) 
Gaessler 
and 
Piezunka 
(2023) 
Furman 
and 
Teodoridis 
(2020) 
Chen 
et 
al. 
(2022) 
Liu 
et 
al. 
(2024) 
Ge 
et 
al. 
(2021) 
Bell 
et 
al. 
(2024) 
Wang 
et 
al. 
(2023c) 
Fugener 
et 
al. 
(2021) 
Krakowski 
et 
al. 
(2023) 
Home 
tutoring 
Remote 
education 
Chess 
Knowledge 
production 
Knowledge 
production 
Lending 
Lending 
Idea 
screening 
Medical 
chart 
coding 
Image 
annotation 
Chess 
JMR 
MS 
SMJ 
OS 
ISR 
ISR 
ISR 
MKS 
MS 
MISQ 
SMJ 


Panel 
B: 
Collaborator 


Karlinsky-Shichor 
and 
Netzer 
(2024) 
Sales 
activities 
MKS 
Fugener 
et 
al. 
(2022) 
Image 
annotation 
ISR 
Luo 
et 
al. 
(2021) 
Sales 
skill 
training 
JM 
Tong 
et 
al. 
(2021) 
Performance 
feedback 
SMJ 
Man 
Tang 
et 
al. 
(2022) 
– 
AMJ 
Boyacı 
et 
al. 
(2024) 
– 
MS 
Sturm 
et 
al. 
(2021) 
Organizational 
learning 
MISQ 
Waardenburg 
et 
al. 
(2022) 
Crime 
detection 
OS 
Te'eni 
et 
al. 
(2023) 
Text 
classication 
MS 
Van 
den 
Broek 
et 
al. 
(2021) 
– 
MISQ 
Bendoly 
et 
al. 
(2023) 
Product 
design 
DS 


Notes: 
JMR: 
Journal 
of 
Marketing 
Research; 
MS: 
Management 
Science; 
SMJ: 
Strategic 
Management 
Journal; 
OS: 
Organization 
Science; 
ISR: 
Information 
Systems 
Research; 
MKS: 
Marketing 
Science; 
MISQ: 
Management 
Information 
Systems 
Quarterly; 
JM: 
Journal 
of 
Marketing; 
AMJ: 
Academy 
of 
Management 
Journal. 



Author: 
AI 
in 
Business 

disrupts 
traditional 
competitive 
skills 
among 
chess 
players, 
presenting 
a 
direct 
contradiction 
to 
the 
positive 
outcomes 
noted 
by 
Gaessler 
and 
Piezunka 
(2023). 


2.2.2. 
Collaborator. 
AI 
can 
engage 
in 
the 
decision-making 
process 
through 
dynamic 
interactions 
with 
human 
counterparts. 
Panel 
B 
of 
Table 
2 
reports 
the 
related 
literature. 
For 
example, 
Karlinsky-Shichor 
and 
Netzer 
(2024) 
introduce 
a 
hybrid 
human-machine 
decision-making 
model 
in 
a 
B2B 
(business-to-business) 
retail 
setting, 
demonstrating 
that 
integrating 
automated 
pricing 
models 
with 
salesperson 
insights 
generates 
prots 
signicantly 
higher 
than 
either 
the 
model 
or 
the 
salespeople. 
Similarly, 
Fugener 
et 
al. 
(2022) 
show 
that 
human-AI 
collaboration 
surpasses 
individual 
eorts 
of 
either 
in 
classication 
tasks. 
Luo 
et 
al. 
(2021) 
assess 
the 
impact 
of 
AI 
coaches 
on 
sales 
agents’ 
performance, 
identifying 
an 
inverted-U 
relationship 
where 
middle-ranked 
agents 
exhibit 
the 
most 
signicant 
performance 
enhancements. 
Tong 
et 
al. 
(2021) 
investigate 
AI's 
role 
in 
delivering 
performance 
feedback 
in 
call 
centers, 
revealing 
simultaneous 
positive 
and 
negative 
impacts 
on 
workers’ 
productivity. 
Man 
Tang 
et 
al. 
(2022) 
demonstrate 
that 
conscientious 
employees 
might 
experience 
decreased 
eectiveness 
when 
working 
alongside 
AI 
systems 
that 
possess 
autonomous 
decision-making 
capabilities. 
Moreover, 
Boyacı 
et 
al. 
(2024) 
develop 
an 
analytical 
model 
to 
explore 
the 
dynamics 
between 
human 
decision-makers 
and 
AI, 
revealing 
that 
although 
AI 
can 
improve 
decision 
accuracy 
overall, 
it 
may 
also 
elevate 
specic 
types 
of 
errors 
and 
cognitive 
burdens, 
particularly 
under 
conditions 
such 
as 
time 
pressure 
or 
multitasking. 
Sturm 
et 
al. 
(2021) 
demonstrate 
the 
positive 
eects 
of 
integrating 
human 
labor 
with 
AI 
technologies 
on 
organizational 
learning 
and 
innovation, 
particularly 
in 
dynamic 
environments. 
Waardenburg 
et 
al. 
(2022) 
investigate 
the 
deployment 
of 
learning 
algorithms 
by 
Dutch 
police 
and 
highlight 
the 
critical 
role 
of 
algorithmic 
brokers 
in 
interpreting 
AI's 
predictive 
results 
in 
criminal 
incidents. 
In 
addition, 
several 
studies 
discuss 
the 
human-in-the-loop 
design 
in 
AI, 
emphasizing 
the 
role 
of 
human-AI 
collaboration 
throughout 
the 
lifecycle 
of 
AI 
systems. 
For 
example, 
Te'eni 
et 
al. 
(2023) 
develop 
an 
abstract 
conguration 
for 
reciprocal 
human-machine 
learning 
that 
enables 
iterative 
learning 
cycles 
between 
humans 
and 
machines. 
Van 
den 
Broek 
et 
al. 
(2021) 
delve 
into 
the 
integration 
of 
machine 
learning 
in 
organizations 
through 
a 
two-year 
ethnographic 
study, 
highlighting 
the 
interdependence 
of 
AI 
developers 
and 
domain 
experts 
in 
developing 
a 
hiring 
AI 
tool. 
Bendoly 
et 
al. 
(2023) 
show 
that 
the 
interaction 
between 
designers 
and 
generative 
design 
tools 
creates 
a 
double-loop 
learning 
cycle, 
enhancing 
resilience 
and 
providing 
a 
competitive 
edge 
through 
a 
unique 
human-AI 
symbiosis 
for 
rms 
in 
response 
to 
exogenous 
shocks, 
such 
as 
COVID-19. 


2.2.3. 
Competitor. 
AI 
can 
even 
be 
a 
competitor. 
Lysyakov 
and 
Viswanathan 
(2023) 
examine 
the 
impact 
of 
AI 
competition 
on 
human 
decision-making 
by 
analyzing 
reactions 
to 
an 
AI 
system 
introduced 
for 
simple 
logo 
designs 
on 
a 
crowdsourcing 
platform. 
They 
observe 
that 
while 
successful 



designers 
enhance 

response 
to 
AI 
competition, 
less 
successful 
ones 
merely 
increase 
their 
participation 
rate 
without 
improving 
their 
work 
quality. 
The 
competition 
pressure 
from 
AI 
is 
serious 
because 
numerous 
studies 
has 
found 
that 
AI 
outperforms 
humans 
(Table 
3). 
For 
example, 
Fu 
et 
al. 
(2021) 
use 
the 
data 
from 
Prosper.com 
to 
train 
an 
AI 
model 
and 
compares 
the 
investing 
performance 
of 
humans 
and 
AI, 
suggesting 
that 
the 
AI 
system 
surpasses 
crowd 
investors 
in 
accurately 
forecasting 
loan 
default 
probabilities. 
Liu 
et 
al. 
(2023a) 
nd 
that 
clients 
using 
robo-advisors 
during 
the 
nancial 
upheaval 
of 
2020 
incur 
signicantly 
fewer 
losses 
than 
those 
with 
traditional 
human 
investment 
strategies. 
Similarly, 
Coleman 
et 
al. 
(2022) 
show 
that 
Robo-Analysts’ 
investment 
recommendations 
not 
only 
exhibit 
a 
more 
balanced 
distribution 
and 
less 
bias 
towards 
glamour 
stocks 
than 
human 
analysts, 
but 
also 
yield 
substantial 
long-term 
investment 
benets. 
Pickard 
et 
al. 
(2020) 
examine 
the 
utility 
of 
automated 
AI 
interviewers 
in 
the 
context 
of 
auditing, 
revealing 
that 
it 
performs 
similarly 
or 
outperforms 
human 
interviewers 
when 
it 
closely 
resembles 
the 
interviewee 
in 
facial 
and 
vocal 
characteristics. 
Notably, 
their 
results 
also 
show 
an 
increase 
of 
up 
to 
32% 
in 
the 
likelihood 
of 
employees 
disclosing 
breaches 
in 
internal 
controls 
when 
interviewed 
by 
an 
AI, 
compared 
to 
human 
interviewers. 
Clarke 
et 
al. 
(2020) 
explore 
the 
role 
of 
machine 
learning 
techniques 
in 
identifying 
fake 
news 
in 
nancial 
markets, 
suggesting 
that 
AI 
algorithms 
can 
successfully 
identify 
fake 
news 
that 
human 
article 
commenters 
failed. 
Aubry 
et 
al. 
(2023) 
investigate 
the 
role 
of 
AI 
in 
auctions, 
suggesting 
that 
the 
trained 
AI 
algorithm 
predicts 
auction 
prices 
signicantly 
better 
than 
the 
auction 
house. 
Similarly, 
Khern-am 
nuai 
et 
al. 
(2024) 
examine 
the 
impact 
of 
AI-based 
versus 
crowd-based 
systems 
on 
the 
selection 
of 
cover 
images 
for 
restaurants 
on 
a 
review 
platform, 
demonstrating 
the 
superior 
performance 
of 
AI, 
particularly 
for 
those 
with 
fewer 
photos, 
lower 
ratings, 
and 
initial 
lower 
engagement. 
Reisenbichler 
et 
al. 
(2022) 
reveal 
that 
using 
AI 
algorithms 
in 
content 
marketing 
not 
only 
generates 
search 
engine 
optimization 
content 
on 
par 
with 
that 
produced 
by 
expert 
humans, 
but 
also 
elevates 
search 
engine 
visibility 
while 
curtailing 
production 
costs. 


However, 
AI 
does 
not 
outperform 
humans 
in 
all 
aspects. 
Peukert 
et 
al. 
(2023) 
nd 
that 
automated 
algorithmic 
recommendations 
generally 
outperform 
human 
curation 
in 
the 
context 
of 
online 
news, 
yet 
human 
curation 
excels 
when 
personal 
data 
is 
scarce 
and 
user 
preferences 
vary 
greatly. 
Liu 
(2022) 
nd 
that 
while 
machine 
learning 
models 
excel 
in 
processing 
hard 
information, 
loan 
ocers 
are 
more 
adept 
at 
gathering 
soft 
information 
than 
AI 
machines. 
Karlinsky-Shichor 
and 
Netzer 
(2024) 
identify 
that 
although 
using 
AI 
algorithms 
to 
price 
in 
a 
B2B 
aluminum 
retailer 
generally 
enhances 
its 
protability, 
human 
salespeople 
outperform 
in 
generating 
prots 
when 
dealing 
with 
unique 
or 
complex 
quotations. 
Luo 
et 
al. 
(2019) 
assess 
the 
eects 
of 
chatbots 
on 
sales 
performance 
within 
a 
nancial 
services 
rm, 
revealing 
that 
AI 
chatbots 
match 
the 
eciency 
of 
skilled 
employees 
and 
quadruple 
that 
of 
novices 
in 
sales 
when 
customers 
are 
unaware 
they 
are 
interacting 
with 
a 



Author: 
AI 
in 
Business 
e 
about 
AI 
competition 


NA 
Lysyakov 
and 
Viswanathan 
(2023) 
Logo 
design 
ISR 
AI 
Reisenbichler 
et 
al. 
(2022) 
Content 
marketing 
MKS 
AI 
Fu 
et 
al. 
(2021) 
Lending 
decisions 
ISR 
AI 
Liu 
et 
al. 
(2023a) 
Investment 
advice 
POM 
AI 
Coleman 
et 
al. 
(2022) 
Investment 
advice 
AR 
AI 
Aubry 
et 
al. 
(2023) 
Price 
prediction 
JF 
AI 
Pickard 
et 
al. 
(2020) 
Interview 
AR 
AI 
Clarke 
et 
al. 
(2020) 
Fake 
news 
detection 
ISR 
AI 
Khern-am 
nuai 
et 
al. 
(2024) 
Cover 
image 
selection 
MSOM 
Contingent 
Peukert 
et 
al. 
(2023) 
Online 
news 
selection 
MS 
Contingent 
Liu 
(2022) 
Loan 
information 
process 
JAR 
Contingent 
Karlinsky-Shichor 
and 
Netzer 
(2024) 
Sales 
activities 
MKS 
Equal 
Wu 
et 
al. 
(2023) 
Trust 
games 
MS 
Equal 
Luo 
et 
al. 
(2019) 
Telemarketing 
MKS 
Human 
Cui 
et 
al. 
(2022) 
Procurement 
MSOM 
Human 
Lebovitz 
et 
al. 
(2021) 
Hospital 
MISQ 


Notes: 
ISR: 
Information 
Systems 
Research; 
MKS: 
Marketing 
Science; 
POM: 
Production 
and 
Operations 
Management; 
AR: 
The 
Accounting 
Review; 
JF: 
The 
Journal 
of 
Finance; 
MS: 
Management 
Science; 
JAR: 
Journal 
of 
Accounting 
Research; 
MSOM: 
Manufacturing 
& 
Service 
Operations 
Management; 
MISQ: 
Managemen
t 
Information 
Systems 
Quarterly. 


chatbot. 
Wu 
et 
al. 
(2023) 
develop 
deep 
neural 
network-based 
AI 
agents 
to 
play 
the 
trust 
game, 
discovering 
that 
the 
performance 
behavior 
of 
AI 
agents 
is 
similar 
to 
human 
decisions 
under 
certain 
conditions. 
Cui 
et 
al. 
(2022) 
conduct 
a 
eld 
experiment 
on 
a 
B2B 
sourcing 
platform 
to 
compare 
the 
quotations 
obtained 
by 
AI 
and 
human 
procurement 
agents. 
Their 
ndings 
reveal 
that 
rms 
employing 
solely 
automated 
chatbots 
for 
procurement 
are 
quoted 
higher 
prices 
compared 
to 
those 
using 
human 
agents, 
and 
the 
amalgamation 
of 
AI 
with 
chatbots 
results 
in 
the 
acquisition 
of 
the 
most 
competitive 
quotes. 
Lebovitz 
et 
al. 
(2021) 
investigate 
the 
performance 
of 
ve 
AI 
tools 
in 
hospitals, 
revealing 
that 
none 
of 
them 
met 
expectations. 


3. 
Human 
Perception 
of 
AI 
Tables 
4 
lists 
the 
literature 
on 
human 
perception 
of 
AI. 
Van 
Donselaar 
et 
al. 
(2010) 
analyze 
the 
behavior 
of 
retail 
store 
managers 
within 
a 
supermarket 
chain 
using 
an 
automated 
inventory 
management 
system 
and 
nd 
that 
managers 
often 
disregard 
the 
system's 
ordering 
recommendations. 
Leung 
et 
al. 
(2018) 
highlight 
that 
while 
automation 
machines 
present 
clear 
advantages, 
they 
are 
less 
appealing 
to 
consumers 
motivated 
by 
identity-driven 
purchases. 
de 
Bellis 
et 
al. 
(2023) 
nd 
that 
autonomous 
technologies 
meet 
resistance 
from 
consumers 
who 
value 
manual 
labor 
as 
a 
source 
of 
meaning. 
Moreover, 
multiple 
studies 
have 
revealed 
that 
human-like 
attributes, 
such 
as 
emotional 
expression 
in 
automated 
machines, 
might 
aect 
human 
perceptions. 
For 
example, 
Bergner 
et 
al. 
(2023) 
demonstrate 
that 
chatbots 
designed 
with 
human 
conversational 
attributes, 
such 
as 
turn-taking, 
turn 
initiation, 
and 
grounding 
between 
turns, 
improve 
the 
consumer's 
perception 
of 





brand 
humanness, 
hips 
and 
positively 
aects 
brand 

al. 
(2023) 
nd 
that 
emotions 
expressed 
by 
chatbots 
are 
perceived 
as 
less 
genuine 
than 
those 
expressed 
by 
humans, 
leading 
to 
increased 
expectation 
discrepancies. 
In 
a 
similar 
vein, 
Crolic 
et 
al. 
(2022) 
uncover 
that 
anthropomorphic 
customer 
service 
chatbots 
can 
negatively 
aect 
satisfaction, 
rm 
evaluation, 
and 
purchase 
intentions 
when 
customers 
are 
angry 
at 
the 
outset 
of 
the 
interaction. 
In 
addition, 
Cohn 
et 
al. 
(2022) 
show 
that 
individuals 
are 
more 
likely 
to 
cheat 
when 
interacting 
with 
a 
machine 
compared 
to 
a 
human, 
regardless 
of 
whether 
the 
machine 
is 
equipped 
with 
human 
features. 
Algorithm 
Aversion. 
There 
is 
a 
rich 
literature 
on 
algorithm 
aversion 
(Dietvorst 
et 
al. 
2015); 
see 
Table 
4 
for 
a 
summary. 
Tan 
and 
Staats 
(2020) 
show 
that 
restaurant 
hosts 
often 
ignore 
algorithmic 
advice 
on 
customer-to-waiter 
assignments. 
Sun 
et 
al. 
(2022) 
nd 
that 
warehouse 
packing 
employees 
frequently 
deviate 
from 
algorithmic 
guidance 
regarding 
package 
organization, 
which 
prolongs 
packing 
times 
and 
diminishes 
operational 
eciency. 
Similarly, 
Commerford 
et 
al. 
(2022) 
reveal 


Table 
4 
Literature 
about 
human 
perceptions 
of 
AI 


Perception 
Literature 
Context 
Journal 
Negative 
Van 
Donselaar 
et 
al. 
(2010) 
Ordering 
management 
MS 
Negative 
Leung 
et 
al. 
(2018) 
Lab 
experiment 
JMR 
Negative 
de 
Bellis 
et 
al. 
(2023) 
Lab 
experiment 
JM 
Positive 
Bergner 
et 
al. 
(2023) 
Customer 
service 
JCR 
Negative 
Han 
et 
al. 
(2023) 
Customer 
service 
ISR 
Negative 
Crolic 
et 
al. 
(2022) 
Customer 
service 
JM 
Negative 
Cohn 
et 
al. 
(2022) 
Lab 
experiment 
MS 
Algorithm 
Aversion 
Negative 
Tan 
and 
Staats 
(2020) 
Customer 
assignments 
POM 
Negative 
Sun 
et 
al. 
(2022) 
Package 
advice 
MS 
Negative 
Commerford 
et 
al. 
(2022) 
Auditing 
JAR 
Negative 
de 
Vericourt 
and 
Gurkan 
(2023) 
High-stakes 
decisions 
MS 
Negative 
Longoni 
et 
al. 
(2023) 
Public 
service 
JMR 
Negative 
Lebovitz 
et 
al. 
(2022) 
Healthcare 
OS 
Negative 
Longoni 
et 
al. 
(2019) 
Healthcare 
JCR 
Negative 
Kyung 
and 
Kwon 
(2022) 
Healthcare 
POM 
Negative 
Costello 
et 
al. 
(2020) 
Lending 
decisions 
JAE 
Negative 
Habel 
et 
al. 
(2023) 
Sales 
activities 
JMR 
Negative 
Liu 
et 
al. 
(2023b) 
Ride-hailing 
platform 
MS 
Negative 
Gnewuch 
et 
al. 
(2023) 
Customer 
service 
ISR 
Positive 
Holzmeister 
et 
al. 
(2023) 
Investment 
decisions 
MS 
Positive 
Bai 
et 
al. 
(2022) 
Task 
assignment 
MSOM 
Positive 
Srinivasan 
and 
Sarial-Abi 
(2021) 
Brand 
harm 
crisis 
JM 


Notes: 
MS: 
Management 
Science; 
JMR: 
Journal 
of 
Marketing 
Research; 
JM: 
Journal 
of 
Marketing
; 
JCR: 
Journal 
of 
Consumer 
Research; 
ISR: 
Information 
Systems 
Research; 
POM: 
Productio
n 
and 
Operations 
Management; 
JAR: 
Journal 
of 
Accounting 
Research; 
OS: 
Organization 
Science; 
JAE: 
Journal 
of 
Accounting 
Economics; 
MSOM: 
Manufacturing 
& 
Service 
Operations 
Management. 





algorithm 
aversion 
in 
the 
auditing 
eld, 
noting 
that 
auditors 
are 
less 
inclined 
to 
revise 
their 
estimates 
when 

opposed 
to 
a 
human 
expert. 
Liu 
et 
al. 
(2023b) 
explore 
the 
algorithm 
aversion 
phenomenon 
of 
drivers 
in 
a 
ride-hailing 
platform, 
suggesting 
that 
drivers’ 
aversion 
is 
signicantly 
aected 
by 
their 
past 
experiences 
and 
peer 
actions. 
Gnewuch 
et 
al. 
(2023) 
reveal 
that 
disclosing 
human 
involvement 
in 
hybrid 
service 
agents 
combining 
AI 
and 
humans 
results 
in 
more 
customers 
adopting 
human-oriented 
communication 
styles, 
showing 
the 
aversion 
of 
AI 
agents. 
Kyung 
and 
Kwon 
(2022) 
investigate 
the 
perception 
of 
AI 
on 
preventive 
healthcare, 
suggesting 
that 
users’ 
acceptance 
and 
behavioral 
change 
are 
lower 
compared 
to 
interventions 
by 
human 
experts. 
Costello 
et 
al. 
(2020) 
conduct 
a 
eld 
experiment 
introducing 
a 
slider 
feature 
on 
a 
lending 
platform, 
which 
allows 
lenders 
to 
modify 
AI 
recommendations. 
Their 
results 
show 
that 
lenders 
in 
the 
treatment 
group 
exhibit 
an 
18% 
larger 
increase 
in 
their 
deviation 
from 
AI 
recommendation. 


The 
literature 
also 
explores 
the 
mechanism 
behind 
algorithm 
aversion. 
de 
Vericourt 
and 
Gurkan 
(2023) 
build 
a 
theoretical 
model 
to 
analyze 
how 
verication 
bias 
aects 
the 
adoption 
and 
trust 
of 
human 
decision-makers 
in 
AI 
recommendations 
in 
high-stakes 
decisions. 
Habel 
et 
al. 
(2023) 
explore 
the 
factors 
that 
can 
mitigate 
or 
intensify 
salespeople's 
aversion 
to 
algorithms, 
revealing 
the 
important 
role 
of 
salespeople's 
realistic 
expectations 
regarding 
the 
algorithm's 
accuracy. 
Longoni 
et 
al. 
(2023) 
investigate 
public 
reactions 
to 
AI 
failures 
across 
various 
sectors, 
discovering 
that 
errors 
made 
by 
algorithms 
tend 
to 
be 
more 
broadly 
generalized 
than 
those 
committed 
by 
humans. 
In 
the 
healthcare 
industry, 
Lebovitz 
et 
al. 
(2022) 
highlight 
the 
opacity 
of 
AI 
tools 
as 
a 
signicant 
barrier 
to 
eective 
human-AI 
collaboration 
in 
diagnostic 
radiology. 
Similarly, 
Longoni 
et 
al. 
(2019) 
explore 
the 
reasons 
why 
consumers 
are 
reluctant 
to 
adopt 
AI 
in 
healthcare, 
nding 
that 
concerns 
over 
AI's 
inability 
to 
recognize 
individual 
uniqueness 
lead 
to 
reduced 
willingness 
to 
use 
AI-provided 
healthcare. 


While 
much 
of 
the 
literature 
identies 
negative 
human 
perceptions 
of 
AI, 
several 
studies 
highlight 
the 
positive 
attitude. 
For 
example, 
Bai 
et 
al. 
(2022) 
examine 
the 
impact 
of 
algorithmic 
versus 
human-based 
task 
assignments 
on 
perceptions 
of 
fairness 
and 
productivity 
through 
a 
eld 
experiment. 
They 
nd 
that 
tasks 
assigned 
by 
algorithms 
are 
perceived 
as 
fairer, 
leading 
to 
enhanced 
productivity. 
Srinivasan 
and 
Sarial-Abi 
(2021) 
explore 
consumer 
reactions 
to 
brand 
harm 
crises 
caused 
by 
algorithmic 
errors 
and 
human 
errors, 
revealing 
that 
consumers 
respond 
less 
negatively 
to 
errors 
made 
by 
algorithms 
than 
those 
made 
by 
humans. 
Holzmeister 
et 
al. 
(2023) 
discover 
that 
clients 
prefer 
to 
delegate 
their 
investment 
decisions 
to 
algorithms 
rather 
than 
nance 
professionals 
in 
a 
lab 
experiment. 
Dynamic 
Perception. 
The 
human 
perception 
of 
AI 
can 
be 
dynamic 
and 
are 
contingent 
upon 
various 
factors; 
see 
Table 
5 
for 
a 
list 
of 
the 
literature. 





First, 
human 
perceptions 
of 
AI 
are 
in
uenced 
by 
the 
features 
of 
the 
AI 
itself. 
Castelo 
et 
al. 
(2023) 
show 
that 
consumers’ 

as 
favorable 
as, 
or 
even 
superior 
to, 
those 
to 
human 
services, 
if 
the 
bots 
can 
provide 
superior 
service. 
Bauer 
et 
al. 
(2023) 
highlight 
the 
importance 
of 
feature-based 
explanations 
of 
AI 
systems 
in 
altering 
the 
way 
people 
use 
AI. 
Lehmann 
et 
al. 
(2022) 
reveal 
that 
the 
adoption 
of 
algorithmic 
advice 
by 
humans 
hinges 
not 
only 
on 
the 
algorithm's 
transparency 
and 
complexity 
but 
on 
its 
perceived 
appropriateness. 
Clegg 
et 
al. 
(2023) 
reveal 
that 
consumers 
generally 
prefer 
products 
with 
high-adaptive 
algorithms 
(i.e., 
those 
with 
higher 
intelligence 
like 
ChatGPT), 
compared 
with 
low-adaptive 
algorithms 
(i.e., 
pre-programmed 
algorithms). 
Bauer 
and 
Gill 
(2024) 
explore 
the 
impacts 
of 
disclosing 
algorithmic 
scoring 
processes 
on 
individuals’ 
behavior. 
Their 
experiments 
show 
that 
revealing 
incorrect 
algorithmic 
scores 
to 
individuals 
can 
shape 
their 
actions 
to 
align 
with 
these 
scores, 
thus 
causing 
self-fullling 
prophecies. 


Second, 
the 
perception 
is 
contingent 
on 
the 
specic 
application 
scenarios. 
Castelo 
et 
al. 
(2019) 
identify 
that 
algorithm 
aversion 
is 
weaker 
for 
tasks 
perceived 
as 
objective 
rather 
than 
subjective. 
Longoni 
and 
Cian 
(2022) 
reveal 
that 
preferences 
for 
AI-based 
recommendations 
are 
in
uenced 
by 
the 
tasks 
perceived 
with 
utilitarian 
and 
hedonic 
attributes. 
Yalcin 
et 
al. 
(2022) 
uncover 
that 
consumers 
react 
more 
favorably 
when 
positive 
decisions 
are 
made 
by 
humans 
rather 
than 
algorithms, 
but 
this 
disparity 
is 
not 
observed 
within 
negative 
decisions. 
In 
a 
similar 
vein, 
Garvey 
et 
al. 
(2023) 
reveal 
that 
consumers 
respond 
more 
positively 
to 
a 
human 
agent 
for 
a 
positive 
oer, 
whereas 
a 
negative 
oer 
is 
more 
tolerable 
when 
presented 
by 
AI, 
attributed 
to 
perceived 
lesser 
intent 
to 
harm. 
Adam 
et 
al. 
(2023) 
explore 
customer 
reactions 
to 
automated 
sales 
agents 
(ASAs) 
versus 
human 
sales 
agents 
(HSAs), 
revealing 
that 
while 
HSAs 
attract 
greater 
initial 
interest 
due 
to 
their 
social 
presence, 
ASAs 
are 
preferred 
when 
requiring 
customers’ 
contact 
information. 


Third, 
the 
human 
perception 
of 
AI 
also 
depends 
on 
individuals’ 
own 
characteristics. 
Ge 
et 
al. 
(2021) 
demonstrate 
that 
investors 
who 
have 
experienced 
more 
defaults 
during 
manual 
investing 
are 
more 
likely 
to 
deviate 
from 
the 
recommendations 
from 
AI 
advisors 
on 
peer-to-peer 
lending 
platforms. 
Kim 
et 
al. 
(2022) 
reveal 
that 
tutors 
with 
higher 
levels 
of 
education 
and 
experience 
are 
less 
inclined 
to 
employ 
AI 
assistance 
in 
the 
context 
of 
tutoring 
services. 
Similarly, 
Dai 
and 
Singh 
(2020) 
uncover 
that 
concerns 
about 
reputation 
and 
private 
knowledge 
lead 
highly 
skilled 
experts 
to 
avoid 
using 
AI 
tools 
in 
the 
medical 
decision-making 
processes, 
thereby 
dierentiating 
themselves 
from 
their 
less 
adept 
counterparts. 
Jussupow 
et 
al. 
(2021) 
investigate 
AI's 
in
uence 
on 
decision-
making 
in 
medical 
settings, 
revealing 
that 
physicians’ 
acceptance 
of 
AI 
advice 
hinges 
on 
complex 
cognitive 
evaluations. 
Moreover, 
Li 
et 
al. 
(2021b) 
demonstrate 
that 
a 
rm's 
adoption 
of 
AI 
is 
signicantly 
aected 
by 
the 
presence 
of 
a 
Chief 
Information 
Ocer 
and 
the 
diversity 
of 
its 
board's 
education 
and 
AI 
experience. 
Dietvorst 
et 
al. 
(2018) 
nd 
that 
allowing 
individuals 
to 
make 
minor 
adjustments 
to 
algorithm-generated 
forecasts 
notably 
increases 
their 
likelihood 
of 
adopting 
these 



Author: 
AI 
in 
Business 
e 
about 
dynamic 
perceptions 
of 
AI 


Perception 
contingent 
on 
Literature 
Context 
Journal 


Algorithm 
performance 
Castelo 
et 
al. 
(2023) 
Customer 
service 
JCR 

Lab 
experiment 
ISR 
Algorithm 
transparency 
and 
complexity 
Lehmann 
et 
al. 
(2022) 
– 
POM 
Algorithm 
adaptivity 
Clegg 
et 
al. 
(2023) 
Lab 
experiment 
JCR 
Algorithm 
transparency 
Bauer 
and 
Gill 
(2024) 
– 
ISR 
Communication 
contents 
Adam 
et 
al. 
(2023) 
Sales 
activities 
ISR 
Task 
types 
Yalcin 
et 
al. 
(2022) 
Lab 
experiment 
JMR 
Task 
types 
Longoni 
and 
Cian 
(2022) 
Product 
choice 
JM 
Oer 
types 
Garvey 
et 
al. 
(2023) 
Ticket 
resale 
JM 
Task 
objectivity 
Castelo 
et 
al. 
(2019) 
Lab 
experiment 
JMR 
Users’ 
education 
and 
experience 
Kim 
et 
al. 
(2022) 
Tutoring 
service 
JMR 
Users’ 
skill 
levels 
Dai 
and 
Singh 
(2020) 
Healthcare 
MKS 
Users’ 
investment 
levels 
Ge 
et 
al. 
(2021) 
Investment 
decisions 
ISR 
Board's 
background 
Li 
et 
al. 
(2021b) 
– 
MISQ 
Users’ 
cognition 
Jussupow 
et 
al. 
(2021) 
Healthcare 
ISR 
Human 
intervention 
Dietvorst 
et 
al. 
(2018) 
Lab 
experiment 
MS 
Human 
intervention 
Kawaguchi 
(2021) 
Product 
assortment 
MS 


Notes: 
JCR: 
Journal 
of 
Consumer 
Research; 
ISR: 
Information 
Systems 
Research; 
JMR: 
Journal 
of 
Marketin
g 
Research; 
JM: 
Journal 
of 
Marketing; 
MKS: 
Marketing 
Science; 
MISQ: 
Management 
Information 
Systems 
Quarterly; 
MS: 
Management 
Science. 


tools. 
Similarly, 
Kawaguchi 
(2021) 
observe 
that 
workers 
are 
more 
inclined 
to 
adhere 
to 
algorithmic 
advice 
when 
they 
can 
integrate 
their 
own 
forecasts 
into 
the 
algorithm. 


4. 
AI 
Behavior 
This 
section 
reviews 
the 
literature 
on 
algorithmic 
bias 
and 
algorithmic 
collusion; 
see 
Table 
6 
for 
a 
summary. 


4.1. 
Algorithmic 
Bias 
Algorithmic 
bias 
arises 
when 
algorithms 
make 
decisions 
that 
consistently 
disadvantage 
specic 
groups 
of 
people 
(Friis 
and 
Riley 
2023). 
This 
bias 
can 
lead 
to 
severe 
consequences 
when 
implemented 
in 
critical 
areas 
such 
as 
healthcare, 
criminal 
justice, 
and 
credit 
scoring. 
Lambrecht 
and 
Tucker 
(2019) 
reveal 
that 
algorithms 
governing 
job 
advertisement 
delivery 
can 
inadvertently 
lead 
to 
gender 
discrimination 
in 
ad 
viewership 
in 
terms 
of 
the 
science, 
technology, 
engineering, 
and 
math 
elds. 
Fuster 
et 
al. 
(2022) 
show 
that 
machine 
learning 
models 
disproportionately 
disadvantage 
Black 
and 
Hispanic 
borrowers 
using 
U.S. 
mortgage 
data. 
Similarly, 
Fu 
et 
al. 
(2021) 
provide 
evidence 
that 
machine 
learning 
algorithms 
can 
exhibit 
biases 
related 
to 
gender 
and 
race, 
even 
when 
not 
explicitly 
using 
these 
attributes 
as 
inputs 
in 
prediction 
model 
training. 
Kelley 
et 
al. 
(2022) 
investigate 
the 
impact 
of 
antidiscrimination 
laws 
on 
discrimination 
and 
protability 
within 
n-
tech 
lending. 
Their 
ndings 
suggest 
that 
laws 
banning 
the 
use 
of 
gender 
information 
inadvertently 
heighten 
discrimination 
while 
only 
marginally 
aecting 
protability. 
Zhang 
et 
al. 
(2021) 
examine 





the 
eects 

disparities, 
noting 
that 
despite 
a 
71.3% 
reduction 
in 
the 
daily 
income 
gap 
between 
White 
and 
Black 
hosts 
following 
algorithm 
adoption, 
the 
broader 
racial 
revenue 

rates 
among 
Black 
hosts. 
In 
addition, 
Choudhury 
et 
al. 
(2020) 
investigate 
prediction 
biases 
arising 
from 
human 
manipulation, 
showing 
that 
patent 
applicants 
can 
strategically 
modify 
content 
descriptions|by 
including 
irrelevant 
information 
or 
omitting 
relevant 
citations|to 
in
uence 
algorithmic 
decisions 
erroneously. 


Algorithmic 
bias 
poses 
signicant 
challenges, 
as 
human 
perceptions 
could 
swiftly 
shift 
from 
positive 
to 
negative 
upon 
revelations 
of 
discriminatory 
practices. 
Researchers 
have 
proposed 
solutions 
to 
address 
it. 
For 
example, 
Ahsen 
et 
al. 
(2019) 
introduce 
a 
bias-aware 
linear 
classication 
algorithm 
designed 
to 
correct 
biases 
in 
human-generated 
datasets, 
focusing 
particularly 
on 
the 
in
uence 
of 
clinical-risk 
information 
on 
radiologists’ 
assessments 
of 
mammograms. 
They 
nd 
that 
the 
bias-
aware 
algorithm 
can 
eectively 
reduce 
or 
eliminate 
bias 
under 
certain 
conditions, 
although 
its 
ecacy 
is 
contingent 
on 
the 
variance 
of 
the 
error 
caused 
by 
the 
bias. 
Samorani 
et 
al. 
(2022) 
propose 
a 
race-aware 
methodology 
to 
address 
the 
racial 
disparities 
arising 
from 
machine 
learning-based 
appointment 
scheduling 
systems. 
They 
nd 
that 
this 
approach 
eectively 
balances 
schedule 
eciency 
with 
fairness, 
eliminating 
racial 
wait 
time 
disparities 
without 
compromising 
overall 
schedule 
cost. 
Choudhury 
et 
al. 
(2020) 
emphasize 
the 
necessity 
of 
combining 
domain 
expertise 
and 
speci
c 
skills 
with 
machine 
learning 
technologies 
to 
mitigate 
biases, 
particularly 
those 
arising 
from 
human 
manipulation. 
In 
contrast, 
Rhue 
(2023) 
reveal 
that 
humans 
may 
reinforce 
emotion 
recognition 
AI 
inconsistencies 
on 
demographics 
due 
to 
anchoring 
eects, 
highlighting 
the 
challenges 
in 
correcting 
algorithmic 
bias 
by 
including 
human 
decisions. 
Moreover, 
Fu 
et 
al. 
(2021) 
propose 
a 
debiasing 
technique 
aimed 
at 
eliminating 
redundant 
encodings, 
thereby 
rendering 
algorithmic 
training 
input 
features 
independent 
of 
sensitive 
attributes 
like 
race. 
They 
show 
that 
while 
this 
method 
may 
slightly 
reduce 
prediction 
accuracy, 
it 
enhances 
the 
fairness 
of 
the 
algorithm. 
Kelley 
et 
al. 
(2022) 
demonstrate 
that 
machine 
learning 
models 
can 
signicantly 
mitigate 
discrimination 
through 
specic 
data 
management 
and 
modeling 
strategies, 
such 
as 
rebalancing 
gender 
distribution 
in 
training 
datasets 
and 
employing 
probabilistic 
gender 
proxy 
models. 
They 
demonstrate 
that 
this 
approach 
not 
only 
reduces 
bias 
but 
also 
maintains 
or 
even 
slightly 
enhances 
predictive 
accuracy 
and 
protability. 
However, 
the 
eectiveness 
of 
the 
\equal 
opportunity” 
model 
in 
addressing 
algorithmic 
bias 
is 
debated 
(Hardt 
et 
al. 
2016). 
Fu 
et 
al. 
(2022) 
critique 
this 
approach, 
arguing 
that 
while 
\equal 
opportunity” 
algorithms 
aim 
to 
enhance 
fairness, 
they 
may 
inadvertently 
disadvantage 
all 
parties, 
including 
those 
they 
are 
designed 
to 
protect. 
Through 
a 
theoretical 
model, 
they 
demonstrate 
that 
such 
fairness 
algorithms 
could 
reduce 
the 
overall 
accuracy 
of 
predictions 
due 
to 
the 
strategic 
behaviors 
of 
decision-makers, 
such 
as 
companies. 



17 
Table 
6 
Literature 
about 
AI 
behavior 
Bias 
Type 

discrimination 
Racial 
discrimination 
Gender 
and 
racial 
discrimination 
Gender 
discrimination 
Algorithmic 
bias 
Prediction 
bias 
Algorithmic 
bias 
Racial 
discrimination 
Algorithmic 
bias 
Panle 
B: 
Algorithmic 
Bias 
Lambrecht 

(2021) 
Fuster 
et 
al. 
(2022) 
Fu 
et 
al. 
(2021) 
Kelley 
et 
al. 
(2022) 
Rhue 
(2023) 
Choudhury 
et 
al. 
(2020) 
Ahsen 
et 
al. 
(2019) 
Samorani 
et 
al. 
(2022) 
Fu 
et 
al. 
(2022) 
Ads 
promotion 
Pricing 
Loan 
Loan 
Loan 
Emotion 
recognition 
Patent 
identication 
Healthcare 
Scheduling 
-
MS 
MKS 
JF 
ISR 
MSOM 
ISR 
SMJ 
ISR 
MSOM 
MS 
Algorithmic 
collusion 
Algorithmic 
collusion 
Algorithmic 
collusion 
Algorithmic 
collusion 
Panle 
B: 
Algorithmic 
Collusion 
Abada 
and 
Lambin 
(2023) 
Pricing 
Meylahn 
and 
denBoer 
(2022) 
Pricing 
Hansen 
et 
al. 
(2021) 
Pricing 
Loots 
and 
denBoer 
(2023) 
Pricing 
MS 
MSOM 
MKS 
POM 


Notes: 
MS: 
Management 
Science; 
MKS: 
Marketing 
Science; 
JF: 
The 
Journal 
of 
Finance; 
ISR: 
Information 
Systems 
Research; 
MSOM:Manufacturing 
& 
Service 
Operations 
Management; 
SMJ: 
Strategic 
Management 
Journal; 
POM: 
Production 
and 
Operations 
Management. 


4.2. 
Algorithmic 
Collusion 
An 
increasing 
number 
of 
rms 
have 
adopted 
pricing 
algorithms, 
which 
has 
caused 
concerns 
such 
as 
algorithmic 
collusion 
(Calvano 
et 
al. 
2020). 
Abada 
and 
Lambin 
(2023) 
indicate 
that 
independent 
machine-learning 
algorithms 
operating 
in 
dynamic 
markets 
can 
unintentionally 
learn 
collusive 
behaviors 
to 
maximize 
prots, 
often 
due 
to 
imperfect 
exploration. 
They 
suggest 
that 
regulatory 
interventions 
or 
the 
promotion 
of 
decentralized 
learning 
may 
prevent 
these 
outcomes 
and 
ensure 
market 
behaviors 
that 
align 
with 
socially 
benecial 
goals. 
Meylahn 
and 
denBoer 
(2022) 
explore 
the 
possibility 
of 
self-learning 
algorithms 
learning 
to 
collude 
in 
duopolies 
without 
violating 
competition 
laws. 
Their 
nding 
shows 
that 
algorithms 
can 
either 
converge 
to 
jointly 
maximize 
revenues 
or 
adopt 
competitive 
pricing 
based 
on 
the 
competitor's 
strategies, 
thus 
underlining 
the 
latent 
threat 
of 
algorithmic 
collusion. 
Furthermore, 
Hansen 
et 
al. 
(2021) 
provide 
evidence 
of 
algorithmic 
collusion 
in 
dynamic 
pricing 
scenarios, 
even 
when 
each 
algorithm 
(or 
rm) 
does 
not 
have 
access 
to 
competitors’ 
pricing 
strategies. 
Loots 
and 
denBoer 
(2023) 
investigate 
the 
interplay 
between 
pricing 
and 
demand 
learning 
in 
a 
duopolistic 
setting 
using 
a 
multinomial 
logit 
model, 
demonstrating 
that 
algorithms 
can 
learn 
to 
set 
prices 
well 
above 
competitive 
levels, 
thereby 
potentially 
undermining 
consumer 
welfare. 


5. 
Future 
Research 
Directions 
We 
propose 
ve 
future 
research 
directions, 
aimed 
at 
constructing 
a 
comprehensive 
research 
framework 
to 
guide 
scholars 
in 
this 
rapidly 
evolving 
landscape. 



Author: 
AI 
in 
Business 

Has 
AI 
Brought? 
Scholarly 
work 
has 
primarily 
focused 
on 
g 
simple, 
repetitive 
tasks 
due 
to 
the 
initial 
limitations 
of 
AI 
technologies. 
However, 
with 
the 
rapid 
advancement 
of 
AI, 
advanced 
AI 
systems 
are 
applied 
in 
increasingly 
complex 
scenarios. 
For 
example, 
growing 
rms 
(e.g., 
H&M, 
Airbnb, 
and 
Chevrolet) 
utilize 
large 
language 
model 
tools, 
such 
as 
ChatGPT, 
to 
engage 
more 
deeply 
in 
customer 
support 
and 
sales 
activities, 
potentially 
replacing 
human 
workers 
in 
these 
contexts. 
While 
previous 
studies 
have 
investigated 
the 
performance 
of 
chatbots, 
new 
chatbots 
powered 
by 
ChatGPT 
may 
provide 
entirely 
dierent 
interaction 
experiences 
for 
customers, 
potentially 
resulting 
in 
varied 
outcomes. 
Therefore, 
it 
is 
worthwhile 
to 
reexamine 
the 
impact 
of 
advanced 
AI 
in 
these 
application 
contexts. 
Moreover, 
AI 
tools 
are 
increasingly 
being 
integrated 
across 
various 
industries. 
Examples 
include 
ChatGPT 
in 
user-generated 
content 
platforms, 
Copilot 
in 
coding, 
Suno 
in 
music, 
Midjourney 
in 
imaging, 
and 
Sora 
in 
video, 
among 
others. 
Therefore, 
another 
important 
research 
question 
is 
to 
investigate 
the 
changes 
these 
advanced 
AI 
tools 
have 
brought 
to 
each 
industry 
and 
the 
professions 
within 
them. 


RQ2: 
How 
Humans 
and 
AI 
Work 
Together? 
AI 
and 
humans 
possess 
distinct 
qualities 
and 
capabilities 
(Cremer 
and 
Kasparov 
2021): 
AI-based 
systems 
are 
characterized 
by 
speed, 
accuracy, 
and 
consistent 
rationality, 
whereas 
humans 
exhibit 
intuitive, 
emotional, 
and 
culturally 
sensitive 
competencies. 
Therefore, 
it 
is 
critical 
to 
explore 
how 
AI 
can 
augment 
human 
intelligence 
in 
decision-
making 
processes, 
and 
how 
can 
humans 
and 
AI 
collaborate 
to 
enhance 
work 
eciency 
and 
improve 
productivity. 
Although 
some 
initial 
investigations 
have 
been 
conducted 
in 
this 
domain, 
signicant 
opportunities 
remain 
for 
future 
research 
considering 
the 
varying 
performance 
of 
AI 
in 
dierent 
application 
contexts 
(e.g., 
healthcare). 
For 
example, 
can 
AI 
tools 
(e.g., 
Med-PaLM 
developed 
by 
Google) 
assist 
physicians 
in 
conducting 
primary 
treatment 
work? 
Similarly, 
can 
physicians 
and 
AI 
collaborate 
to 
improve 
diagnostic 
capabilities 
during 
remote 
consultations? 
Furthermore, 
given 
the 
rapid 
technological 
advancements 
and 
the 
increasing 
intelligence 
of 
AI, 
it 
is 
essential 
to 
examine 
how 
humans 
can 
eectively 
harness 
and 
collaborate 
with 
these 
advanced 
AI 
tools, 
such 
as 
ChatGPT, 
to 
improve 
production 
eciency. 


RQ3: 
How 
Humans 
Perceive 
AI? 
Extensive 
research 
has 
explored 
human 
perceptions 
related 
to 
specic 
AI 
tasks 
and 
how 
these 
perceptions 
evolve 
under 
dierent 
conditions. 
Much 
of 
this 
research 
has 
highlighted 
a 
phenomenon 
known 
as 
\algorithm 
aversion.” 
Although 
this 
phenomenon 
has 
been 
observed 
in 
various 
contexts, 
questions 
remain 
about 
its 
prevalence 
across 
all 
AI 
applications. 
If 
algorithm 
aversion 
is 
identied 
in 
a 
new 
context, 
a 
crucial 
question 
is 
to 
explore 
the 
conditions 
under 
which 
people 
are 
more 
likely 
to 
exhibit 
lower 
aversion 
or 
embrace 
AI 
technologies. 
Furthermore, 
human 
perceptions 
may 
be 
dynamic 
with 
the 
development 
of 
AI. 
For 
example, 
it 
is 
uncertain 
whether 
this 
aversion 
will 
diminish 
or 
amplify 
with 
further 
advancements 
in 
AI 
technology, 
such 
as 
the 
introduction 
of 
ChatGPT. 
Do 
customers 
still 
exhibit 
aversion 
when 
communicating 
with 





chatbots 
powered 

contribute 
to 
this 
change? 
Given 
that 
previous 
studies 
show 
varying 
perceptions 
of 
AI 
in 
dierent 
contexts, 
future 
research 
could 
investigate 
whether 
human 
perceptions 
shift 
with 
the 
development 
and 
application 
of 
AI 
in 
those 
specic 
contexts. 


RQ4: 
Does 
AI 
Perform 
Human-like 
Behavior? 
Emerging 
evidence 
indicates 
that 
AI 
may 
manifest 
human-like 
behaviors 
(e.g., 
gender 
and 
racial 
discrimination) 
within 
certain 
contexts. 
Such 
prejudice 
has 
the 
potential 
to 
erode 
the 
trust 
that 
has 
been 
established 
in 
AI, 
altering 
human 
perceptions 
from 
acceptance 
to 
boycotts. 
Additionally, 
since 
most 
AI 
systems 
operate 
as 
black 
boxes, 
it 
is 
challenging 
to 
directly 
detect 
AI 
behavior 
prior 
to 
deployment. 
Consequently, 
a 
critical 
area 
for 
future 
research 
is 
to 
identify 
AI 
behaviors 
across 
diverse 
application 
contexts 
and 
explore 
their 
eects. 
Note 
that 
the 
human-like 
behavior 
is 
not 
inherently 
negative. 
For 
example, 
LLMs 
can 
accurately 
predict 
the 
outcomes 
of 
social 
science 
experiments 
originally 
conducted 
by 
humans 
(Hewitt 
et 
al. 
2024; 
Li 
et 
al. 
2024). 
This 
suggests 
that 
future 
researchers 
could 
leverage 
AI 
agents 
to 
simulate 
human 
participants 
in 
experiments, 
reducing 
the 
costs 
associated 
with 
conducting 
such 
studies. 
Similarly, 
AI 
agents 
could 
potentially 
be 
utilized 
to 
provide 
emotional 
value 
to 
humans 
(Yin 
et 
al. 
2024). 
Therefore, 
a 
promising 
direction 
for 
future 
research 
is 
to 
explore 
the 
potential 
applications 
of 
AI 
exhibiting 
human-like 
behavior 
across 
various 
contexts. 


RQ5: 
How 
to 
Reduce 
AI 
Bias? 
A 
pivotal 
direction 
for 
future 
research 
is 
addressing 
AI 
behavior 
bias. 
Existing 
literature 
identies 
three 
primary 
sources 
contributing 
to 
AI 
bias: 
biased 
training 
datasets, 
inherent 
biases 
within 
algorithms, 
and 
human 
manipulation. 
Yet, 
other 
factors 
may 
also 
contribute 
to 
bias 
within 
AI 
systems, 
demanding 
a 
more 
comprehensive 
understanding 
of 
these 
sources, 
especially 
given 
the 
opacity 
of 
many 
AI 
algorithms. 
This 
knowledge 
is 
essential 
for 
developers 
who 
aim 
to 
eectively 
mitigate 
AI 
bias. 
Moreover, 
while 
several 
solutions 
to 
counteract 
AI 
bias 
have 
been 
proposed, 
it 
remains 
unclear 
how 
about 
the 
externality 
of 
these 
solutions 
or 
whether 
they 
are 
merely 
applicable 
on 
a 
case-by-case 
basis. 
To 
our 
knowledge, 
there 
is 
currently 
no 
foolproof 
way 
to 
ensure 
the 
unbias 
of 
AI. 


6. 
Conclusion 
This 
paper 
reviews 
the 
extant 
literature 
about 
AI 
within 
the 
domain 
of 
business 
research, 
endeavoring 
to 
delineate 
a 
roadmap 
for 
the 
burgeoning 
and 
intricate 
research 
terrain 
surrounding 
AI. 
However, 
we 
also 
acknowledge 
the 
limitations. 
First, 
this 
review 
does 
not 
cover 
a 
signicant 
body 
of 
AI 
research 
within 
Economics, 
Psychology, 
and 
Social 
Science 
(e.g., 
Brynjolfsson 
and 
Mitchell 
2017; 
Kleinberg 
et 
al. 
2018; 
Obermeyer 
et 
al. 
2019; 
Yam 
et 
al. 
2021; 
Chen 
et 
al. 
2023b), 
because 
it 
is 
constrained 
to 
publications 
in 
business 
research. 
Second, 
some 
recent 
studies 
relevant 
to 
our 
review 
framework 
are 
excluded 
due 
to 
the 
limited 
review 
period 
(e.g., 
Babina 
et 
al. 
2024; 
Hou 
et 
al. 
2024; 
Dong 
et 
al. 
2024; 
Gofman 
and 
Jin 
2024). 
