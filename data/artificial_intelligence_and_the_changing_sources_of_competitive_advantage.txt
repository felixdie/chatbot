Krakowski, S., Luger, J., & Raisch, S. (2023). Artificial intelligence and the changing
sources of competitive advantage. Strategic Management Journal, 44(6), 1425-1452.


Abstract 
Research 
Summary: 
We 
apply 
a 
resource-based 
view 
to 
investigate 
how 
the 
adoption 
of 
Artificial 
Intelligence 
(AI) 
affects 
competitive 
capabilities 
and 
performance. 
Following 
prior 
work 
on 
using 
chess 
as 
a 
controlled 
setting 
for 
studying 
competitive 
interactions, 
we 
compare 
the 
same 
players’ 
capabilities 
and 
performance 
across 
conventional, 
centaur, 
and 
engine 
chess 
tournaments. 
Our 
analysis 
shows 
that 
AI 
adoption 
triggers 
interrelated 
substitution 
and 
complementation 
dynamics, 
which 
make 
humans’ 
traditional 
competitive 
capabilities 
obsolete, 
while 
creating 
new 
sources 
of 
persistent 
heterogeneity 
when 
humans 
interact 
with 
chess 
engines. 
These 
novel 
human-machine 
capabilities 
are 
unrelated, 
or 
even 
negatively 
related, 
to 
traditional 
capabilities. 
We 
contribute 
an 
integrated 
view 
of 
substitution 
and 
complementation, 
which 
identifies 
AI 
as 
the 
driver 
of 
these 
dynamics 
and 


explains 
how 
they 
jointly 
shift 
the 
sources 
of 
competitive 
advantage. 
Managerial 
Summary: 
AI-based 
technologies 
increas


ingly 
substitute 
and 
complement 
humans 
in 
managerial 
tasks 
such 
as 
decision 
making. 
We 
investigate 
how 
such 
change 
affects 
the 
sources 
of 
competitive 
advantage. 
AI-
based 
engines’ 
adoption 
in 
chess 
allows 
us 
to 
investigate 
competitive 
capabilities 
and 
performance 
in 
human, 
AI, 
and 
hybrid 
settings. 
We 
find 
that 
neither 
humans 
nor 
AI 



This 
is 
an 
open 
access 
article 
under 
the 
terms 
of 
the 
Creative 
Commons 
Attribution-NonCommercial-NoDerivs 
License, 
which 
permits 
use 
and 
distribution 
in 
any 
medium, 
provided 
the 
original 
work 
is 
properly 
cited, 
the 
use 
is 
non-commercial 
and 
no 
modifications 
or 
adaptations 
are 
made. 
© 
2022 
The 
Authors. 
Strategic 
Management 
Journal 
published 
by 
John 
Wiley 
& 
Sons 
Ltd. 


Strat 
Mgmt 
J. 
2022;1–28. 
wileyonlinelibrary.com/journal/smj 


1 







in 
isolation 
explain 
performance 
differences 
in 
the 
AI 
and 
hybrid 
settings. 
Instead, 
a 
new 
decision-making 
resource 
emerges 
at 
the 
human-AI 
intersection, 
which 
drives 
performance 
but 
is 
unrelated 
or 
even 
negatively 
related 
to 
humans’ 
original 
capability. 
Our 
results 
document 
how 
AI 
adoption 
changes 
the 
sources 
of 
competitive 
advantage 
and, 
in 
turn, 
requires 
managers 
to 
develop 
new 
capabilities 
to 
stay 
relevant 
in 
an 
AI-based 
competitive 
landscape. 


KEYWORDS 


artificial 
intelligence, 
competitive 
behavior, 
decision 
making, 
firm 
capabilities, 
resource-based 
view 


1 
| 
INTRODUCTION 


Artificial 
intelligence 
(AI) 
enables 
machines 
to 
perform 
cognitive 
functions 
previously 
only 
associated 
with 
human 
minds 
(Rai, 
Constantinides, 
& 
Sarker, 
2019). 
Management 
scholars 
surmise 
that 
AI 
changes 
the 
sources 
of 
competitive 
advantage 
(Daugherty 
& 
Wilson, 
2018, 
p. 
214; 
Davenport 
& 
Kirby, 
2016, 
p. 
204), 
but 
offer 
contrasting 
views 
on 
how 
this 
change 
occurs. 
Some 
assume 
that 
AI 
substitutes 
humans' 
cognitive 
capabilities 
(Balasubramanian, 
Ye, 
& 
Xu, 
2021) 
when, 
for 
example, 
machines 
replace 
bankers 
in 
equity 
investment 
(Noonan, 
2017), 
stand 
in 
for 
managers 
in 
talent 
recruitment 
(Chamorro-Premuzic, 
Polli, 
& 
Dattner, 
2019), 
and 
take 
over 
from 
physicians 
in 
medical 
treatment 
(Blakely, 
2020). 
Others 
suppose 
that 
AI 
complements 
rather 
than 
substitutes 
humans' 
cognitive 
capabilities 
(Murray, 
Rhymer, 
& 
Sirmon, 
2021) 
when 
bankers, 
managers, 
and 
physicians 
collaborate 
with 
machines 
on 
equity 
investments 
(Marriage, 
2017), 
talent 
recruitment 
(Hook, 
2017), 
and 
medical 
treatments 
(Topol, 
2019). 


The 
resource-based 
view 
(RBV) 
describes 
the 
theoretical 
mechanisms 
through 
which 
resources 
are 
associated 
with 
competitive 
advantage 
(Barney, 
1991). 
It 
depicts 
humans' 
cognitive 
capabilities 
as 
an 
important 
source 
of 
advantage 
because 
these 
capabilities 
are 
heterogeneously 
distributed, 
limited 
in 
supply, 
and 
difficult 
to 
imitate. 
Such 
capabilities 
thus 
lead 
to 
performance 
differences 
when 
managers 
use 
them 
for 
strategic 
decision 
making 
and 
problem 
solving 
(Helfat 
& 
Peteraf, 
2015; 
Kunc 
& 
Morecroft, 
2010). 
The 
RBV's 
predictions 
regarding 
how 
AI's 
adoption 
affects 
competitive 
advantage 
in 
decision 
making 
are, 
however, 
inconclusive. 
When 
AI 
substitutes 
humans' 
cognitive 
capabilities, 
the 
RBV 
expects 
the 
advantage 
that 
these 
capabilities 
provided 
to 
erode 
(Peteraf 
& 
Bergen, 
2003). 
This 
is 
because, 
as 
a 
technology 
resource, 
AI 
has 
close 
to 
zero 
marginal 
reproduction 
costs 
and 
few 
imitation 
barriers 
(Brynjolfsson 
& 
McAfee, 
2014, 
p. 
31). 
Conversely, 
if 
AI 
complements 
humans' 
cognitive 
capabilities, 
the 
RBV 
expects 
it 
to 
generate 
advantages 
(Argyres 
& 
Zenger, 
2012), 
because, 
as 
a 
widely 
applicable 
technology, 
AI 
enables 
the 
creation 
of 
unique 
bundles 
of 
previously 
unrelated 
resources—such 
as 
physicians' 
expertise 
and 
AI's 
machine 
prediction 
(Agrawal, 
Gans, 
& 
Goldfarb, 
2018, 
p. 
108). 


These 
inconclusive 
predictions 
emanate 
from 
AI's 
unique 
characteristics. 
Contrary 
to 
prior 
technologies, 
AI 
enables 
machines 
to 
learn 
and 
act 
autonomously 
(Balasubramanian 
et 
al., 
2021), 
which, 
in 
turn, 
allows 
these 
machines 
to 
interact 
with 
humans 
in 
decision 
making 
and 
problem 
solving 
(Murray 
et 
al., 
2021). 
Consequently, 
AI 
has 
the 
potential 
to 
both 
substitute 



KRAKOWSKI 
ET 


and 
complement 
humans' 
cognitive 
capabilities 
(Raisch 
& 
Krakowski, 
2021). 
Prior 
RBV 
research 
has 
documented 
the 
co-occurrence 
of 
substitution 
and 
complementation 
when 
organizations 
use 
both 
familiar 
and 
new 
technologies 
(Stadler, 
Helfat, 
& 
Verona, 
2021). 
In 
the 
case 
of 
AI, 
however, 
the 
technology 
and 
its 
novelty 
remain 
constant 
but 
substitution 
and 
complementation 
are 
still 
expected 
to 
co-occur. 
This 
raises 
pressing 
questions 
about 
the 
interrelations 
between 
substitution 
and 
complementation, 
drivers 
of 
these 
interrelations, 
and 
possible 
outcomes. 
In 
this 
article, 
we 
address 
these 
lacunae 
by 
exploring 
how 
AI 
is 
associated 
with 
the 
substitution 
and 
complementation 
of 
humans' 
cognitive 
capabilities 
through 
technology 
resources 
and 
assess 
the 
impact 
on 
the 
sources 
of 
competitive 
advantage. 


Since 
we 
have 
no 
clear 
a 
priori 
theoretical 
guidance, 
we 
take 
a 
question-based 
approach 
(Berry, 
Kaul, 
& 
Lee, 
2021) 
to 
juxtapose 
the 
theoretical 
cases 
for 
AI-driven 
substitution 
and 
complementation. 
We 
explore 
these 
dynamics 
abductively 
in 
the 
context 
of 
chess 
competitions, 
which 
provides 
a 
controlled 
setting 
for 
studying 
cognitive 
capabilities 
and 
competitive 
interactions 
(Bromiley, 
2005; 
Knez 
& 
Camerer, 
1994; 
Powell, 
2003). 
This 
setting 
offers 
the 
unique 
possibility 
to 
clearly 
identify 
and 
directly 
compare 
the 
sources 
of 
competitive 
advantage 
across 
conventional 
(i.e., 
humans 
play 
against 
humans), 
centaur 
(i.e., 
humans 
with 
engines1 
play 
against 
other 
humans 
with 
engines), 
and 
engine 
chess 
(i.e., 
engines 
play 
chess 
autonomously, 
but 
humans 
select, 
tune, 
and 
govern 
these 
engines) 
while 
keeping 
the 
context 
(i.e., 
the 
chess 
rules 
and 
the 
tournament 
formats) 
stable. 
This 
limits 
the 
risk 
of 
confounding, 
which 
is 
high 
in 
real-
world 
business 
settings 
where 
contexts 
are 
unstable, 
and 
emerging 
substitution 
and 
complementation 
alter 
competitive 
interactions 
and 
their 
outcomes. 


On 
analyzing 
the 
chess 
data, 
we 
find 
that, 
in 
a 
previously 
human-only 
strategic 
decision 
context, 
AI 
adoption 
triggered 
interrelated 
substitution 
and 
complementation 
dynamics 
between 
humans 
and 
machines. 
First, 
we 
find 
evidence 
for 
substitution 
when 
chess 
engines 
enter 
the 
competition, 
which 
erodes 
the 
previously 
positive 
association 
between 
humans' 
chess 
playing 
capabilities 
and 
their 
chess 
performance. 
Chess 
engines 
show 
no 
corresponding 
performance 
effect, 
since 
they 
lack 
supply 
restrictions 
and 
face 
few 
imitation 
barriers. 
Second, 
complementation 
emerges 
when 
humans 
interact 
with 
engines 
while 
playing 
centaur 
chess, 
and 
when 
selecting, 
tuning, 
and 
governing 
engines 
in 
both 
centaur 
and 
engine 
chess. 
These 
human 
capabilities 
to 
complement 
machines 
create 
new 
persistent 
performance 
differences, 
but 
are 
unrelated, 
or 
even 
negatively 
related, 
to 
humans' 
traditional 
chess 
playing 
capabilities. 


Our 
explanation 
of 
these 
findings 
is 
that 
AI 
has 
a 
dualistic 
effect 
that 
shifts 
the 
sources 
of 
competitive 
advantage. 
Although 
AI 
substitutes 
humans' 
traditional 
domain-related 
cognitive 
capabilities 
with 
machines' 
abundant 
computational 
capabilities, 
thus 
eradicating 
the 
extant 
sources 
of 
competitive 
advantage, 
it 
simultaneously 
enables 
complementation 
when 
humans 
use 
previously 
domain-unrelated 
cognitive 
capabilities 
to 
augment 
machines' 
capabilities, 
thus 
creating 
new 
persistent 
sources 
of 
competitive 
advantage. 


We 
contribute 
to 
the 
strategy 
literature 
by 
moving 
beyond 
the 
discussion 
of 
either 
substitution 
as 
an 
act 
of 
destroying 
advantage 
(Peteraf 
& 
Bergen, 
2003) 
or 
complementation 
as 
an 
act 
of 
creating 
advantage 
(Argyres 
& 
Zenger, 
2012) 
toward 
an 
integrated 
view 
of 
these 
two 
acts 
occurring 
together. 
Moreover, 
we 
identify 
AI 
as 
the 
driver 
of 
these 
interrelated 
resource 
dynamics. 
Developing 
these 
insights 
is 
important, 
not 
only 
because 
they 
help 
integrate 
previously 
disparate 
RBV 
perspectives, 
but 
also 
because 
they 
are 
practically 
relevant. 
If 
substitution 
through 
AI 
provides 
opportunities 
to 
create 
new 
advantages 
from 
complementary 
human–machine 
capabilities—as 
was 
the 
case 
in 
our 
chess 
sample—then 
firms 
might 
survive 
disruption 
and 
realize 
superior 
profits 
nurturing 
these 



1Engines 
are 
AI-based 
machines 
that 
analyze 
chess 
positions 
and 
determine 
the 
best 
possible 
moves. 





mentation 
skills” 
(Raisch 
& 
Krakowski, 
2021, 
p. 
202). 
We 
therefore 
conclude 
our 
article 
by 
discussing 
our 
findings' 
applicability 
in 
business 
contexts 
and 
their 
practical 
implications. 


2 
| 
CONCEPTUAL 
BACKGROUND 


We 
draw 
on 
prior 
RBV 
research 
focusing 
on 
new 
resources' 
emergence 
and 
their 
relationship 
with 
existing 
resources 
(Argyres 
& 
Zenger, 
2012; 
Levinthal 
& 
Wu, 
2010; 
Peteraf 
& 
Bergen, 
2003; 
Polidoro 
& 
Toh, 
2011). 
This 
work 
distinguishes 
between 
resource 
substitution 
and 
complementation, 
with 
substitution 
eliminating 
a 
competitive 
advantage 
when 
new 
resources 
with 
abundant 
availability 
replace 
traditional 
ones 
by 
providing 
the 
same 
functionality; 
and 
complementation 
creating 
a 
competitive 
advantage 
when 
traditional 
resources 
and 
new 
heterogeneous 
ones 
are 
integrated 
to 
form 
unique 
resource 
bundles. 


When 
applying 
these 
insights 
to 
the 
AI 
context, 
we 
also 
rely 
on 
prior 
work 
describing 
AI 
as 
a 
new 
technology 
resource 
of 
strategic 
importance 
that 
can 
learn 
and 
act 
independently 
of 
humans 
(Agrawal 
et 
al., 
2018; 
Brynjolfsson 
& 
McAfee, 
2014; 
Choudhury, 
Starr, 
& 
Agarwal, 
2020; 
Raisch 
& 
Krakowski, 
2021). 
Humans 
and 
AI 
differ 
in 
the 
ways 
they 
process 
information 
to 
create 
domain 
expertise, 
since 
AI 
can 
process 
much 
larger 
quantities 
of 
information 
at 
a 
higher 
speed 
and 
accuracy, 
whereas 
humans 
rely 
on 
information 
processing 
shortcuts, 
which 
could 
cause 
potential 
errors 
or 
biases, 
but 
also 
make 
humans 
more 
versatile 
in 
scarce 
or 
complex 
information 
environments. 
From 
an 
RBV 
perspective, 
these 
different 
properties 
suggest 
interrelated 
substitution 
and 
complementation 
relationships, 
which 
we 
explore 
next. 


2.1 
| 
Substitution 
through 
AI 
Substitution 
is 
an 
important 
RBV 
construct 
(Peteraf 
& 
Bergen, 
2003; 
Polidoro 
& 
Toh, 
2011), 
which 
centers 
on 
resources 
replacing 
others 
providing 
the 
same 
functionality 
(Levinthal 
& 
Wu, 
2010). 
Resources 
with 
low 
fungibility 
are 
specific 
to 
one 
domain, 
whereas 
those 
with 
high 
fungibility 
can 
be 
applied 
widely. 
Furthermore, 
scale-free 
resources 
can 
be 
allocated 
across 
domains 
without 
additional 
costs, 
while 
those 
that 
are 
not 
scale 
free 
have 
opportunity 
costs. 
While 
humans' 
general 
cognitive 
capabilities 
have 
a 
high 
fungibility, 
advantage-generating 
resources, 
such 
as 
humans' 
domain-specific 
cognitive 
capabilities, 
have 
a 
low 
fungibility 
and 
are 
also 
not 
scale 
free 
(Helfat 
& 
Peteraf, 
2015). 
This 
constrains 
these 
capabilities' 
use 
to 
related 
domains 
(Montgomery 
& 
Wernerfelt, 
1988) 
because 
their 
application 
for 
substitution 
in 
unrelated 
domains 
would 
require 
extensive 
learning 
from 
experience, 
coming 
with 
significant 
economic 
costs 
that 
quickly 
exceed 
any 
potential 
benefits 
(Helfat 
& 
Peteraf, 
2003). 


The 
adoption 
of 
AI 
in 
a 
competitive 
domain 
could 
trigger 
substitution. 
Currently, 
AI 
is 
used 
widely 
to 
automate 
predictions 
regarding 
strategic 
decision 
making 
and 
problem 
solving 
tasks, 
which, 
traditionally, 
only 
humans 
could 
do 
by 
relying 
on 
their 
cognitive 
capabilities 
(Choudhury 
et 
al., 
2020; 
Shrestha, 
Ben-Menahem, 
& 
von 
Krogh, 
2019). 
Unlike 
humans, 
machines 
have 
quasi-
unlimited 
information 
processing 
capacity, 
often 
providing 
better 
predictions 
than 
humans 
do 
(Raisch 
& 
Krakowski, 
2021). 
This 
is 
evident, 
as 
AI-based 
machines 
now 
match 
or 
surpass 
physicians' 
cancer 
diagnosis 
and 
treatment 
recommendations 
(Jiang 
et 
al., 
2017), 
human 
resource 
experts' 
prediction 
of 
candidates' 
future 
job 
performance 
(Chamorro-Premuzic 
et 
al., 
2019), 
product 
developers' 
creation 
of 
design 
alternatives 
(Verganti, 
Vendraminelli, 
& 
Iansiti, 
2020), 
and 
business 
angels' 
venture 
investments 
(Blohm, 
Antretter, 
Sirén, 
Grichnik, 
& 
Wincent, 
2021). 
AI 
resources' 
accuracy 
and 







efore 
likely 
to 
reduce 
human 
prediction 
capabilities' 
traditional 
value 
(Ahuja, 
Coff, 
& 
Lee, 
2005), 
or 
even 
make 
these 
capabilities 
obsolete 
(Agrawal 
et 
al., 
2018, 
p. 
80). 


While 
this 
prior 
work 
offers 
strong 
foundations, 
several 
open 
questions 
remain 
on 
how 
substitution 
occurs 
in 
an 
AI 
context. 
First, 
technical 
limitations 
hinder 
machines 
from 
taking 
over 
decision 
making 
or 
problem 
solving 
tasks 
entirely 
(Raisch 
& 
Krakowski, 
2021). 
For 
example, 
prediction 
is 
only 
one 
component 
of 
decisions, 
which 
also 
require 
tasks 
like 
setting 
objectives, 
selecting 
data, 
exercising 
judgment, 
and 
taking 
action 
(Shrestha 
et 
al., 
2019). 
While 
substitution 
through 
AI 
may 
occur, 
it 
is 
unlikely 
to 
capture 
AI-driven 
dynamics 
exhaustively. 
Second, 
the 
nature 
of 
substitution 
may 
differ 
when 
machines 
replace 
humans. 
For 
example, 
prior 
studies 
described 
the 
substitution 
of 
resources 
between 
related 
domains 
(Levinthal 
& 
Wu, 
2010; 
Peteraf 
& 
Bergen, 
2003), 
because 
humans' 
domain-specific 
cognitive 
capabilities 
are 
difficult 
to 
transfer 
to 
unrelated 
domains. 
While 
these 
arguments 
apply 
to 
humans 
and 
their 
cognitive 
capabilities, 
they 
may 
not 
apply 
to 
machines' 
corresponding 
capabilities, 
which 
AI 
scholars 
suggest 
are 
widely 
applicable 
across 
domains 
(Agrawal 
et 
al., 
2018, 
p. 
2) 
and 
scale 
free 
(Brynjolfsson 
& 
McAfee, 
2014, 
p. 
31). 
Extant 
research 
has 
little 
to 
report 
on 
how 
substitution 
might 
occur 
across 
previously 
unrelated 
domains, 
such 
as 
AI 
technology 
versus 
medical 
care, 
talent 
recruitment, 
product 
design, 
and 
venture 
capital. 
Consequently, 
the 
first 
question 
to 
explore 
is 
whether 
and 
how 
AI 
substitutes 
humans' 
advantage-generating 
cognitive 
capabilities. 


2.2 
| 
Complementation 
through 
AI 
The 
RBV 
also 
explores 
how 
complementation 
creates 
a 
competitive 
advantage 
by 
developing 
unique 
resource 
combinations 
(Newbert, 
2007). 
Actors 
with 
“the 
intent 
of 
creating 
a 
new 
competitive 
advantage” 
(Sirmon, 
Hitt, 
& 
Ireland, 
2007, 
p. 
282) 
integrate 
existing 
resources 
and 
new 
ones 
into 
resource 
bundles 
that 
are 
“uniquely 
complementary” 
(Argyres 
& 
Zenger, 
2012, 
p. 
1648). 
Complementary 
refers 
to 
resources 
that 
are 
supermodular 
in 
the 
sense 
that 
given 
two 
resources, 
A 
and 
B, 
more 
of 
A 
makes 
B 
more 
valuable 
(Milgrom 
& 
Roberts, 
1990). 
To 
be 
uniquely 
complementary, 
these 
resources 
not 
only 
have 
to 
be 
supermodular, 
but 
also 
unrelated. 
Such 
unrelatedness 
ensures 
that 
the 
resulting 
resource 
bundles 
are 
novel 
and 
scarce, 
providing 
a 
foundation 
for 
sustainable 
heterogeneity 
(Argyres 
& 
Zenger, 
2012). 
Conversely, 
resources 
within 
a 
competitive 
domain's 
reach 
may 
be 
complementary, 
but 
their 
proximity 
usually 
results 
in 
resource 
abundance 
and 
few 
supply 
restrictions. 


Extant 
work 
provides 
different 
views 
of 
how 
AI 
adoption 
leads 
to 
complementation. 
One 
view 
describes 
the 
partitioning 
of 
tasks 
into 
subtasks, 
which 
are 
partly 
taken 
over 
by 
AI-based 
machines 
and 
partly 
remain 
with 
humans 
(Brynjolfsson 
& 
McAfee, 
2014, 
p. 
92; 
Raisch 
& 
Krakowski, 
2021). 
For 
example, 
physicians 
delegate 
medical 
diagnosis 
to 
AI-based 
machines, 
while 
focusing 
on 
patient 
treatment 
(Talby, 
2019). 
Another 
view 
suggests 
human–machine 
interaction 
in 
the 
same 
tasks 
(Agrawal 
et 
al., 
2018, 
p. 
66; 
Metcalf, 
Askay, 
& 
Rosenberg, 
2019). 
For 
example, 
physicians 
can 
complement 
machines' 
medical 
diagnosis 
by 
using 
their 
contextual 
understanding 
to 
spot 
machine 
biases 
(Talby, 
2019). 
Both 
views 
stress 
humans' 
and 
machines' 
distinctive 
capabilities, 
with 
their 
complementary 
strengths 
and 
weaknesses. 
Specifically, 
humans 
can 
complement 
machines' 
superior 
prediction 
capability 
by 
relying 
on 
their 
unique 
capabilities, 
such 
as 
creative 
ideation, 
large-scale 
contextualization, 
and 
social 
interaction 
(Brynjolfsson 
& 
McAfee, 
2014, 
p. 
202). 
For 
example, 
human 
resource 
experts 
can 
do 
so 
by 
assessing 
candidates' 
cultural 
fit 
and 
convincing 
them 
to 
work 
for 
their 
firms 
(Hook, 
2017), 
while 
product 
designers 
do 
so 
by 
making 
sense 
of 
customers' 
problems 
(Verganti 
et 
al., 
2020), 



KRAKOWSKI 
ET 


and 
portfolio 
iding 
creative 
investment 
ideas 
and 
selling 
them 
to 
investors 
(Marriage, 
2017). 
Davenport 
and 
Kirby 
(2016, 
p. 
204) 
therefore 
speculate 
that 
such 
human 
augmentation 
capabilities, 
which 
complement 
AI-based 
machines' 
capabilities, 
could 
be 
a 
new 
source 
of 
competitive 
advantage. 


While 
providing 
valuable 
insights, 
this 
prior 
work 
still 
leaves 
questions 
on 
complementation 
in 
an 
AI 
context 
unanswered. 
First, 
prior 
RBV 
studies 
described 
how 
humans 
purposefully 
acquire 
new 
capabilities 
to 
complement 
their 
existing 
ones 
(Argyres 
& 
Zenger, 
2012). 
However, 
AI 
as 
a 
novel 
technology 
with 
the 
ability 
to 
learn 
and 
act 
independently 
might 
not 
follow 
these 
predictions. 
For 
example, 
Shrestha 
et 
al. 
(2019) 
warn 
that 
combining 
human 
and 
machine 
capabilities 
in 
an 
AI 
context 
could 
also 
lead 
to 
negative 
complementarities. 
Second, 
prior 
research 
studied 
substitution 
and 
complementation 
in 
different 
contexts 
(Hess 
& 
Rothaermel, 
2011; 
Stadler 
et 
al., 
2021), 
providing 
little 
insight 
into 
how 
they 
are 
interrelated. 
In 
the 
case 
of 
AI, 
scholars 
described 
these 
resource 
dynamics 
as 
occurring 
in 
the 
same 
context 
(Brynjolfsson 
& 
McAfee, 
2014, 
p. 
134f; 
Raisch 
& 
Krakowski, 
2021). 
For 
example, 
Talby 
(2019) 
showed 
that 
AI-based 
machines 
both 
substitute 
and 
complement 
physicians. 
Two 
additional 
questions 
to 
explore 
are 
therefore 
whether 
and 
how 
AI 
complements 
human 
capabilities 
with 
technology 
resources; 
and 
how 
such 
complementation 
relates 
to 
substitution 
effects. 


3 
| 
EMPIRICAL 
CONTEXT, 
DATA, 
AND 
METHODS 


We 
embrace 
the 
variety 
of 
prior 
theoretical 
accounts 
and 
anecdotal 
observations 
by 
utilizing 
an 
abductive 
approach 
(Sætre 
& 
van 
de 
Ven, 
2021). 
Specifically, 
we 
examine 
how 
the 
adoption 
of 
AI 
in 
chess 
competition 
is 
associated 
with 
the 
substitution 
and/or 
complementation 
of 
human 
capabilities 
through 
technology 
resources, 
and 
assess 
its 
impact 
on 
the 
sources 
of 
competitive 
advantage. 
Prior 
RBV 
studies 
used 
chess 
competition 
as 
a 
metaphor 
(e.g., 
Bromiley, 
2005; 
Wernerfelt, 
1995) 
and 
as 
an 
empirical 
context 
(e.g., 
Knez 
& 
Camerer, 
1994; 
Powell, 
2003). 
Building 
on 
seminal 
studies 
of 
chess 
competition 
(Chase 
& 
Simon, 
1973; 
de 
Groot, 
1946), 
these 
researchers 
explored 
how 
human 
capabilities, 
as 
heterogeneously 
distributed 
cognitive 
resources, 
contribute 
to 
performance 
differences. 
Since 
other 
resources 
(such 
as 
the 
time 
and 
the 
chess 
pieces) 
are 
distributed 
equally, 
the 
differences 
between 
competitive 
actors' 
chess 
playing 
capabilities 
largely 
explain 
performance 
heterogeneity. 
Chess 
is, 
therefore, 
a 
relatively 
“clean” 
and 
well-
observable 
context 
for 
competitive 
interactions, 
which 
is 
often 
used 
to 
provide 
insight 
into 
strategic 
actions 
and 
outcomes 
that 
extends 
beyond 
the 
chess 
context 
(Gobet 
& 
Simon, 
1996). 


Studying 
competitive 
strategy 
in 
a 
chess 
context 
has 
certain 
limitations. 
The 
most 
important 
of 
these 
is 
that 
chess 
is 
a 
well-defined 
game 
with 
a 
lower 
degree 
of 
uncertainty 
than 
most 
strategic 
actions 
in 
business 
settings 
(Bromiley, 
2005). 
However, 
similar 
to 
business 
settings, 
chess 
exposes 
humans 
to 
problem 
situations 
under 
uncertainty 
in 
which 
their 
cognitive 
limitations 
prevent 
them 
from 
exploring 
alternative 
courses 
of 
action 
comprehensively 
(Bromiley 
& 
Rau, 
2018). 
The 
advantage 
of 
chess 
is 
that 
it 
provides 
a 
controlled 
context 
in 
which 
actors' 
capabilities, 
as 
well 
as 
the 
quality 
and 
sequence 
of 
their 
actions, 
are 
consistently 
identifiable 
and 
comparable 
(Cowen, 
2013, 
p. 
69f; 
Simon, 
1972, 
p. 
165ff). 
Such 
a 
controlled 
context 
is 
generally 
unavailable 
in 
business 
contexts, 
where 
each 
strategic 
action 
is 
essentially 
unique. 
Furthermore, 
the 
high 
levels 
of 
noise, 
as 
well 
as 
imprecise 
identification, 
limit 
researchers' 
ability 
to 
derive 
valid 
and 
generalizable 
theoretical 
insight 
from 
these 
contexts. 


We 
use 
the 
controlled 
chess 
context 
to 
compare 
the 
same 
players' 
capabilities 
and 
performance 
across 
conventional, 
centaur, 
and 
engine 
chess 
tournaments. 
In 
conventional 
games, 





n 
players 
rely 
exclusively 
s 
playing 
capabilities, 
whereas 
in 
centaur 
games 
they 
may 
consult 
a 
chess 
engine 
at 
any 
time 
during 
the 
game 
to 
evaluate 
the 
board 
positions 
and 
moves, 
and 
in 
engine 
games, 
in 
turn, 
the 
engine 
plays 
chess 
without 
a 
human 
player's 
involvement 
(Cowen, 
2013, 
p. 
77ff). 
In 
centaur 
and 
engine 
games, 
humans 
also 
intervene 
by 
selecting, 
tuning, 
and 
governing 
the 
chess 
engines 
(Ensmenger, 
2012; 
Suba, 
2010, 
p. 
29f). 


3.1 
| 
Data 
sources 
and 
sample 
We 
collected 
data 
in 
2017 
from 
chess 
tournament 
organizers' 
databases 
covering 
all 
the 
official 
centaur 
and 
engine 
tournaments 
that 
had 
been 
held 
at 
this 
time.2 
We 
therefore 
have 
full 
population 
level 
data. 
Chess 
players 
identified 
as 
participants 
in 
these 
tournaments 
constitute 
our 
sample's 
focal 
players. 
We 
identified 
players 
by 
their 
names 
or, 
if 
they 
used 
aliases, 
conducted 
extensive 
research 
to 
reveal 
their 
identities. 
Subsequently, 
we 
focused 
on 
Fédération 
Inter




nationale 
des 
Echecs 
(FIDE) 
members, 
which 
allowed 
us 
to 
gather 
additional 
player 
data. 
We 
then 
collected 
data 
on 
all 
the 
official 
conventional 
chess 
tournament 
games 
involving 
these 
players 
between 
2000 
and 
2017, 
using 
the 
ChessBase 
Mega 
Database 
2018.3 
We 
therefore 
observe 
the 
same 
chess 
players 
across 
the 
three 
tournament 
formats, 
having 
initially 
identified 
them 
through 
the 
centaur 
and 
engine 
formats. 
This 
sampling 
procedure 
yields 
a 
sample 
of 
112 
unique 
players 
from 
39 
chess 
federations 
participating 
in 
3,281 
tournaments. 


3.2 
| 
Dependent 
variables 
Our 
primary 
measure 
of 
chess 
performance 
is 
the 
game 
result, 
namely 
a 
win, 
loss, 
or 
draw 
from 
the 
focal 
player's 
perspective 
(with 
a 
draw 
as 
a 
baseline 
outcome).4 
Our 
secondary 
measure 
is 
the 
ply5 
quality, 
which 
we 
assessed 
using 
the 
chess 
engine 
Stockfish 
10 
as 
a 
benchmark.6 
Two 
count 
variables, 
positive 
plies 
and 
negative 
plies, 
denote 
the 
respective 
sums 
of 
positive 
and 
negative 
plies 
that 
the 
focal 
player 
made 
in 
each 
game 
(Matanovic, 
2008).7 
Finally, 
we 
conducted 
supplementary 
analyses, 
using 
the 
propensity 
for 
games 
to 
end 
in 
a 
draw 
as 
a 
binary 
variable, 
and 
assessing 
the 
game 
length, 
a 
count 
variable 
that 
measures 
the 
total 
number 
of 
plies 
in 
a 
game. 



4For 
an 
overview 
of 
the 
dependent, 
independent, 
and 
control 
variables' 
descriptions 
and 
measures, 
please 
see 
Table 
S1. 
5In 
chess 
terminology, 
“ply” 
denotes 
a 
turn 
taken 
by 
one 
player, 
while 
a 
“move” 
refers 
to 
two 
consecutive 
turns 
or 
plies 
made 
by 
White 
and 
then 
Black 
(Charness, 
1977). 
For 
a 
glossary 
of 
chess 
terms, 
please 
see 
the 
Appendix 
S1. 
6The 
optimal 
choice 
was 
determined 
using 
Stockfish 
10, 
the 
strongest 
available 
chess 
engine 
at 
the 
time 
of 
data 
collection 
(Cilento, 
2019). 
This 
engine, 
and 
consequently 
its 
level 
of 
analysis, 
were 
not 
available 
to 
players 
during 
our 
observation 
period 
(2000–2017). 
Amazon's 
cloud-computing 
platform, 
which 
includes 
the 
Elastic 
Compute 
Cloud 
(EC2) 
application 
for 
parallel 
processing, 
enabled 
us 
to 
benchmark 
any 
decision 
for 
a 
given 
board 
combination 
against 
an 
optimal 
choice. 
7The 
chess 
players 
in 
our 
sample 
are 
highly 
skilled 
and 
their 
plies 
are 
consistently 
considered 
excellent 
compared 
to 
those 
of 
non-professional 
players. 
Consequently, 
the 
benchmarking 
only 
identifies 
plies 
that 
are 
particularly 
close 
to 
the 
theoretical 
optimum 
as 
“positive,” 
and 
those 
that 
are 
disproportionately 
below 
this 
optimum, 
as 
“negative.” 



KRAKOWSKI 
ET 


3.3 
| 
Independent 
variables 
To 
capture 
ing 
capabilities, 
we 
follow 
prior 
studies 
(e.g., 
Chassy 
& 
Gobet, 
2011) 
and 
use 
Elo 
ratings 
(Elo, 
1978) 
to 
measure 
player 
capabilities 
and 
opponent 
capabilities. 
This 
measure 
predicts 
the 
players' 
relative 
capability 
levels 
based 
on 
their 
previous 
tournament 
performance.8 
In 
addition, 
player 
capabilities 
difference 
captures 
the 
absolute 
difference 
in 
the 
focal 
player 
and 
the 
opponent 
player's 
chess 
playing 
capabilities. 


Like 
human 
players, 
chess 
engines 
have 
Elo 
ratings 
that 
are 
predictions 
of 
their 
relative 
capability 
levels 
based 
on 
their 
prior 
tournament 
performance 
(Haworth, 
2007). 
We 
use 
this 
machine 
capabilities 
measure 
as 
an 
indication 
of 
the 
focal 
player's 
machine 
chess 
playing 
capabilities, 
which 
is 
broadly 
(albeit 
not 
perfectly) 
comparable 
to 
human 
chess 
playing 
capabilities 
(Regan 
& 
Haworth, 
2011). 
Accordingly, 
machine 
capabilities 
difference 
denotes 
the 
absolute 
difference 
between 
the 
focal 
player 
and 
the 
opponents' 
engines' 
chess 
playing 
capabilities. 


Similar 
to 
the 
conceptualization 
of 
humans' 
and 
machines' 
Elo 
ratings 
(Haworth, 
2007), 
we 
predict 
human–machine 
capabilities 
based 
on 
the 
focal 
players' 
prior 
performance 
in 
centaur 
or 
engine 
tournaments. 
Human–machine 
capabilities 
capture 
players' 
capabilities 
when 
interacting 
with 
chess 
engines 
in 
the 
respective 
tournament 
formats. 
Human–centaur 
capabilities 
denote 
this 
capability 
in 
centaur 
chess, 
and 
human–engine 
capabilities 
in 
engine 
chess. 
We 
also 
use 
the 
alternative 
measure 
human–engine 
scope, 
which 
refers 
to 
the 
cumulative 
number 
of 
unique 
chess 
engines 
that 
a 
player 
has 
used 
in 
centaur 
and 
engine 
tournaments. 


Additionally, 
we 
designate 
the 
tournament 
format 
by 
using 
a 
categorical 
indicator 
of 
conventional 
(i.e., 
baseline), 
centaur, 
and 
engine 
tournaments. 
In 
analyses 
that 
exclude 
conventional 
games, 
this 
measure 
becomes 
a 
binary 
variable 
with 
centaur 
as 
the 
baseline. 


3.4 
| 
Control 
variables 
We 
include 
control 
variables, 
such 
as 
the 
focal 
player 
gender, 
player 
federation, 
player 
age, 
player 
members 
(i.e., 
the 
number 
of 
members 
on 
the 
team), 
and 
player 
set, 
which 
indicates 
whether 
the 
focal 
player 
plays 
White 
(and 
thus 
makes 
the 
first 
move) 
or 
Black, 
with 
White 
as 
the 
baseline 
category. 
We 
also 
measure 
the 
cumulative 
numbers 
of 
previous 
centaur 
or 
engine 
tournament 
games 
that 
the 
focal 
player 
has 
played 
(i.e., 
centaur 
games 
played, 
and 
engine 
games 
played) 
to 
capture 
any 
learning 
effects 
from 
playing 
these 
tournaments. 
At 
the 
game 
level, 
we 
include 
time 
controls, 
which 
indicate 
the 
time 
available 
for 
players 
to 
reflect 
on 
and 
complete 
their 
plies,9 
tournament 
system 
controls, 
which 
indicate 
how 
a 
tournament 
winner 
is 
determined, 
and 
tournament 
round 
controls, 
which 
indicate 
the 
round 
in 
which 
the 
game 
is 
played. 
Finally, 
at 
the 
macro 
level, 
we 
control 
for 
unobserved 
time 
effects 
by 
using 
dummy 
variables 
for 
the 
current 
year 
and 
quarter. 
In 
some 
analyses, 
we 
substitute 
these 
time 
dummies 
with 
a 
time 
count 
variable 
to 
control 
for 
potential 
general 
learning 
effects 
(e.g., 
engines' 
improved 



8As 
in 
many 
RBV 
studies, 
one 
could 
voice 
tautology 
or 
path 
dependency 
concerns 
(Priem 
& 
Butler, 
2001) 
regarding 
Elo 
ratings 
(i.e., 
past 
chess 
performance 
affecting 
future 
chess 
performance). 
We 
nevertheless 
believe 
that 
such 
concerns 
are 
limited 
in 
our 
study, 
given 
that 
the 
Elo 
ratings' 
construction 
does 
not 
build 
directly 
on 
players' 
past 
game 
results 
but 
incorporates 
multiple 
and 
partially 
asymmetrical 
adjustments 
to 
account 
for 
the 
chess 
game's 
particularities. 
For 
more 
information, 
see 
our 
detailed 
explanations 
on 
the 
Elo 
ratings' 
construction 
in 
the 
Appendix 
S1. 
9The 
normal 
time 
controls 
are 
60 
min 
per 
game 
and 
player 
for 
games 
with 
a 
“classic” 
time 
control 
(i.e., 
our 
baseline), 
between 
10 
and 
60 
min 
for 
“rapid” 
games, 
and 
below 
10 
min 
for 
“blitz” 
games 
(FIDE, 
2020). 





ormance 
over 
time). 
When 
applicable, 
we 
include 
player 
 
in 
these 
models, 
exclude 
the 
time-invariant 
variables.10 


3.5 
| 
Descriptive 
statistics 
The 
players 
in 
our 
sample 
have 
an 
average 
Elo 
slightly 
above 
1,800, 
making 
it 
highly 
comparable 
to 
the 
global 
FIDE 
average. 
This 
suggests 
that 
our 
player 
selection 
via 
centaur 
and 
engine 
tournament 
participation 
does 
not 
seem 
to 
introduce 
selection 
effects 
into 
our 
sample. 
The 
players 
use 
engines 
rated 
at 
3,155. 
On 
average, 
games 
last 
85 
plies, 
with 
players 
making 
about 
1 
disproportionally 
positive 
and 
0.6 
disproportionally 
negative 
plies 
per 
game. 
Please 
see 
Table 
S2 
for 
the 
main 
variables' 
descriptive 
statistics. 


On 
analyzing 
the 
main 
variables' 
relative 
frequencies 
in 
respect 
of 
conventional 
games 
(see 
TableS3),weobserve 
patternsinlinewithprior 
research: 
White's 
has 
a 
first-mover 
advantage 
over 
Black 
(35% 
compared 
with 
26% 
of 
games 
won) 
(Ribeiro, 
Mendes, 
Lenzi, 
del 
Castillo-Mussot, 
& 
Amaral, 
2013), 
and 
men 
are 
vastly 
overrepresented 
(Maass, 
D'Ettole, 
& 
Cadinu, 
2008). 
In 
centaur 
and 
engine 
games, 
new 
patterns 
become 
apparent. 
Compared 
with 
conventional 
games, 
an 
increasing 
share 
of 
games 
with 
machines 
end 
in 
a 
draw 
(increasing 
from 
39% 
of 
conventional 
to 
54% 
of 
centaur, 
and 
77% 
of 
engine 
games). 
These 
games 
also 
last 
longer 
in 
terms 
of 
the 
average 
number 
of 
plies 
(increasing 
from 
80 
in 
conventional 
to 
100 
in 
centaur, 
and 
140 
in 
engine 
games), 
and 
are 
characterized 
by 
fewer 
disproportionately 
positive 
and 
negative 
plies, 
whereby 
the 
decrease 
in 
negative 
plies 
is 
much 
higher. 
This 
suggests 
a 
convergence 
in 
game 
outcomes, 
with 
centaur 
and 
engine 
chess 
allowing 
less 
heterogeneity 
in 
relative 
player 
performance 
than 
conventional 
chess 
does. 


We 
also 
analyze 
the 
main 
variables' 
pairwise 
correlations 
(see 
Table 
S4) 
to 
assess 
whether 
multicollinearity 
is 
a 
possible 
source 
of 
endogeneity. 
The 
correlations 
do 
not 
exceed 
the 
conventional 
cut-off 
of 
0.70 
between 
variables 
in 
the 
same 
econometric 
model 
(Dormann 
et 
al., 
2013), 
although 
the 
correlations 
between 
human–engine 
capabilities 
and 
engine 
games 
played 
(0.80) 
were 
a 
notable 
exception. 
Since 
this 
problem 
only 
concerns 
a 
post 
hoc 
test, 
we 
address 
it 
later. 
We 
also 
calculate 
the 
collinearity 
diagnostic 
factors 
(see 
Table 
S5): 
Given 
a 
mean 
variance 
inflation 
factor 
(VIF) 
of 
2.19 
and 
a 
maximum 
of 
8.07, 
all 
below 
the 
conventional 
threshold 
of 
10, 
there 
is 
no 
major 
multicollinearity 
concern 
(Salkind, 
2007, 
p. 
639f). 


3.6 
| 
Methodology 
In 
keeping 
with 
prior 
studies 
that 
used 
competitive 
game 
data 
(e.g., 
Cea 
et 
al., 
2020), 
we 
apply 
a 
multinomial 
logistic 
model 
(Powers 
& 
Xie, 
2008) 
to 
estimate 
the 
factors 
contributing 
to 
the 
likelihood 
of 
one 
of 
the 
three 
possible 
game 
results 
(i.e., 
win, 
draw, 
or 
loss). 
Although 
an 
ordered 
logistic 
regression 
would 
yield 
a 
more 
parsimonious 
model, 
modeling 
game 
result 
as 
an 
ordinal 
variable 
yields 
biased 
results 
if 
the 
proportional 
odds 
assumption, 
that 
is, 
that 
the 
coefficients 
will 
be 
equal 
across 
outcome 
pairs 
(win 
vs. 
draw, 
loss 
vs. 
draw), 
is 
violated 
(Fullerton, 
2009). 
We 
therefore 
tested 
the 
proportional 
odds 
assumption 
by 
using 
Wolfe 
and 
Gould's 
(1998) 



10Due 
to 
our 
unbalanced 
data 
structure 
and 
sparse 
variables, 
we 
were 
unable 
to 
include 
individual-level 
fixed 
effects 
in 
the 
multinomial 
logistic 
regressions, 
making 
estimation 
infeasible. 
Nevertheless, 
we 
estimated 
the 
models 
once 
more, 
clustering 
standard 
errors 
on 
the 
player 
federation 
level, 
given 
that 
chess 
players 
spend 
most 
of 
their 
time 
developing 
their 
capabilities 
in 
domestic 
federation 
contexts. 
Our 
findings 
are 
replicated 
across 
models, 
with 
results 
remaining 
robust 
in 
terms 
of 
comparable 
magnitude 
and 
significance. 



KRAKOWSKI 
ET 


omodel 
Stata 
command, 
followed 
by 
a 
Brant 
(1990) 
test 
based 

Freese's 
(2006, 


p. 
199f) 
brant 
Stata 
command. 
The 
test 
statistics 
from 
both 
tests 
indicate 
that 
the 
assumption 
is 
unlikely 
to 
hold, 
leading 
us 
to 
proceed 
with 
a 
multinomial 
logistic 
model 
(Fullerton, 
2009). 
4 
| 
ANALYSIS 
AND 
FINDINGS 


4.1 
| 
Human–machine 
resource 
substitution 
In 
conventional 
chess 
competition, 
humans 
use 
their 
chess 
playing 
capabilities 
in 
order 
to 
make 
superior 
chess 
plies 
(Charness, 
1977), 
which 
is 
the 
critical 
resource 
functionality 
(Peteraf 
& 
Bergen, 
2003). 
The 
emergence 
of 
AI-based 
chess 
engines 
led 
to 
the 
creation 
of 
centaur 
and 
engine 
chess 
competitions. 
While 
these 
competitions 
are 
played 
in 
separate 
competitive 
niches 
(i.e., 
with 
their 
own 
tournaments), 
they 
belong 
to 
the 
same 
domain 
(i.e., 
chess 
competition), 
because 
the 
same 
players 
compete 
across 
these 
formats, 
and 
the 
same 
tournament 
organizers 
and 
audiences 
assign 
their 
attention 
and 
other 
scarce 
resources 
to 
them. 
We 
explore 
next 
whether 
and 
how 
the 
adoption 
of 
engines 
with 
their 
own 
chess 
playing 
capabilities 
substitutes 
humans' 
corresponding 
capabilities 
and 
assess 
the 
relevant 
impact 
on 
the 
performance 
differences. 


4.1.1 
| 
Human 
capabilities 
in 
conventional 
chess 
Table 
1 
provides 
the 
results 
of 
a 
regression 
analysis 
that 
predicts 
the 
focal 
chess 
player's 
game 
result 
as 
a 
function 
of 
player 
and 
opponent 
capabilities, 
as 
well 
as 
the 
control 
variables' 
vector, 
in 
order 
to 
establish 
a 
baseline 
for 
human 
capabilities' 
role 
in 
conventional 
chess. 
As 
expected, 
player 
capabilities 
are 
associated 
with 
increased 
(decreased) 
chances 
of 
winning 
(losing) 
a 
conventional 
game, 
while 
the 
inverse 
is 
true 
of 
opponent 
capabilities. 
The 
raw 
coefficients 
in 
multinomial 
models 
are 
notoriously 
difficult 
to 
interpret. 
We 
illustrate 
them 
by 
calculating 
the 
average 
marginal 
effect 
(AME) 
of 
changing 
an 
independent 
variable's 
value 
with 
respect 
to 
the 
probability 
of 
observing 
an 
outcome, 
maintaining 
the 
other 
independent 
variables' 
observed 
values, 
and 
then 
calculating 
the 
average 
across 
the 
observations. 
A 
one 
standard 
deviation 
higher 
player 
Elo 
(i.e., 
182.75), 
ceteris 
paribus, 
increases 
the 
chances 
of 
winning 
by 
roughly 
22% 
(with 
an 
AME 
of 
0.0012), 
and 
decreases 
the 
chances 
of 
losing 
by 
roughly 
16% 
(0.0009). 


From 
a 
theoretical 
perspective, 
the 
RBV 
describes 
humans' 
domain-specific 
decision 
making 
capabilities 
as 
an 
important 
source 
of 
competitive 
advantage 
(Kunc 
& 
Morecroft, 
2010). 
In 
our 
domain, 
human 
chess 
playing 
capabilities 
are 
valuable 
and 
rare 
(Barney, 
1991): 
Valuable, 
because 
they 
allow 
players 
to 
make 
better 
chess 
plies, 
therefore 
ultimatelyincreasingtheir 
chance 
of 
winning(Chassy 
& 
Gobet, 
2011), 
and 
rare, 
because 
humans 
must 
endure 
a 
long 
learning 
process 
to 
develop 
this 
expertise, 
which 
creates 
capability 
differentials 
(Castanias 
& 
Helfat, 
2001) 
and 
supply 
restrictions 
(Levinthal 
& 
Wu, 
2010). 
Human 
chess 
playing 
capabilities' 
tacit 
nature 
also 
means 
they 
cannot 
be 
easily 
imitated 
or 
traded 
(Miller 
& 
Shamsie, 
1996). 


4.1.2 
| 
Human 
capabilities 
after 
AI 
adoption 
We 
proceed 
by 
investigating 
what 
happens 
to 
human 
chess 
playing 
capabilities 
when 
we 
examine 
games 
played 
by 
the 
same 
players 
in 
centaur 
and 
engine 
chess 
tournaments. 
While 
it 
is 



TABLE 
1 
Effect 
of 
player 
capabilities 
in 
the 
conventional, 
centaur, 
and 
engine 
tournament 
formats 


IndependentvariableConventionalgamesCentaurgamesEnginegames
Outcome 
Win 
Loss 
Win 
Loss 
Win 
Loss 


Player 
capabilities 
0.0048 
(.0000) 
−0.0040 
(.0000) 
0.0001 
(.7955) 
−0.0009 
(.0371) 
−0.0208 
(.6025) 
−0.0273 
(.7848) 
Opponent 
capabilities 
−0.0060 
(.0000) 
0.0030 
(.0000) 
−0.0006 
(.0341) 
0.0003 
(.3669) 
−0.0039 
(.0700) 
−0.0013 
(.5343) 
Player 
set 
−0.5302 
(.0000) 
0.2149 
(.0059) 
−0.5059 
(.0048) 
0.6635 
(.0004) 
−1.6524 
(.0279) 
1.2560 
(.0912) 
Player 
members 
0.1637 
(.5206) 
−1.3012 
(.0255) 
Player 
gender 
−0.3650 
(.0217) 
−0.1877 
(.2861) 
−2.1446 
(.0553) 
−1.1781 
(.1490) 
Player 
age 
−0.0206 
(.0119) 
−0.0040 
(.6355) 
−0.0004 
(.9710) 
0.0070 
(.5683) 
−0.9920 
(.1230) 
−0.2492 
(.6615) 
Tournament 
system 


K.O. 
0.1807 
(.1359) 
0.3012 
(.0229) 
−1.8134 
(.0038) 
−1.3638 
(.0387) 
Round-Robin 
−0.5858 
(.1999) 
−0.0325 
(.9448) 
Scheveningen 
−0.0928 
(.7713) 
0.3885 
(.2428) 
Simultaneous 
1.3296 
(.1211) 
−14.2804 
(.9811) 
Tournament 
round 
−0.0179 
(.0900) 
0.0241 
(.0388) 
0.0321 
(.2354) 
0.0526 
(.0702) 
−0.1422 
(.0771) 
−0.0835 
(.2885) 
Time 
controls 
Rapid 
(<60 
min; 
>10 
min) 
0.6822 
(.0000) 
0.7238 
(.0000) 
−0.0019 
(.9969) 
0.1362 
(.7858) 
Blitz 
(≤10 
min) 
1.1115 
(.0000) 
1.2022 
(.0000) 
1.6001 
(.1972) 
1.9390 
(.1247) 


Constant 
−10.5301 
(.9903) 
1.8149 
(.1078) 
−17.6551 
(.9971) 
0.3667 
(.8500) 
77.9088 
(.9213) 
62.0155 
(.7279) 
Controls 
(coefficients 
omitted) 
Player 
federation, 
year, 
quarter 
Pseudo 
R2 
12.78% 
14.21% 
29.35% 
N 
4,929 
905 
122 


Note: 
Multinomial 
logistic 
regression. 
Base 
outcome: 
draw. 
p-values 
in 
parentheses. 


KRAKOWSKIETAL.11



itive 
that 
human 
chess 
playing 
capabilities 
promote 
wins 
and 
prevent 
losses 
in 

is 
less 
clear 
if, 
and 
to 
what 
extent, 
these 
capabilities 
play 
a 
role 
in 
determining 
performance 
in 
the 
other 
tournament 
formats. 
The 
centaur 
and 
engine 
game 
results 
presented 
in 
Table 
1 
suggest 
that 
the 
player 
capability 
effects 
largely 
vanish 
after 
the 
adoption 
of 
AI, 
with 
the 
one 
remaining 
effect 
being 
a 
negligible 
prevention 
of 
losses 
in 
centaur 
games 
(with 
an 
AME 
suggesting 
a 
slight 
decrease 
of 
0.01% 
in 
the 
risk 
of 
losing 
rather 
than 
drawing). 
Traditional 
chess 
playing 
capabilities' 
overall 
negligible 
effects 
provide 
evidence 
that 
the 
machine's 
computational 
capabilities 
substitute 
human 
cognitive 
capabilities. 


To 
investigate 
this 
substitutive 
effect 
more 
directly, 
we 
replace 
the 
game 
results 
with 
the 
numbers 
of 
positive 
and 
negative 
plies 
as 
alternative 
outcome 
variables 
by 
using 
Poisson 
models. 
In 
respect 
of 
centaur 
games, 
we 
find 
that 
compared 
with 
conventional 
games, 
the 
expected 
log 
count 


−0.8684 


of 
the 
number 
of 
positive 
plies 
decreases 
by 
0.8684. 
The 
incident 
rate 
ratio 
(IRR) 
of 
e 
= 
0.42 
suggests 
that 
the 
positive 
plies' 
incident 
rate 
in 
centaur 
games 
is, 
ceteris 
paribus, 
0.42 
times 
that 
of 
conventional 
games. 
Furthermore, 
negative 
plies' 
incident 
rate 
is 
0.16 
times 
that 
of 
conventional 
games. 
In 
terms 
of 
engine 
games, 
there 
is 
no 
change 
in 
the 
number 
of 
positive 
plies, 
but 
a 
large 
decrease 
in 
the 
number 
of 
negative 
plies. 
Overall, 
these 
findings 
indicate 
that 
centaur 
and 
engine 
games 
reduce 
negative 
and/or 
positive 
plies 
(see 
Table 
S6). 


We 
explore 
this 
tendency 
toward 
convergence 
further 
by 
estimating 
two 
fixed-effects 
panel 
models 
with 
standard 
errors 
clustered 
at 
the 
player 
level, 
using 
a 
draw 
outcome 
(logistic 
model) 
and 
the 
number 
of 
plies 
per 
game 
(Poisson 
model) 
as 
dependent 
variables 
in 
our 
full 
sample 
that 
comprises 
all 
three 
tournament 
formats. 
The 
logistic 
model 
shows 
that, 
compared 
with 
conventional 
games, 
centaur 
games 
increase 
the 
log 
odds 
of 
a 
draw 
by 
1.0680 
or 
a 
factor 
of 


1.0680 
1.6522

e 
= 
2.91, 
while 
the 
engine 
games 
do 
so 
by 
a 
factor 
of 
e 
= 
5.22. 
The 
Poisson 
model 
shows 
that, 
compared 
with 
conventional 
games, 
the 
total 
number 
of 
plies 
is 
1.26 
times 
higher 
in 
centaur 
and 
1.65 
times 
higher 
in 
engine 
games. 
These 
findings 
show 
that 
tournaments 
with 
machines 
yield 
more 
draws 
and 
longer 
games, 
which 
is 
further 
evidence 
that 
the 
adoption 
of 
AI-based 
machines 
eliminates 
performance 
differences 
(see 
Table 
S7). 


We 
proceed 
by 
discussing 
our 
findings 
regarding 
AI's 
substitution 
effects. 
As 
a 
general-
purpose 
resource 
(Brynjolfsson 
& 
McAfee, 
2014, 
p. 
31), 
AI 
has 
a 
high 
fungibility, 
which 
prior 
RBV 
research 
associates 
with 
great 
potential 
for 
substitution 
across 
domains 
(Levinthal 
& 
Wu, 
2010). 
In 
the 
chess 
domain, 
AI-based 
engines 
can, 
like 
humans, 
provide 
the 
functionality 
of 
making 
high-quality 
chess 
plies, 
although 
it 
is 
based 
on 
a 
different 
type 
of 
underlying 
resource, 
which 
describes 
a 
typical 
substitution 
scenario 
(Peteraf 
& 
Bergen, 
2003). 
Given 
their 
superior 
computational 
capacity, 
chess 
engines 
process 
information 
far 
more 
comprehensively 
and 
rapidly 
than 
humans.11 
Machines 
are 
never 
tired 
or 
emotional, 
and 
their 
calculations 
are 
accurate. 
This 
means 
that 
the 
way 
machines 
play 
chess 
differs 
from 
the 
way 
humans 
do, 
because 
humans 
have 
imperfect 
memories, 
are 
highly 
selective 
in 
the 
options 
they 
consider, 
and 
make 
blunders 
when 
they 
are 
tired 
or 
emotional 
(Cowen, 
2013, 
p. 
104). 
With 
superior 
functionality 
in 
terms 
of 
identifying 
high-quality 
chess 
plies 
(Collins, 
2017; 
Silver 
et 
al., 
2018), 
chess 
engines 
can 
substitute 
human 
chess 
playing 
capabilities 
completely, 
rendering 
this 
resource 
obsolete 
(Polidoro 
& 
Toh, 
2011). 
Consequently, 
human 
chess 
playing 
capabilities 
no 
longer 
fulfill 
the 
RBV's 
criteria 
as 
a 
valuable 
and 
rare 
resource 
(Barney, 
1991) 
in 
centaur 
and 
engine 
chess 
competitions. 



11For 
example, 
the 
chess 
engine 
Stockfish 
(TCEC, 
2020) 
is 
capable 
of 
searching 
60 
million 
board 
positions 
per 
second 
when 
suggesting 
the 
best 
chess 
plies 
for 
a 
given 
position 
(Silver 
et 
al., 
2018). 



KRAKOWSKI 
ET 



role 
of 
machine 
capabilities 
To 
assess 
the 
role 
of 
machine 
chess 
ude 
a 
control 
variable 
for 
these 
capabilities 
in 
centaur 
and 
engine 
games. 
The 
results 
in 
Table 
2 
provide 
no 
evidence 
of 
a 
relationship 
between 
machine 
capabilities 
and 
chess 
performance. 
This 
suggests 
that 
the 
substitution 
that 
occurs 
due 
to 
machines' 
introduction 
not 
only 
effectively 
ousts 
the 
previous 
human-derived 
performance 
differences, 
but 
also 
that 
the 
machine 
capabilities 
do 
not 
introduce 
new 
differences. 


One 
of 
our 
analysis' 
limitations 
is 
that 
the 
absence 
of 
empirical 
relationships 
between 
human 
or 
machine 
chess 
playing 
capabilities 
and 
chess 
performance 
does 
not 
demonstrate 
that 
there 
is 
a 
non-relationship. 
Unlike 
the 
standard 
regression 
testing 
that 
we 
used, 
Bayesian 
analysis 
allows 
us 
to 
glean 
evidence 
of 
absence, 
rather 
than 
mere 
absence 
of 
evidence 
(Keysers, 
Gazzola, 
& 
Wagenmakers, 
2020).12 
We 
therefore 
conduct 
a 
Bayesian 
analysis 
to 
explore 
the 
potential 
non-relationships 
further. 
The 
results 
of 
the 
Bayes 
factors 
(BF), 
the 
relevant 
Bayesian 
Information 
Criteria 
(BIC), 
and 
the 
R2 
values 
suggest 
strong 
(BF 
> 
20) 
to 
very 
strong 
(BF 
> 
150) 
evidence 
of 
the 
absence 
of 
non-trivial 
effects 
regarding 
the 
relationships 
presented 
in 
Sections 
4.1.2. 
and 
4.1.3.13 
In 
other 
words, 
human 
and 
machine 
chess 
playing 
capabilities 
have 
no 
material 
impact 
on 
chess 
performance 
in 
centaur 
and 
engine 
tournaments. 


We 
also 
used 
alternative 
variables 
for 
supplementary 
analyses 
in 
order 
to 
address 
potential 
identification 
and 
measurement 
issues. 
Chess 
engines 
do 
not 
only 
differ 
in 
terms 
of 
their 
capabilities, 
but 
also 
in 
their 
underlying 
architecture. 
Among 
other 
factors, 
different 
engines 
vary 
in 
how 
they 
search 
and 
evaluate 
chess 
plies 
in 
a 
game's 
different 
stages 
(Cowen, 
2013, 
p. 
77ff). 
We 
therefore 
tested 
a 
model 
that 
replaces 
machine 
capability 
with 
dummy 
variables 
for 
player 
machine 
indicating 
the 
chess 
engine 
types 
(i.e., 
Stockfish, 
Komodo, 
etc.). 
The 
findings 
do 
not 
suggest 
a 
relationship 
between 
player 
machine 
and 
game 
results 
in 
terms 
of 
wins 
or 
losses.14 
Our 
results 
also 
hold 
when 
we 
substitute 
time 
dummies 
with 
the 
time 
count 
variable 
in 
order 
to 
control 
for 
general 
learning 
effects 
that 
could 
originate 
from 
sample-wide 
learning 
among 
engines 
over 
time. 
For 
instance, 
engine-specific 
weaknesses 
could 
become 
known 
and 
exploited 
by 
other 
engines. 
However, 
this 
variable's 
inclusion 
does 
not 
affect 
our 
results 
meaningfully. 


Finally, 
the 
number 
of 
observations 
varies 
across 
the 
three 
tournament 
formats 
(see 
Tables 
1 
and 
2). 
We 
ascertained 
that 
this 
variance 
does 
not 
affect 
our 
results 
by 
using 
random 
samples, 
equal 
in 
size 
to 
the 
engine 
chess 
sample 
(i.e., 
the 
smallest 
of 
the 
three 
subsamples), 
for 
the 
conventional 
and 
the 
centaur 
tournament 
formats. 
Apart 
from 
the 
obvious 
reduction 
in 
power, 
such 
random 
selection 
does 
not 
affect 
our 
results 
materially 
(see 
Table 
S9). 


We 
conclude 
this 
section 
by 
discussing 
our 
findings 
regarding 
machine 
capabilities. 
There 
are 
many 
chess 
engines, 
whose 
chess 
playing 
capabilities 
vary 
(Wilkenfeld, 
2019). 
Several 
state-ofthe-
art 
engines, 
such 
as 
Stockfish, 
are 
free, 
open-source 
programs 
(Cilento, 
2019), 
while 
other 



12Bayesian 
analysis 
compares 
competing 
models, 
usually 
a 
null 
hypothesis 
and 
an 
alternative 
one, 
to 
evaluate 
the 
change 
in 
the 
odds 
from 
their 
prior 
to 
their 
posterior 
distribution 
in 
the 
observed 
data 
(Wagenmakers, 
2007). 
The 
Bayes 
factor 
captures 
this 
change 
by 
means 
of 
the 
ratio 
of 
the 
two 
competing 
hypotheses' 
marginal 
likelihood 
(Jeffreys, 
1961, 


p. 
30ff). 
A 
Bayes 
factor 
test 
yields 
evidence 
indicating 
whether, 
given 
the 
observed 
data, 
the 
null 
hypothesis 
or 
alternative 
hypothesis 
is 
more 
likely 
to 
be 
true, 
and, 
if 
so, 
what 
its 
probability 
is 
(Andraszewicz 
et 
al., 
2015). 
For 
further 
discussion 
of 
Bayesian 
methods 
in 
management 
research, 
we 
refer 
the 
interested 
reader 
to 
Zyphur 
and 
Oswald 
(2015). 
13In 
line 
with 
prior 
research, 
we 
use 
the 
widely 
accepted 
Raftery 
classification 
scheme 
(Kass 
& 
Raftery, 
1995; 
Raftery, 
1995). 
See 
Table 
S8 
for 
the 
Bayesian 
analysis 
results 
and 
further 
explanations 
of 
the 
classification 
scheme. 
14We 
conducted 
similar 
tests 
to 
investigate 
the 
effects 
of 
other 
potential 
sources 
of 
machine 
heterogeneity, 
such 
as 
engine 
programming 
language 
(i.e., 
C++, 
C, 
Pascal/Delphi, 
or 
asm/other), 
legal 
attribute 
(i.e., 
open 
source, 
commercial, 
or 
private), 
and 
vendor 
organization 
(i.e., 
ChessOK, 
ChessBase, 
or 
independent), 
which 
did 
not 
have 
a 
material 
impact. 



E 
2 
ine 
capabilities 
in 
the 
centaur 
and 
engine 
tournament 
formats 


Independent 
s 
Engine 
games 
Outcome 
Win 
Loss 
Win 
Loss 
Player 
capabilities 
−0.0003 
(.5762) 
−0.0016 
(.0085) 
0.0577 
(.5857) 
−0.0228 
(.8412) 
Machine 
capabilities 
0.0004 
(.8480) 
−0.0004 
(.8417) 
−0.0696 
(.2845) 
−0.0048 
(.9201) 
Opponent 
capabilities 
−0.0006 
(.1392) 
0.0005 
(.2793) 
−0.0094 
(.1425) 
−0.0020 
(.6463) 
Player 
set 
−0.3997 
(.1026) 
0.9537 
(.0010) 
−21.0781 
(.9966) 
−0.3694 
(.7723) 
Player 
members 
−0.0675 
(.8433) 
−26.1369 
(.9874) 
Player 
gender 
−2.2525 
(.1103) 
10.6006 
(.9928) 
Player 
age 
−0.0058 
(.7382) 
0.0205 
(.2844) 
5.5582 
(.3011) 
1.3977 
(.6342) 
Tournament 
system 
K.O. 
Round-Robin 
−0.5498 
(.3236) 
−0.5481 
(.4706) 
Scheveningen 
Simultaneous 
Tournament 
round 
0.0582 
(.0943) 
0.0612 
(.1198) 
0.0390 
(.8586) 
−0.2414 
(.0779) 
Time 
controls 
Rapid 
(<60 
min; 
>10 
min) 
−0.2975 
(.6450) 
0.2186 
(.7701) 
Blitz 
(≤10 
min) 
2.3335 
(.1239) 
2.3355 
(.1851) 
Constant 
−0.3896 
(.9416) 
26.6596 
(.9872) 
−115.9203 
(.9928) 
−4.1883 
(.9850) 
Controls 
(coefficients 
Player 
federation, 
year, 
quarter 
omitted) 
Pseudo 
R2 
18.43% 
51.01% 
N 
499 
74 


Note: 
Multinomial 
logistic 
regression. 
Base 
outcome: 
draw. 
p-values 
in 
parentheses. 


engines, 
such 
as 
Komodo 
and 
Houdini, 
are 
commercial, 
but 
can 
be 
downloaded 
from 
the 
Internet 
at 
a 
relatively 
low 
price.15 
There 
are 
also 
private 
engines, 
such 
as 
IBM's 
Deep 
Blue 
(Campbell, 
Hoane, 
& 
Hsu, 
2002) 
and 
DeepMind's 
AlphaZero 
(Silver 
et 
al., 
2018), 
which 
sometimes 
introduce 
new 
technologies 
allowing 
superior 
performance. 
However, 
these 
engines' 
advantages 
tend 
to 
be 
short-lived, 
because 
open-source 
solutions 
quickly 
adopt 
similar 
technologies.16 


Developers 
can 
offer 
AI-based 
chess 
engines 
for 
free 
or 
at 
a 
low 
price, 
since 
these 
digital 
resources 
are 
scale 
free, 
which 
means 
they 
can 
be 
infinitely 
copied 
and 
used 
without 
being 
depleted 
(Levinthal 
& 
Wu, 
2010). 
Since 
chess 
engines 
are 
widely 
available, 
and 
players 
can 
choose 
freely 
among 
them, 
this 
resource 
has 
few 
supply 
restrictions 
and 
mobility 
barriers 
(Barney, 
1986; 



15At 
the 
time 
of 
writing, 
these 
chess 
engines' 
professional 
versions 
are 
available 
for 
roughly 
USD 
60. 
16For 
example, 
IBM's 
Deep 
Blue 
introduced 
heuristics 
into 
chess 
engines, 
but 
non-proprietary 
chess 
engines 
surpassed 
its 
chess-playing 
capabilities 
rapidly 
(Campbell 
et 
al., 
2002). 
DeepMind's 
AlphaZero 
was 
the 
first 
to 
use 
neural 
networks 
in 
its 
chess 
engine, 
which 
allowed 
it 
to 
beat 
Stockfish 
in 
laboratory 
tests 
(Silver 
et 
al., 
2018), 
but 
just 
months 
later 
an 
open-source 
version, 
called 
Leela 
Chess 
Zero, 
became 
available 
for 
chess 
tournaments 
(Wilkenfeld, 
2019). 
While 
Leela 
Chess 
Zero 
won 
the 
engine-chess 
world 
championship 
in 
2019, 
a 
new 
Stockfish 
version 
incorporating 
a 
neural 
network 
regained 
the 
title 
in 
2020 
(TCEC, 
2020). 







hermore, 
chess 
ral 
purpose 
AI 
technologies 
(Brynjolfsson 
& 
McAfee, 
2014, 
p. 
31), 
which 
competing 
engines 
can 
also 
adopt, 
therefore 
eroding 
new 
engines' 
initial 
performance 
advantages 
rapidly. 
In 
keeping 
with 
prior 
RBV 
assumptions 
(Barney, 
1991; 
Levinthal 
& 
Wu, 
2010), 
we 
conclude 
that 
technological 
solutions, 
even 
advanced 
AI-based 
engines, 
do 
not 
fulfill 
the 
criteria 
regarding 
sustaining 
resource 
heterogeneity. 


4.2 
| 
Human–machine 
resource 
complementation 
Our 
results 
thus 
far 
indicate 
substitution, 
with 
traditional 
chess 
playing 
capabilities 
rendered 
obsolete 
in 
terms 
of 
determining 
game 
results 
in 
the 
centaur 
and 
engine 
chess 
tournament 
formats. 
Having 
focused 
on 
the 
erosion 
of 
these 
previously 
valuable 
capabilities, 
we 
next 
investigate 
whether 
there 
is 
also 
evidence 
of 
complementation 
(Argyres 
& 
Zenger, 
2012) 
between 
humans' 
and 
machines' 
capabilities. 


4.2.1 
| 
A 
new 
source 
of 
performance 
differentials 
After 
chess 
engines' 
introduction 
into 
tournaments 
in 
the 
mid-2000s, 
centaur 
chess 
received 
most 
of 
the 
attention 
(Collins, 
2017). 
Kasparov 
(2017, 
p. 
246) 
commented 
on 
a 
2005 
chess 
tournament 
during 
which 
centaur 
teams 
had 
beaten 
the 
strongest 
machines, 
“Human 
strategic 
guidance 
combined 
with 
[the] 
tactical 
acuity 
of 
a 
computer 
is 
overwhelming.” 
Further 
technological 
progress 
shifted 
attention 
from 
human–machine 
chess 
playing 
to 
other 
forms 
of 
complementation 
between 
humans 
and 
machines. 
Humans 
can 
influence 
centaur 
and 
engine 
game 
outcomes 
by 
selecting 
a 
chess 
engine, 
tuning 
its 
parameters, 
and 
developing 
the 
databases 
that 
the 
engine 
uses 
(Ensmenger, 
2012; 
Suba, 
2010, 
p. 
29). 
This 
influencing 
occurs 
when 
humans 
draw 
on 
their 
unique 
human 
capabilities, 
such 
as 
their 
creativity, 
which 
enables 
them 
to 
tune 
their 
engine 
in 
ways 
that 
exploit 
an 
opponent 
machine's 
weaknesses; 
their 
large-scale 
contextualization, 
which 
enables 
them 
to 
select 
engines 
or 
parameters 
that 
surprise 
their 
opponents; 
and 
their 
social 
interaction 
within 
the 
chess 
community, 
which 
allows 
them 
to 
develop 
an 
arsenal 
of 
possible 
strategies 
to 
interact 
with 
chess 
engines.17 


We 
next 
examine 
the 
potential 
role 
of 
these 
novel 
human–machine 
capabilities. 
Table 
3 
shows 
the 
results 
of 
estimating 
the 
impact 
of 
human–centaur 
capabilities 
(for 
centaur 
chess 
games) 
and 
human–engine 
capabilities 
(for 
engine 
chess 
games) 
in 
terms 
of 
determining 
the 
focal 
player's 
game 
result. 
The 
results 
in 
Table 
3 
show 
that 
these 
human–machine 
capabilities 
have 
new, 
significant 
effects 
on 
game 
results. 
These 
effects 
are 
asymmetric, 
with 
the 
capabilities 
leading 
to 
wins 
in 
centaur 
games 
and 
preventing 
losses 
in 
engine 
games. 
To 
illustrate, 
a 
one-
standard 
deviation 
increase 
in 
human–machine 
capabilities 
(i.e., 
19.60) 
increases 
the 
likelihood 
of 
winning 
a 
centaur 
game 
by 
7.6% 
(AME 
of 
0.0039), 
and 
decreases 
the 
likelihood 
of 
losing 
an 
engine 
game 
by 
8.4% 
(−0.037). 
Overall, 
the 
findings 
suggest 
the 
presence 
of 
new 
domain-
specific 
human 
capabilities 
that, 
like 
traditional 
chess 
playing 
capabilities, 
have 
supply 
and 
imitation 
restrictions. 


We 
ensure 
the 
validity 
of 
our 
findings 
by 
conducting 
supplementary 
analyses 
of 
our 
new 
measures 
of 
human–machine 
capabilities. 
These 
measures 
could 
contain 
noise 
relating 
to 



17These 
illustrative 
examples 
of 
human-machine 
capabilities 
are 
taken 
from 
machine 
chess 
forums 
(such 
as 
https:// 
forum.computerschach.de) 
and 
tournament 
reports 
(such 
as 
http://www.infinitychess.com/tournaments/reports). 



KRAKOWSKI 
ET 


TABLE 
3 
n–machine 
capabilities 
aur 
and 
engine 
tournament 
formats 


Independent 
variable 
Centaur 
games 
Engine 
games 
Outcome 
Win 
Loss 
Win 
Loss 
Player 
capabilities 
0.0001 
(.7947) 
−0.0008 
(.0479) 
−0.0208 
(.6128) 
−0.0636 
(.6332) 
Human–centaur 
capabilities 
0.0216 
(.0001) 
−0.0084 
(.1515) 
0.0667 
(.8067) 
0.0870 
(.8826) 
Human–engine 
capabilities 
−0.0311 
(.6485) 
0.0029 
(.9705) 
0.0366 
(.7649) 
−0.4232 
(.0351) 
Opponent 
capabilities 
−0.0006 
(.0298) 
0.0003 
(.3812) 
−0.0039 
(.0761) 
−0.0018 
(.4255) 
Player 
set 
−0.5127 
(.0049) 
0.6757 
(.0003) 
−1.5609 
(.0404) 
1.1697 
(.1565) 
Player 
members 
0.0261 
(.9206) 
−1.3321 
(.0269) 
Player 
gender 
−2.1547 
(.0565) 
−1.1561 
(.1654) 
Player 
age 
0.0018 
(.8864) 
0.0051 
(.6841) 
−0.9301 
(.1619) 
−0.4571 
(.4928) 
Tournament 
system 
K.O. 
−1.4675 
(.0224) 
−1.3885 
(.0368) 
Round-Robin 
−0.6279 
(.1718) 
−0.0029 
(.9950) 
Scheveningen 
Simultaneous 
Tournament 
round 
0.0310 
(.2560) 
0.0562 
(.0550) 
−0.1431 
(.0771) 
−0.0806 
(.3248) 
Time 
controls 
Rapid 
(<60 
min; 
>10 
min) 
−0.1640 
(.7443) 
0.1435 
(.7754) 
Blitz 
(≤10 
min) 
1.4772 
(.2367) 
1.9550 
(.1228) 
Constant 
−18.0122 
(.9966) 
0.5923 
(.7614) 
71.1444 
(.9773) 
138.4705 
(.5567) 
Controls 
(coefficients 
omitted) 
Player 
federation, 
year, 
quarter 
Pseudo 
R2 
15.90% 
32.58% 
N 
905 
122 


Note: 
Multinomial 
logistic 
regression. 
Base 
outcome: 
draw. 
p-values 
in 
parentheses. 


higher-order 
effects, 
notably 
experience 
or 
learning 
in 
the 
relevant 
tournament 
formats. 
We 
investigate 
whether 
this 
possibility 
could 
be 
an 
alternative 
explanation 
for 
our 
findings 
by 
controlling 
for 
centaur 
and 
engine 
experience 
(i.e., 
the 
number 
of 
games 
played 
in 
the 
corresponding 
formats 
using 
the 
relevant 
centaur 
games 
played 
and 
engine 
games 
played 
variables). 
This 
alternative 
model 
specification 
leaves 
our 
findings 
largely 
unchanged, 
suggesting 
that 
our 
measures 
capture 
the 
underlying 
capabilities 
rather 
than 
mere 
experience 
effects 
(Anand, 
Mulotte, 
& 
Ren, 
2016). 
Interestingly, 
the 
variables 
centaur 
games 
played 
and 
engine 
games 
played, 
do 
not 
affect 
the 
game 
results. 
This 
is 
logical, 
given 
that 
chess 
players, 
inter 
alia, 
acquire 
their 
chess 
capability 
outside 
official 
tournaments, 
especially 
by 
practicing 
in 
domestic 
club 
tournaments 
or 
private 
competitions. 
In 
addition, 
we 
address 
the 
relatively 
high 
correlation 
between 
(and, 
relatedly, 
high 
VIFs 
for) 
human–engine 
capabilities 
and 
engine 
games 
played, 
which 
we 
mentioned 
in 
our 
earlier 
discussion 
of 
descriptive 
statistics. 
In 
an 
analysis 
without 
the 
engine 
games 
played 
variable, 
the 
estimates 
remain 
stable 
in 
terms 
of 
magnitude 
and 
p-values 
(see 
Tables 
S10 
and 
S11). 


To 
address 
potential 
path 
dependency 
(or 
tautology) 
concerns 
(i.e., 
estimates 
based 
on 
past 
performance 
affecting 
future 
performance) 
associated 
with 
our 
new 
human–machine 
capability 





ures, 
we 
search 
for 
truct 
that 
 
underlying 
effects 
(i.e., 
players' 
proficiency 
with 
the 
respective 
engines) 
without 
being 
directly 
associated 
with 
previous 
game 
outcomes. 
We 
select 
human–engine 
scope, 
which 
is 
defined 
as 
the 
number 
of 
distinct 
engines 
a 
focal 
chess 
player 
used 
in 
prior 
centaur 
and 
engine 
tournaments. 
We 
find 
that 
human–engine 
scope 
has 
a 
positive 
effect 
on 
centaur 
game 
results 
in 
terms 
of 
preventing 
losses, 
which 
supports 
our 
main 
findings 
(see 
Table 
S12). 


In 
addition, 
we 
include 
machine 
capabilities 
in 
the 
estimation, 
which 
we 
had 
initially 
omitted 
to 
enable 
comparison 
with 
conventional 
games. 
Overall, 
this 
variable's 
inclusion 
provides 
further 
corroborative 
evidence 
despite 
a 
high 
correlation 
between 
machine 
capabilities 
and 
human–engine 
capabilities 
(0.67). 
We 
do 
not 
expect 
this 
high 
correlation 
to 
translate 
into 
a 
collinearity 
issue 
for 
the 
following 
reasons: 
First, 
the 
VIFs 
are 
still 
within 
an 
acceptable 
range 
(3.45 
and 
7.73) 
in 
models 
containing 
the 
two 
variables; 
second, 
while 
including 
machine 
capabilities 
in 
the 
engine 
games' 
estimation 
renders 
the 
human–engine 
capabilities 
coefficient 
insignificant, 
additional 
analysis 
shows 
that 
this 
is 
due 
to 
the 
decreased 
sample 
size 
and 
not 
to 
collinearity. 
Running 
the 
regression 
for 
the 
same 
74 
observations 
without 
machine 
capabilities 
as 
a 
covariate 
also 
renders 
the 
coefficient 
insignificant, 
therefore 
yielding 
ahighlycomparableresultinterms 
of 
magnitudeand 
p-values 
(see 
Tables 
S13 
and 
S14). 


Finally, 
similar 
to 
the 
prior 
analyses 
(see 
Tables 
1 
and 
2), 
the 
number 
of 
observations 
varies 
across 
the 
tournament 
formats 
(see 
Table 
3). 
We 
again 
use 
random 
samples 
for 
the 
conventional 
and 
the 
centaur 
tournament 
formats, 
equal 
in 
size 
to 
the 
full 
sample 
for 
engine 
chess 
(i.e., 
the 
smallest 
of 
the 
three 
subsamples). 
Our 
results 
remain 
substantially 
unchanged, 
apart 
from 
an 
expected 
reduction 
in 
statistical 
power 
(see 
Table 
S15). 


We 
next 
discuss 
our 
findings 
regarding 
AI's 
complementation 
effects. 
In 
both 
centaur 
and 
engine 
chess 
competitions, 
humans 
can 
create 
new, 
uniquely 
complementary 
resource 
bundles 
(Argyres 
& 
Zenger, 
2012) 
by 
integrating 
the 
machine 
capabilities 
with 
their 
own 
capabilities. 
These 
resource 
bundles 
are 
heterogeneous, 
because 
humans 
learn 
to 
interact 
with 
machines 
through 
personal 
experience. 
Such 
experience 
creates 
persistent 
capability 
differentials 
across 
individuals 
(Castanias 
& 
Helfat, 
2001). 
Furthermore, 
limited 
understanding 
of 
how 
exactly 
humans 
add 
value 
to 
machines 
in 
centaur 
and 
engine 
chess 
should 
create 
causal 
ambiguity, 
which 
makes 
transferring 
or 
imitating 
these 
capabilities 
difficult 
(Miller 
& 
Shamsie, 
1996).18 
When 
actors 
compete 
like 
chess 
players 
do, 
their 
adversarial 
relationship 
and 
the 
resulting 
lack 
of 
motivation 
to 
share 
practices 
are 
additional 
barriers 
to 
knowledge 
transfer 
(Szulanski, 
1996). 
Furthermore, 
human 
capabilities' 
domain 
specificity 
imposes 
limits 
on 
the 
new 
complementary 
capabilities' 
mobility 
(Helfat 
& 
Peteraf, 
2015). 
Overall, 
the 
new 
human–machine 
capabilities 
are 
valuable 
(for 
winning 
games), 
while 
simultaneously 
imposing 
supply 
and 
imitation 
restrictions. 


4.2.2 
| 
The 
relationship 
between 
traditional 
and 
new 
capabilities 
Finally, 
we 
turn 
our 
attention 
to 
the 
relationship 
between 
traditional 
and 
new 
advantage-
generating 
chess 
capabilities. 
Table 
4 
provides 
the 
results 
of 
estimating 
focal 
chess 
players' 
human–centaur 
capabilities, 
measured 
in 
centaur 
games, 
and 
their 
human–engine 
capabilities, 



18Despite 
an 
extensive 
search, 
we 
could 
not 
find 
a 
single 
reference 
explaining 
how 
exactly 
human 
players 
add 
value 
in 
engine 
chess 
tournaments, 
which 
illustrates 
the 
causal 
ambiguity 
argument. 
We 
did, 
however, 
find 
highly 
idiosyncratic 
comments 
on 
machine 
chess 
forums 
and 
in 
tournament 
reports 
(see 
Footnote 
17). 
A 
reason 
for 
this 
apparent 
lack 
of 
explicit 
knowledge 
could 
be 
that 
players 
do 
not 
disclose 
the 
parameters 
of 
the 
specific 
machine 
implementations 
that 
they 
use 
during 
tournaments. 





tionship 
between 
chess-playing 
capabilities 
bilities 

able 
Human–centaur 
capabilities 
Human–engine 
capabilities 
Player 
capabilities 
−0.0331 
(.3355) 
−0.0602 
(.0632) 
Opponent 
capabilities 
0.0003 
(.8326) 
0.0014 
(.5347) 
Player 
set 
−0.2432 
(.8301) 
−0.8868 
(.2762) 
Player 
members 
0.5035 
(.7473) 
Player 
gender 
Player 
age 
−1.2465 
(.0216) 
−0.6224 
(.4822) 
Tournament 
system 
K.O. 
−8.7749 
(.2336) 
Round-Robin 
2.0230 
(.3289) 
Scheveningen 
Simultaneous 
Tournament 
round 
−0.0139 
(.8934) 
0.0179 
(.8260) 
Time 
controls 
Rapid 
(<60 
min; 
>10 
min) 
1.2877 
(.6925) 
Blitz 
(≤10 
min) 
2.9914 
(.5754) 
Constant 
147.9460 
(.0668) 
160.1268 
(.0520) 
Controls 
(coefficients 
omitted) 
Player 
federation, 
year, 
quarter 
R2 
(within 
subjects) 
3.47% 
12.92% 
N 
905 
84 


Note: 
Fixed-effects 
panel 
regression. 
SEs 
clustered 
at 
the 
player 
level. 
p-values 
in 
parentheses. 


measured 
in 
engine 
games 
as 
a 
function 
of 
human 
chess 
playing 
capabilities. 
The 
estimates 
of 
a 
fixed-effects 
panel 
model 
indicate 
a 
negative 
relationship 
between 
traditional 
chess 
playing 
capabilities 
and 
human–machine 
capabilities 
in 
engine 
games 
(with 
a 
p-value 
of 
.0632), 
and 
no 
such 
relationship 
in 
centaur 
games. 


We 
conducted 
another 
Bayesian 
analysis 
to 
explore 
this 
non-finding. 
The 
results 
confirm 
our 
initial 
estimations 
by 
providing 
evidence 
of 
the 
absence 
of 
a 
non-trivial 
relationship 
between 
traditional 
and 
new 
capabilities 
regarding 
centaur 
games 
(BF 
> 
3; 
see 
Table 
S16). 


Player 
self-selection 
could 
provide 
an 
alternative 
explanation 
of 
the 
non-relationship 
or 
negative 
association 
(i.e., 
the 
best 
players 
do 
not 
select 
themselves 
into 
centaur/engine 
chess). 
A 
closer 
look 
at 
the 
average 
player 
capability 
by 
year 
and 
tournament 
format 
reveals 
that 
in 
2005 
(the 
first 
year 
of 
centaur 
chess 
tournaments), 
the 
average 
player's 
Elo 
rating 
was 
2,462 
for 
centaur 
chess 
compared 
with 
2,487 
for 
conventional 
chess, 
while 
in 
2014 
(the 
first 
year 
of 
engine 
chess 
tournaments), 
it 
was 
1,947 
for 
engine 
chess 
compared 
with 
1,928 
for 
centaur 
chess. 
These 
similar 
capability 
levels 
do 
not 
suggest 
ex 
ante 
selection. 
However, 
the 
Elo 
ratings 
increasingly 
diverge 
across 
tournament 
formats 
in 
subsequent 
years, 
indicating 
ex 
post 
selection 
(see 
Table 
S17). 
We 
therefore 
analyzed 
the 
effects 
of 
chess 
playing 
capabilities 
and 
human– 
centaur 
capabilities 
in 
the 
early 
years 
after 
the 
centaur 
tournament 
format's 
introduction 
(i.e., 
2005–2008). 
The 
results 
show 
that 
the 
findings 
still 
hold 
for 
this 
subsample 





 
Tables 
.19 
Overall, 
these 
additional 
 
selection 
 
due 
to 
traditional 
chess 
playing 
capabilities' 
eroding 
value 
in 
centaur 
and 
engine 
tournaments, 
and 
that 
this 
ex 
post 
selection 
does 
not 
bias 
our 
results. 


These 
results 
indicate 
that 
the 
new 
human–machine 
capabilities 
are 
unrelated, 
or 
even 
negatively 
related, 
to 
humans' 
traditional 
chess 
playing 
capabilities–the 
capabilities 
that 
machines 
substitute 
(see 
Section 
4.1.2). 
In 
respect 
of 
centaur 
chess, 
Kasparov 
(2017, 
p. 
246) 
reported 
on 
the 
above-cited 
2005 
chess 
tournament 
that, 
“The 
surprise 
came 
at 
the 
conclusion 
of 
the 
event. 
The 
winner 
was 
revealed 
to 
be 
not 
a 
grandmaster 
with 
a 
state-of-the-art 
PC 
but 
a 
pair 
of 
amateur 
American 
chess 
players 
(…). 
Their 
skill 
at 
manipulating 
and 
“coaching” 
their 
computers 
to 
look 
very 
deeply 
into 
positions 
effectively 
counteracted 
the 
superior 
chess 
understanding 
of 
their 
grandmaster 
opponents.” 
Paradoxically, 
centaur 
chess 
players 
must 
not 
rely 
on 
their 
chess 
playing 
capabilities, 
which 
are 
inferior 
to 
those 
of 
the 
machine, 
but 
use 
other 
capabilities 
that 
allow 
them 
to 
complement 
the 
machine's 
capabilities. 
Leading 
players 
are 
therefore 
often 
not 
highly 
rated 
chess 
players, 
but 
computer 
engineers 
with 
modest 
chess 
capability, 
who 
approach 
the 
game 
from 
a 
computational 
point 
of 
view 
(Cassidy, 
2014). 
Similarly, 
the 
ability 
to 
select 
and 
tune 
chess 
engines 
in 
both 
centaur 
and 
machine 
chess 
is 
associated 
with 
general 
data 
science 
and 
creative 
capabilities 
rather 
than 
with 
specific 
chess 
playing 
capabilities 
(Cowen, 
2013, 
p. 
86).20 


To 
develop 
new 
complementary 
resource 
bundles, 
humans 
must 
have 
a 
flexible 
ability 
to 
go 
beyond 
domain-specific 
expertise 
when 
structuring, 
bundling, 
and 
leveraging 
resources 
(Sirmon 
et 
al., 
2007). 
Since 
humans 
develop 
their 
expertise 
in 
a 
path-dependent 
learning 
process 
(Helfat 
& 
Peteraf, 
2015), 
domain 
experts, 
who 
have 
focused 
their 
limited 
attention 
and 
resources 
on 
building 
domain-specific 
capabilities, 
usually 
have 
little 
general 
data 
science 
or 
augmentation 
capabilities 
(Davenport 
& 
Kirby, 
2016, 
p. 
189). 
Applied 
to 
our 
domain, 
this 
means 
that 
computer 
engineers 
initially 
have, 
and—due 
to 
their 
path-dependent 
learning— 
continue 
to 
have, 
an 
edge 
over 
traditional 
chess 
players 
with 
regard 
to 
human–machine 
capabilities. 
Conventional 
chess 
players 
are 
therefore 
likely 
to 
experience 
motivational 
problems 
when, 
as 
beginners, 
attempting 
to 
develop 
these 
capabilities 
in 
a 
new 
community 
(Lave 
& 
Wenger, 
1991, 
p. 
96). 
Although 
some 
of 
them 
may 
make 
the 
transition, 
acquiring 
new 
capabilities 
once 
again 
requires 
learning 
through 
experience, 
which 
is 
time 
consuming 
(Kogut 
& 
Zander, 
1992). 
As 
our 
findings 
show, 
it 
is 
therefore 
unlikely 
that 
actors 
who 
outperform 
in 
terms 
of 
traditional 
domain-specific 
capabilities 
are 
also 
able 
to 
do 
so 
in 
changed 
contexts 
where 
new 
and 
unrelated 
capabilities 
determine 
competitive 
advantage. 


5 
| 
DISCUSSION 


In 
the 
context 
of 
chess 
competition, 
we 
find 
that 
AI 
adoption 
has 
a 
dualistic 
effect 
that 
shifts 
the 
sources 
of 
competitive 
advantage: 
Although 
substituting 
humans' 
traditional, 
domain-
specific 
cognitive 
capabilities 
with 
machines' 
abundant 
computational 
ones 
destroys 
the 
existing 
advantage, 
complementation 
between 
previously 
domain-unrelated 
human 
and 
machine 



19We 
would 
like 
to 
point 
out 
that 
a 
corresponding 
analysis 
of 
engine 
chess 
is 
superfluous, 
given 
that 
our 
sample 
only 
comprises 
3 
years 
(2014–2016) 
in 
which 
such 
tournaments 
took 
place. 
20We 
obtained 
background 
information 
on 
12 
of 
the 
20 
centaur 
and 
engine 
chess 
tournament 
winners 
in 
our 
sample: 
10 
of 
the 
12 
studied 
computer 
science, 
data 
science, 
and/or 
software 
engineering 
and 
are 
currently 
employed 
in 
one 
of 
these 
domains. 
Only 
6 
of 
the 
12 
have 
an 
official 
chess 
rating, 
and 
these 
players 
have 
a 
modest 
Elo 
average 
of 
1,994, 
therefore 
not 
even 
reaching 
the 
2,000 
threshold 
required 
for 
chess's 
“expert” 
status 
(US 
Chess 
Federation, 
2004). 







 
persistent 
advantages. 
We 
now 
argue 
that 
these 
s 
competitions 

business 
contexts, 
but 
also 
acknowledge 
the 
limitations 
of 
such 
a 
generalization. 


5.1 
| 
AI 
substitution 
and 
complementation 
in 
chess 
versus 
business 
contexts 
With 
regard 
to 
substitution, 
machine 
capabilities 
have 
also 
become 
an 
alternative 
to 
humans' 
decision 
making 
and 
problem 
solving 
capabilities 
in 
business 
contexts 
such 
as 
consumer 
products, 
finance, 
healthcare, 
and 
insurance. 
This 
trend 
is 
likely 
to 
continue, 
“since 
[the] 
human/ 
machine 
performance 
gap 
will 
only 
increase” 
(Davenport 
& 
Kirby, 
2016, 
p. 
20). 
In 
line 
with 
our 
results, 
AI 
experts 
also 
do 
not 
expect 
this 
new 
technological 
resource's 
abundant 
availability 
to 
provide 
a 
sustainable 
advantage. 
For 
example, 
Davenport 
and 
Kirby 
(2016, 
p. 
204) 
expect 
companies' 
cost 
advantages 
from 
cognitive 
task 
automation 
to 
erode 
quickly, 
since 
competitors 
could 
simply 
imitate 
these 
automation 
strategies. 


However, 
there 
are 
also 
notable 
differences 
between 
substitution 
in 
the 
chess 
and 
business 
contexts. 
For 
example, 
chess 
players 
can 
choose 
to 
remain 
in 
a 
legacy 
niche 
that 
is 
no 
longer 
competitive 
(i.e., 
conventional 
chess), 
which 
is 
difficult 
in 
a 
market 
context. 
Firms 
that 
fail 
to 
realize 
the 
benefits 
that 
machine 
substitution 
affords, 
risk 
losing 
their 
competitive 
edge, 
which 
could 
cause 
their 
decline. 
While 
these 
differences 
strengthen 
the 
tendency 
toward 
substitution 
even 
further, 
others 
constrain 
it. 
Machines 
perform 
well 
under 
uncertainty 
(Ghahramani, 
2015), 
but 
need 
clear 
objectives 
and 
constraints 
to 
operate. 
While 
the 
goals 
and 
rules 
are 
clear 
and 
stable 
in 
chess, 
business 
contexts 
can 
be 
subject 
to 
goal 
conflicts 
(Cyert 
& 
March, 
1963), 
leading 
to 
negotiations 
and 
the 
breaking 
of 
rules 
(Williamson, 
1975). 
Machines 
also 
have 
limitations 
when 
there 
is 
little 
data, 
or 
when 
constant 
change 
makes 
using 
past 
decision 
patterns 
to 
predict 
future 
outcomes 
impossible 
(Raisch 
& 
Krakowski, 
2021). 
In 
these 
situations 
of 
high 
uncertainty, 
companies 
must 
continue 
relying 
on 
human 
intuition 
(Huang 
& 
Pearce, 
2015). 


These 
machine 
limitations 
imply 
that 
humans 
still 
have 
a 
role 
to 
play 
in 
the 
AI 
age 
(Murray 
et 
al., 
2021; 
Raisch 
& 
Krakowski, 
2021). 
Our 
findings 
show 
the 
importance 
of 
human–machine 
capabilities 
as 
a 
new 
source 
of 
advantage, 
even 
in 
chess 
competitions' 
controlled 
environment. 
In 
business 
contexts, 
AI 
experts 
also 
associate 
competitive 
advantage 
with 
human 
augmentation 
capabilities 
that 
complement 
machine 
capabilities, 
such 
as 
creative 
ideation, 
large-scale 
contextualization, 
and 
social 
interaction 
(Brynjolfsson 
& 
McAfee, 
2014, 
p. 
202). 
Consistent 
with 
our 
results, 
business 
actors 
with 
deep 
domain-specific 
capabilities 
may 
not 
be 
the 
ones 
with 
superior 
augmentation 
capabilities, 
which 
require 
both 
advanced 
data 
science 
capability 
and 
strong 
social 
or 
creative 
capabilities 
(Davenport 
& 
Kirby, 
2016, 
p. 
189). 
Brynjolfsson 
and 
McAfee 
(2014, 
p. 
194ff) 
similarly 
conclude 
that 
neither 
of 
these 
capabilities 
is 
commonly 
found 
in 
business 
actors 
whose 
education 
centered 
on 
acquiring 
domain-specific 
expertise, 
while 
building 
these 
capabilities 
now 
would 
require 
a 
long 
learning 
process. 


Despite 
these 
similarities, 
there 
are 
also 
differences. 
Some 
companies 
make 
large-scale 
investments 
to 
develop 
their 
employees' 
augmentation 
capabilities 
(Davenport 
& 
Westerman, 
2021) 
and 
design 
supportive 
organizational 
contexts 
for 
augmentation 
(Daugherty 
& 
Wilson, 
2018, 


p. 
105f). 
These 
investments, 
as 
well 
as 
similar 
governmental 
programs 
(Future 
of 
Life 
Institute, 
2021), 
increase 
the 
chances 
of 
human 
experts 
acquiring 
augmentation 
capabilities 
more 
so 
than 
those 
of 
chess 
players 
lacking 
similar 
supportive 
measures. 
Furthermore, 
the 
substitution 
of 
traditional 
domain-specific 
capabilities 
may 
not 
always 
be 
as 
comprehensive 
in 
business 

KRAKOWSKI 
ET 


contexts 
as 
etitions. 
For 
example, 
Raisch 
and 
Krakowski 
(2021) 
describe 
umers 
remain 
aborate 
with 
data 
scientists 
after 
AI's 
introduction 
into 
the 
fragrance 
industry. 
While 
machines 
substitute 
perfumers 
regarding 
certain 
problem 
solving 
activities, 
they 
are 
unable 
to 
match 
the 
perfumers' 
unique 
ability 
to 
smell 
fragrances 
and 
predict 
the 
human 
emotions 
they 
trigger. 
This 
example 
illustrates 
that 
AI 
is 
likely 
to 
substitute 
some, 
but 
not 
all 
of 
complex 
business 
tasks' 
activities. 
This 
difference 
increases 
the 
likelihood 
that 
certain 
traditional 
domain-specific 
capabilities 
remain 
valuable 
and, 
in 
turn, 
provide 
additional 
opportunities 
for 
combining 
them 
with 
machine 
capabilities 
to 
create 
unique 
complementarities. 


5.2 
| 
Theoretical 
implications 
The 
ways 
sources 
of 
competitive 
advantage 
change 
over 
time 
have 
received 
substantial 
research 
attention 
(Argyres 
& 
Zenger, 
2012; 
Levinthal 
& 
Wu, 
2010; 
Polidoro 
& 
Toh, 
2011). 
This 
literature 
has 
tended 
to 
treat 
a 
new 
resource 
as 
either 
a 
substitute 
or 
a 
complement, 
informing 
a 
contingency 
view 
(Hess 
& 
Rothaermel, 
2011; 
Stadler 
et 
al., 
2021): 
The 
resource 
is 
either 
related, 
thus 
providing 
the 
potential 
to 
substitute 
rather 
than 
complement, 
or 
it 
is 
unrelated, 
therefore 
enabling 
complementation 
rather 
than 
substitution. 
In 
contrast, 
our 
findings 
show 
substitution 
and 
complementation 
as 
interrelated 
effects. 
Therefore, 
unlike 
prior 
RBV 
research 
with 
its 
contingency 
view 
of 
substitution 
as 
an 
act 
of 
destroying 
advantage 
(Peteraf 
& 
Bergen, 
2003), 
and 
complementation 
as 
an 
act 
of 
creating 
advantage 
(Newbert, 
2007), 
we 
propose 
an 
integrated 
view 
of 
these 
simultaneously 
occurring 
acts 
that 
shift 
the 
sources 
of 
competitive 
advantage. 


We 
further 
identify 
AI 
as 
the 
driver 
of 
these 
new 
resource 
dynamics. 
RBV 
scholars 
traditionally 
described 
substitution 
as 
occurring 
between 
resources 
from 
related 
domains 
(Levinthal 
& 
Wu, 
2010; 
Peteraf 
& 
Bergen, 
2003). 
The 
latter 
was 
due 
to 
their 
focus 
on 
humans' 
domain-
specific 
cognitive 
capabilities, 
which 
lose 
their 
value 
in 
unrelated 
domains 
(Montgomery 
& 
Wernerfelt, 
1988).21 
In 
contrast, 
we 
observe 
that, 
as 
a 
general-purpose 
resource, 
AI 
enables 
substitution 
across 
previously 
unrelated 
domains, 
such 
as 
technology 
and 
chess 
competitions. 
For 
example, 
DeepMind 
outperformed 
the 
competition 
with 
no 
prior 
domain-specific 
chess 
expertise 
by 
exclusively 
relying 
on 
its 
AI-based 
capabilities 
(Silver 
et 
al., 
2018). 
Such 
substitution 
across 
unrelated 
domains 
is 
possible, 
because 
AI-based 
machines' 
general-purpose 
capabilities 
are 
widely 
applicable 
across 
domains, 
their 
scale-free 
nature 
allows 
substitution 
across 
multiple 
domains, 
and 
the 
use 
of 
machine 
learning 
reduces 
the 
need 
for 
domain-specific 
expertise. 


Combining 
these 
unrelated 
domains' 
heterogeneous 
resources 
could 
provide 
unique 
complementarities 
(Newbert, 
2007), 
which 
are 
scarce 
when 
substitution 
occurs 
between 
related 
domains. 
Such 
AI-based 
complementation 
differs 
from 
the 
RBV's 
traditional 
perspective. 
In 
prior 
complementation 
accounts, 
domain 
experts 
purposefully 
explored 
a 
new 
unrelated 
resource 
that 
they 
integrated 
into 
their 
existing 
bundle 
of 
domain-specific 
resources 
(Argyres 
& 
Zenger, 
2012).22 
Such 
complementation 
extends 
a 
once 
chosen 
development 
path 
and 
preserves 
the 
traditional 
domain-specific 
capabilities' 
value. 
In 
the 
AI 
context, 
however, 
we 
observe 
that 



21For 
example, 
Peteraf 
and 
Bergen 
(2003) 
describe 
how 
Quaker 
Oats, 
a 
maker 
of 
hot 
cereals, 
uses 
its 
grain-based 
capabilities 
to 
move 
into 
the 
ready-to-eat 
cereals 
industry. 
The 
new 
industry 
domain 
(ready-to-eat 
cereals) 
is 
closely 
related 
to 
the 
existing 
one 
(hot 
cereals), 
and 
the 
domain-specific 
capabilities 
that 
Quaker 
Oats 
transfers 
are 
described 
as 
highly 
similar 
to 
those 
they 
substitute. 
22For 
example, 
Argyres 
and 
Zenger 
(2012) 
describe 
how 
media 
managers 
at 
The 
Walt 
Disney 
Company 
created 
competitive 
advantage 
by 
integrating 
new 
animation 
capabilities 
with 
their 
existing 
bundle 
of 
complementary 
entertainment 
capabilities. 





experts, 
or 
those 
with 
rtise, 
use 
their 
general 
augmentation 
capabilities 
to 
create 
new 
competitive 
advantages. 
This 
lementation 
breaks 
the 
domain's 
current 
development 
path 
by 
shifting 
attention 
to 
its 
augmentation 
capabilities, 
while 
AI-based 
machine 
capabilities 
substitute 
traditional 
domain-specific 
capabilities. 
Consequently, 
and 
as 
our 
findings 
show, 
human 
experts 
who 
have 
enjoyed 
competitive 
advantage 
in 
the 
past 
are 
no 
longer 
the 
ones 
to 
generate 
it 
in 
the 
future 
competitive 
landscape 
that 
AI 
creates. 


Our 
findings 
also 
have 
wider 
implications 
for 
the 
RBV 
debate. 
In 
their 
influential 
review 
article, 
Kraaijenbrink, 
Spender, 
and 
Groen 
(2010, 
p. 
350) 
summarize 
the 
RBV 
as 
follows: 


The 
RBV 
assumes 
firms 
are 
profit 
maximizing 
entities 
directed 
by 
boundedly 
rational 
managers 
operating 
in 
distinctive 
markets 
that 
are 
to 
a 
reasonable 
extent 
predictable 
and 
moving 
towards 
equilibrium 
(…). 
It 
accepts 
that 
information 
about 
the 
future 
value 
of 
a 
resource 
is 
asymmetrically 
distributed. 
If 
the 
firm's 
managers 
can 
estimate 
the 
future 
value 
of 
a 
resource 
better 
than 
their 
competitors—or 
when 
they 
are 
simply 
lucky—this 
provides 
their 
firm 
with 
ex 
ante 
sources 
of 
sustainable 
competitive 
advantage. 
Subsequently, 
the 
development 
of 
isolating 
mechanisms 
that 
prevent 
other 
firms 
from 
competing 
their 
above-normal-profits 
away 
provides 
the 
firm 
with 
ex 
post 
sources 
of 
sustainable 
competitive 
advantage. 


Our 
findings 
relate 
to 
key 
elements 
of 
this 
statement. 
First, 
the 
strategic 
factor 
market 
concept 
(Adegbesan, 
2009; 
Barney, 
1986) 
suggests 
that 
there 
is, 
in 
predictable 
environments, 
heterogeneity 
in 
managers' 
ability 
to 
estimate 
resources' 
future 
value, 
providing 
ex 
ante 
sources 
of 
sustainable 
advantage. 
Our 
findings 
(Section 
4.1.2) 
inform 
this 
debate 
by 
suggesting 
that, 
in 
competitive 
prediction 
contexts 
(like 
chess), 
AI-based 
capabilities 
have 
the 
potential 
to 
substitute 
human 
foresight 
(Csaszar 
& 
Laureiro-Martínez, 
2018). 
Given 
AI-based 
capabilities' 
abundant 
availability, 
one 
of 
the 
RBV's 
most 
prominent 
ex 
ante 
sources 
of 
advantage 
(i.e., 
scarce 
managerial 
prediction 
capabilities) 
could 
be 
subject 
to 
equilibrium 
tendencies, 
which 
make 
creating 
or 
acquiring 
resources 
at 
a 
lower 
price 
than 
their 
subsequent 
value 
in 
use 
increasingly 
difficult. 


Second, 
our 
findings 
corroborate 
the 
RBV's 
traditional 
assumption 
(Barney, 
1986; 
Peteraf, 
1993) 
that 
technological 
resources 
do 
not 
provide 
the 
isolating 
mechanisms 
that 
characterize 
human 
resources 
as 
ex 
post 
sources 
of 
competitive 
advantage 
(Helfat 
& 
Peteraf, 
2015). 
This 
statement 
even 
holds 
for 
sophisticated 
AI-based 
machines 
that 
assimilate 
humans' 
cognitive 
functions. 
Our 
findings 
show 
that 
humans 
remain 
sources 
of 
sustainable 
advantage 
by 
combining 
and 
integrating 
their 
capabilities 
with 
machine 
capabilities 
into 
uniquely 
complementary 
bundles 
(Argyres 
& 
Zenger, 
2012). 
These 
insights 
inform 
a 
central 
RBV 
debate 
about 
whether 
the 
locus 
of 
sustainable 
advantage 
lies 
in 
non-human 
resources 
or 
in 
the 
characteristics 
of 
the 
humans 
comprising 
the 
firm 
(Kraaijenbrink 
et 
al., 
2010; 
Mahoney, 
1995). 
Ironically, 
our 
study 
of 
AI-based 
technology 
suggests 
it 
is 
humans, 
because 
the 
locus 
of 
sustainable 
advantage 
is 
neither 
human 
nor 
machine 
capabilities, 
but 
what 
humans 
do 
with 
these 
capabilities. 


5.3 
| 
Limitations 
and 
future 
research 
We 
have 
offered 
a 
perspective 
on 
how 
AI 
triggers 
resource 
dynamics 
that 
change 
the 
sources 
of 
competitive 
advantage. 
Our 
research 
has 
a 
significant 
limitation 
in 
that 
we 
have 
provided 
empirical 
evidence 
from 
just 
one 
domain—chess 
competitions—in 
which 
complete 
substitution 







 
scenario 
applies 
to 
certain 
business 
domains, 
the 
substitution 
may 
be 
partial 
in 
other 
domains, 
which 
means 
that 
rtise 
is 
still 
required 
(Raisch 
& 
Krakowski, 
2021). 
In 
these 
domains, 
experts' 
capabilities 
retain 
some 
value, 
but 
additional 
augmentation 
capabilities 
are 
also 
required. 


Furthermore, 
consistent 
with 
prior 
RBV 
studies 
conducting 
within-level 
analysis, 
chess 
players 
compete 
primarily 
at 
the 
individual 
level. 
Consequently, 
our 
study 
associates 
individual-level 
substitution 
and 
complementation 
with 
individual-level 
performance. 
While 
we 
believe 
that 
such 
within-level 
analysis 
provides 
a 
strong 
foundation 
for 
studying 
AI's 
impact 
on 
individuals 
and 
their 
capabilities, 
some 
RBV 
studies 
have 
also 
explored 
multilevel 
relationships 
(see 
Nyberg, 
Moliterno, 
Hale, 
& 
Lepak, 
2014). 
Specifically, 
these 
studies 
show 
that 
organizational-level 
human 
capabilities, 
such 
as 
those 
provided 
by 
corporate 
functions, 
can 
substitute 
or 
complement 
individual-level 
human 
capabilities 
(Crocker 
& 
Eckardt, 
2014; 
Stadler 
et 
al., 
2021). 
Moreover, 
the 
strategic 
human 
capital 
literature 
describes 
organizational-level 
human 
resources 
practices 
that 
promote 
and 
leverage 
individuals' 
capabilities 
(e.g., 
Gerhart 
& 
Feng, 
2021; 
Ployhart, 
2021; 
Shaw, 
2021). 
Building 
on 
these 
insights, 
future 
research 
could 
study 
AI-driven 
substitution 
and 
complementation 
in 
multilevel 
settings, 
for 
example, 
by 
investigating 
how 
AI-driven 
substitution 
and 
complementation 
yields 
positive 
and/or 
negative 
outcomes 
across 
levels. 


When 
implementing 
such 
multilevel 
work, 
we 
encourage 
scholars 
to 
conduct 
field 
experiments 
that 
will 
allow 
them 
to 
manipulate 
the 
functioning 
and/or 
implementation 
of 
AI 
in 
specific 
industries 
and 
decision 
making 
or 
problem 
solving 
domains. 
Such 
experiments 
have 
several 
advantages: 
First, 
they 
enable 
insight 
into 
AI's 
effects 
in 
real-life 
business 
contexts, 
including 
those 
characterized 
by 
high 
uncertainty 
and 
incomplete 
information. 
Second, 
manipulating 
contextual 
variables 
could 
provide 
valuable 
insight 
into 
the 
future 
division 
of 
labor 
between 
humans 
and 
AI 
within 
and 
across 
organizational 
levels, 
and 
the 
associated 
sources 
of 
advantage. 
Third, 
unlike 
our 
stable 
chess 
context, 
experiments 
could 
provide 
insight 
into 
the 
behavioral 
changes 
that 
occur 
during 
substitution 
and 
complementation 
through 
AI. 
Finally, 
given 
their 
experimental 
nature, 
these 
approaches 
could 
provide 
causal 
insight 
into 
these 
resource 
dynamics. 
While 
field 
experiments 
are 
likely 
to 
play 
a 
key 
role 
in 
future 
research, 
exploring 
the 
complex, 
yet 
increasingly 
pervasive, 
AI-driven 
resource 
dynamics 
also 
warrants 
the 
use 
of 
other 
methods 
that 
provide 
complementary 
insight. 
In 
order 
to 
empirically 
capture 
the 
nuances 
at 
play 
in 
AI-related 
substitution 
and 
complementation 
dynamics, 
future 
research 
requires 
approaches 
ranging 
from 
qualitative 
studies 
and 
ethnographies 
to 
simulations 
and 
observational 
studies. 


5.4 
| 
Practical 
implications 
Managers 
need 
to 
increasingly 
deal 
with 
AI 
in 
their 
business 
domains. 
This 
requires 
knowledge 
of 
AI's 
impact 
on 
their 
competitive 
position. 
The 
arguments 
and 
evidence 
presented 
in 
this 
article 
suggest 
that 
substitution 
will 
increasingly 
originate 
from 
domains 
outside 
firms' 
related 
spheres. 
AI-driven 
substitution 
across 
unrelated 
domains 
has 
emerged 
as 
a 
new 
competitive 
threat 
that 
erodes 
firms' 
competitive 
advantages. 
However, 
our 
findings 
also 
suggest 
possible 
ways 
for 
companies 
to 
deal 
with 
this 
challenge. 
They 
highlight 
the 
importance 
of 
companies 
acquiring 
augmentation 
capabilities 
that 
complement 
and 
substitute 
their 
traditional 
domain-
specific 
capabilities 
as 
sources 
of 
competitive 
advantage. 
Companies 
could 
invest 
in 
capability 
building 
initiatives 
to 
increase 
their 
employees' 
AI 
literacy 
and 
develop 
their 
complementary 







cognitive 
and 
social 
capabilities. 
Alternatively, 
they 
could 
hire 
human 
resources 
with 
these 
augmentation 
capabilities 
and 
deploy 
them 
in 
teams 
that 
also 
include 
h 
will 
allow 
them 
to 
combine 
their 
complementary 
capabilities 
in 
unique 
ways 
that 
generate 
competitive 
advantage. 


6 
| 
CONCLUSION 


At 
the 
outset 
of 
our 
research, 
we 
posed 
the 
question 
of 
how 
AI 
adoption 
affects 
the 
sources 
of 
competitive 
advantage. 
By 
exploring 
this 
question, 
we 
expanded 
our 
understanding 
of 
the 
resource 
dynamics 
that 
AI 
triggers. 
A 
key 
insight 
is 
that 
people 
still 
matter, 
which 
confirms 
the 
RBV's 
traditional 
focus 
on 
human 
cognitive 
capabilities' 
continued 
relevance. 
Another 
key 
insight 
is 
that 
AI 
substantially 
changes 
the 
ways 
in 
which 
people 
make 
a 
difference. 
These 
changes 
imply 
that 
the 
RBV 
should 
also 
evolve 
and 
continue 
to 
challenge, 
revise, 
and 
extend 
its 
theoretical 
assumptions 
to 
defend 
its 
competitive 
advantage 
as 
a 
leading 
management 
theory. 